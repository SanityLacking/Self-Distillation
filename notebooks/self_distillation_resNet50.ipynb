{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Distillation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "import branching\n",
    "\n",
    "from branching import branches\n",
    "from branching import evaluate\n",
    "\n",
    "# branching.enable_neptune(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, validation_ds = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,shuffle_size=15000,input_size=(32,32),include_targets=False,num_outputs = 10,reshuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds100, test_ds100, validation_ds100 = branching.dataset.prepare.dataset(tf.keras.datasets.cifar100.load_data(),32,5000,shuffle_size=15000,input_size=(32,32),include_targets=False,num_outputs = 100,reshuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Branch Model. this is a subclass of the standard Keras model and can do all the normal things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchModel(tf.keras.Model):\n",
    "    '''\n",
    "    Branched model sub-class. \n",
    "    Acts as a drop in replacement keras model class, with the additional functionality of adding branches to the model.\n",
    "            \n",
    "    '''\n",
    "    def __init__(self, inputs=None, outputs=None, name=\"\", model=None, transfer=True,custom_objects={}):\n",
    "        ## add default custom objects to the custom objects dictionary, this saves having to define them everytime.\n",
    "        custom_objects = {**branching.default_custom_objects,**custom_objects} \n",
    "        if inputs  is None and model is None and name is not \"\":\n",
    "            model = tf.keras.models.load_model(name,custom_objects=custom_objects)\n",
    "            self.saveLocation = name\n",
    "            super(BranchModel, self).__init__(inputs = model.inputs, outputs=model.outputs,name=model.name)            \n",
    "        elif model is None:\n",
    "            super(BranchModel, self).__init__(inputs = inputs, outputs=outputs,name=name)\n",
    "        elif model is not None:\n",
    "            super(BranchModel, self).__init__(inputs = model.inputs, outputs=model.outputs,name=name)\n",
    "        self.transfer = transfer\n",
    "        self.custom_objects = custom_objects\n",
    "        ##remap the depths of the layers to match the desired layout for branching\n",
    "        # self._map_graph_network(self.inputs,self.outputs, True)\n",
    "        self.branch_active = False\n",
    "   \n",
    "    def _run_internal_graph(self, inputs, training=None, mask=None):\n",
    "        \"\"\"custom version of _run_internal_graph\n",
    "            used to allow for interuption of the graph by an internal layer if conditions are met.\n",
    "        Computes output tensors for new inputs.\n",
    "        Args:\n",
    "            inputs: Tensor or nested structure of Tensors.\n",
    "            training: Boolean learning phase.\n",
    "            mask: (Optional) Tensor or nested structure of Tensors.\n",
    "\n",
    "        Returns:\n",
    "            output_tensors\n",
    "        \"\"\"\n",
    "        inputs = self._flatten_to_reference_inputs(inputs)\n",
    "        if mask is None:\n",
    "            masks = [None] * len(inputs)\n",
    "        else:\n",
    "            masks = self._flatten_to_reference_inputs(mask)\n",
    "        for input_t, mask in zip(inputs, masks):\n",
    "            input_t._keras_mask = mask\n",
    "\n",
    "        # Dictionary mapping reference tensors to computed tensors.\n",
    "        tensor_dict = {}\n",
    "        tensor_usage_count = self._tensor_usage_count\n",
    "        for x, y in zip(self.inputs, inputs):\n",
    "            y = self._conform_to_reference_input(y, ref_input=x)\n",
    "            x_id = str(id(x))\n",
    "            tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n",
    "\n",
    "        nodes_by_depth = self._nodes_by_depth\n",
    "        depth_keys = list(nodes_by_depth.keys())\n",
    "        depth_keys.sort(reverse=True)\n",
    "    \n",
    "        for depth in depth_keys:\n",
    "            nodes = nodes_by_depth[depth]\n",
    "            for node in nodes:\n",
    "                # print(node.layer.name)\n",
    "                if node.is_input:\n",
    "                    continue  # Input tensors already exist.\n",
    "\n",
    "                if any(t_id not in tensor_dict for t_id in node.flat_input_ids):\n",
    "                    continue  # Node is not computable, try skipping.\n",
    "\n",
    "                args, kwargs = node.map_arguments(tensor_dict)\n",
    "                outputs = node.layer(*args, **kwargs)\n",
    "                # Update tensor_dict.\n",
    "                for x_id, y in zip(node.flat_output_ids, nest.flatten(outputs)):\n",
    "                    tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n",
    "                \n",
    "                ## check if branch exiting is turned on and if current layer is a potential exit.\n",
    "                # print(node.layer.name, hasattr(node.layer, 'branch_exit'))\n",
    "                if not training:\n",
    "                    if self.branch_active == True and hasattr(node.layer, 'branch_exit'):  \n",
    "                        ## check if the confidence of output of the layer is equal to or above the threshold hyperparameter\n",
    "                        # print(\"threshold: \", node.layer.threshold, \"evidence: \", tf.reduce_sum(node.layer.evidence(outputs)))\n",
    "                        if node.layer.branch_exit and (tf.reduce_sum(node.layer.evidence(outputs)) >= node.layer.confidence_threshold): ##check if current layer's exit is active\n",
    "                            # print(\"branch exit activated\")\n",
    "                            output_tensors = []\n",
    "                            for x_id, y in zip(node.flat_output_ids, nest.flatten(outputs)):\n",
    "                                for x in self.outputs:\n",
    "                                    output_id = str(id(x))  \n",
    "                                    if output_id == x_id:\n",
    "                                        output_tensors.append(tensor_dict[x_id])\n",
    "                                    else:\n",
    "                                        # print(tensor_dict[x_id][0].shape)\n",
    "                                        output_tensors.append(tf.zeros(tensor_dict[x_id][0].shape))\n",
    "                                    # x_id_output = str(id(x))\n",
    "                                    # assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n",
    "                                    # output_tensors.append(tensor_dict[x_id])\n",
    "\n",
    "                            return nest.pack_sequence_as(self._nested_outputs, output_tensors)\n",
    "        output_tensors = []\n",
    "        for x in self.outputs:\n",
    "            x_id = str(id(x))\n",
    "            assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n",
    "            output_tensors.append(tensor_dict[x_id].pop())\n",
    "\n",
    "        return nest.pack_sequence_as(self._nested_outputs, output_tensors)\n",
    "\n",
    "    def add_branches(self,branchName, branchPoints=[], exact = True, target_input = False, compact = False, loop=True,num_outputs=10):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        # [\"max_pooling2d\",\"max_pooling2d_1\",\"dense\"]\n",
    "        # branch.newBranch_flatten\n",
    "        if loop:\n",
    "            newModel = branch.add_loop(self,branchName, branchPoints,exact=exact, target_input = target_input, compact = compact,num_outputs=num_outputs)\n",
    "        else:\n",
    "            newModel = branch.add(self,branchName,branchPoints, exact=exact, target_input = target_input, compact = compact,num_outputs=num_outputs)\n",
    "        print(\"branch added\", newModel)\n",
    "        self.__dict__.update(newModel.__dict__)\n",
    "\n",
    "        return self\n",
    "\n",
    "#     def compile(self, loss, optimizer, metrics=['accuracy'], run_eagerly=True, preset=\"\",**kwargs):\n",
    "#         ''' compile the model with custom options, either ones provided here or ones already set'''\n",
    "\n",
    "#         # if preset == \"\":\n",
    "#             # preset = self.customOptions\n",
    "#         print(preset)\n",
    "#         if preset == \"customLoss\": \n",
    "#             print(\"preset: customLoss\")\n",
    "#             loss_fn = evidence_crossentropy()\n",
    "#             super().compile(loss=loss_fn, optimizer=tf.optimizers.SGD(learning_rate=0.001,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "#         elif preset == \"customLoss_onehot\": \n",
    "#             print(\"preset: CrossE_onehot\")\n",
    "#             super().compile( loss={\"dense_2\":keras.losses.CategoricalCrossentropy(from_logits=True)}, optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "\n",
    "#         elif preset == \"CrossE\": \n",
    "#             print(\"preset: CrossE\")\n",
    "#             super().compile( loss =tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "\n",
    "#         elif preset == \"CrossE_Eadd\":\n",
    "#             print(\"preset: CrossE_Eadd\")\n",
    "#             entropyAdd = entropyAddition_loss()\n",
    "#             super().compile( optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9,clipvalue=0.5), loss=[keras.losses.SparseCategoricalCrossentropy(),entropyAdd,entropyAdd,entropyAdd], metrics=['accuracy',confidenceScore, unconfidence],run_eagerly=True,**kwargs)\n",
    "#             # model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.001), loss=[crossE_test, entropyAdd, entropyAdd, entropyAdd], metrics=['accuracy',confidenceScore, unconfidence],run_eagerly=True)\n",
    "#         else:\n",
    "#             print(\"preset: Other\")\n",
    "#         # model.compile(loss=entropyAddition, optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'],run_eagerly=True)\n",
    "#             super().compile(loss=loss, optimizer=optimizer, metrics=['accuracy'], **kwargs)\n",
    "\n",
    "    def setTrainable(self,trainable):\n",
    "        \"\"\" sets the trainable status of all main path layers in the model\"\"\"\n",
    "        if trainable == True: \n",
    "            print(\"Freezing Main Layers and setting branch layers training to true\")\n",
    "            for i in range(len(self.layers)):\n",
    "                # print(model.layers[i].name)\n",
    "                if \"branch\" in self.layers[i].name:\n",
    "                    # print(\"setting \",self.layers[i].name,\" training to true\")\n",
    "                    self.layers[i].trainable = True\n",
    "                else: \n",
    "                    # print(\"setting \",self.layers[i].name,\" training to false\")\n",
    "                    self.layers[i].trainable = False               \n",
    "        else:\n",
    "            print(\"Setting Main Layers  and branch layers training to true\")\n",
    "            for i in range(len(self.layers)):\n",
    "                # print(model.layers[i].name)\n",
    "                self.layers[i].trainable = True\n",
    "                # print(\"setting \",self.layers[i].name,\" training to true\")\n",
    "\n",
    "\n",
    "    def fit(self, train_ds, validation_data=None, epochs=1, callbacks=[], saveName = \"\", transfer = False, customOptions=\"\"):\n",
    "        \"\"\"Train the model that is passed using transfer learning. This function expects a model with trained main branches and untrained (or randomized) side branches.\n",
    "    \"\"\"\n",
    "        logs = []\n",
    "        num_outputs = len(self.outputs) # the number of output layers for the purpose of providing labels\n",
    "        #Freeze main branch layers\n",
    "        #how to iterate through layers and find main branch ones?\n",
    "        #simple fix for now: all branch nodes get branch in name.\n",
    "        self.setTrainable(transfer)\n",
    "        run_logdir = get_run_logdir(self.name)\n",
    "        tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "        if saveName ==\"\":\n",
    "            newModelName = \"{}_branched\".format(self.name )\n",
    "        else:\n",
    "            newModelName = saveName\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\"models/{}\".format(newModelName), monitor='val_loss', verbose=1, mode='max')\n",
    "\n",
    "        history =super().fit(train_ds,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_data,\n",
    "                validation_freq=1,\n",
    "                callbacks=[tensorboard_cb]+callbacks)\n",
    "        return self\n",
    "\n",
    "### the distill version of the branch model\n",
    "    \n",
    "class distilled_branch_model(BranchModel):\n",
    "    def __init__(self, modelName=\"\",saveName=\"\",transfer=True,customOptions=\"\") -> None:\n",
    "        self.modelName=modelName\n",
    "        self.saveName=saveName\n",
    "        self.transfer=transfer\n",
    "        self.customOptions=customOptions\n",
    "        self.model = tf.keras.models.load_model(\"{}\".format(modelName))\n",
    "        self.branchName = \"\"\n",
    "        self.dataset =\"\"\n",
    "        return None\n",
    "\n",
    "    def add_branches(self,branchName, branchPoints=[], exact = True, target_input = False):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        self.model = branch.add(self.model,branchPoints,branchName, exact=exact, target_input = target_input)\n",
    "        print(self)\n",
    "        return self\n",
    "\n",
    "    def add_distill(self,branchName, branchPoints, teacher_softmax, teaching_features, exact = True, target_input = False):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        self.model = branch.add_distil(self.model, teacher_softmax, teaching_features, branchPoints,branchName, exact=exact, target_input = target_input)\n",
    "        print(self)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define some functions for report the results after the training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Datasets\n",
    "<hr>\n",
    "validation set is for eval during training, testing set is for eval after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"./models/resnet_CE_entropy_finetuned.hdf5\")\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import tf_logging as logging\n",
    "class _earlyStopping(keras.callbacks.EarlyStopping):\n",
    "    def __init__(self,\n",
    "               monitor='val_loss',\n",
    "               min_delta=0,\n",
    "               patience=0,\n",
    "               verbose=0,\n",
    "               mode='auto',\n",
    "               baseline=None,\n",
    "               restore_best_weights=False):\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.baseline = baseline\n",
    "        self.min_delta = abs(min_delta)\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "        # super(_earlyStopping, self).__init__(monitor=)\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            logging.warning('EarlyStopping mode %s is unknown, '\n",
    "                          'fallback to auto mode.', mode)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "        else:\n",
    "            \n",
    "            # if (self.monitor.endswith('acc') or self.monitor.endswith('accuracy') or self.monitor.endswith('auc')):\n",
    "            self.monitor_op = np.greater\n",
    "            # else:\n",
    "                # self.monitor_op = np.less\n",
    "\n",
    "        if self.monitor_op == np.greater:\n",
    "            self.min_delta *= 1\n",
    "        else:\n",
    "            self.min_delta *= -1\n",
    "\n",
    "        self.monitor_op = np.greater\n",
    "        self.min_delta *= 1\n",
    "        \n",
    "    def get_monitor_value(self, logs):\n",
    "        logs = logs or {}\n",
    "        monitor_value = 0\n",
    "        if type(self.monitor) is list:\n",
    "            for i in self.monitor:\n",
    "                _log_val = logs.get(i)\n",
    "                # logging.warning(\"values are {}, {}\".format(i,_log_val))\n",
    "                if _log_val is None:\n",
    "                    logging.warning('Metric `%s` '\n",
    "                          'for early stopping is not available. Available metrics are: %s',\n",
    "                          i, ','.join(list(logs.keys())))\n",
    "                else:\n",
    "                    monitor_value += _log_val\n",
    "        # monitor_value = logs.get(self.monitor)\n",
    "        if monitor_value is None:\n",
    "            logging.warning('Early stopping conditioned on metric `%s` '\n",
    "                          'which is not available. Available metrics are: %s',\n",
    "                          self.monitor, ','.join(list(logs.keys())))\n",
    "        return monitor_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the branch structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = branching.Distill_BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1024)         2098176     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          524800      ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,215,818\n",
      "Trainable params: 26,162,698\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 14ms/step - loss: 0.8078 - accuracy: 0.7815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8078320622444153, 0.781499981880188]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.compile(loss=[trunk_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "                  # optimizer=\"adam\",\n",
    "               metrics=['accuracy'])\n",
    "base_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.compile(loss=[trunk_loss], \n",
    "#                   optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "#                   # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "#                   # optimizer=\"adam\",\n",
    "#                metrics=['accuracy'])\n",
    "# base_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "class SelfDistilEndpoint_2(branches.branch.BranchEndpoint):\n",
    "        \"\"\" distillation endpoint, performs the KL divergence between the teacher's and student's logits\n",
    "    \"\"\"\n",
    "        def __init__(self, num_outputs, loss_coef=1.9, temperature=10, name=None, **kwargs):\n",
    "            super(SelfDistilEndpoint_2, self).__init__(num_outputs=num_outputs, name=name)\n",
    "            self.num_outputs = num_outputs\n",
    "            self.loss_coef = loss_coef\n",
    "            self.temperature = temperature \n",
    "            self.distillation_loss_fn=keras.losses.KLDivergence()\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            tf.print(\"inputShape\",input_shape)\n",
    "            self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "        def get_config(self):\n",
    "            config = super().get_config().copy()\n",
    "            config.update({\n",
    "                'name': self.name\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def call(self, inputs, teaching_distill=None):\n",
    "            ''' do the normal kernel operations, then compare the difference between the teacher and this.\n",
    "            '''\n",
    "            outputs = tf.matmul(inputs,self.kernel)\n",
    "            outputs_sm = tf.nn.softmax(outputs)\n",
    "            # tf.print(\"outputs\",outputs)\n",
    "            # tf.print(\"teaching\",teaching_distill)\n",
    "            if teaching_distill is not None:\n",
    "                distil_loss = self.distillation_loss_fn(outputs_sm/self.temperature, teaching_distill/self.temperature)\n",
    "                distil_loss = distil_loss * self.loss_coef\n",
    "                # print(\"KL_LOSS\", kl_loss)\n",
    "                # self.add_loss(kl_loss)\n",
    "                self.add_loss(distil_loss)\n",
    "                self.add_metric(distil_loss, aggregation='mean',name=self.name+\"_distil\") # metric so this loss value can be monitored.\n",
    "            return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _branch_conv1(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" \n",
    "        Standard Branch, no distillation\n",
    "        Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, activation='softmax', name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "def _branch_Resnet50(prevLayer, teacher = None, targets=None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    # branchLayer = SelfDistilDense(512, loss_coef=1.9, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_feature_student\"))(branchLayer,teacher)\n",
    "    # branchLayer = layers.ReLU()(branchLayer)\n",
    "    # print(teacher)\n",
    "    output = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    return output\n",
    "\n",
    "\n",
    "def _branch_Distill(prevLayer, teacher = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    # branchLayer = SelfDistilDense(512, loss_coef=1.9, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_feature_student\"))(branchLayer,teacher)\n",
    "    # branchLayer = layers.ReLU()(branchLayer)\n",
    "    # print(teacher)\n",
    "    output = SelfDistilEndpoint_2(num_outputs=10, loss_coef=1.9, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer,teacher)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    # output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branching Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  conv2_block1_out\n",
      "add Branch to branch point  conv2_block3_out\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\")\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n",
      "branch added <branching.core.BranchModel object at 0x000002050009ACC8>\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# branch_loss = IAD_loss(growth_callback)\n",
    "branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=6,restore_best_weights=True)\n",
    "earlyStop = _earlyStopping(monitor=[\"val_classification_accuracy\",\"val_branch_exit_accuracy\",\"val_branch_exit_1_accuracy\"],patience=6,restore_best_weights=True)\n",
    "model = branching.BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\")\n",
    "\n",
    "### branch the model, no distillation\n",
    "model.add_branches([_branch_Resnet50,_branch_Resnet50],\n",
    "                          [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "                            # \"dense\"\n",
    "                          ],\n",
    "                          )\n",
    "\n",
    "#efficientNet\n",
    "# block2b_add, block3b_add \n",
    "\n",
    "### branch and distill the model\n",
    "\n",
    "# model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss, trunk_loss, trunk_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "                  # optimizer=\"adam\",\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " branch_conv2d (Conv2D)         (None, 8, 8, 128)    32896       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_3 (Conv2D)       (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " branch_batchnorm (BatchNormali  (None, 8, 8, 128)   512         ['branch_conv2d[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " branch_batchnorm_3 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " branch_conv2d_1 (Conv2D)       (None, 8, 8, 128)    16512       ['branch_batchnorm[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_4 (Conv2D)       (None, 8, 8, 128)    16512       ['branch_batchnorm_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " branch_batchnorm_1 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_4 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_4[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " branch_conv2d_2 (Conv2D)       (None, 4, 4, 512)    66048       ['branch_batchnorm_1[0][0]']     \n",
      "                                                                                                  \n",
      " branch_conv2d_5 (Conv2D)       (None, 4, 4, 512)    66048       ['branch_batchnorm_4[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " branch_batchnorm_2 (BatchNorma  (None, 4, 4, 512)   2048        ['branch_conv2d_2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_5 (BatchNorma  (None, 4, 4, 512)   2048        ['branch_conv2d_5[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " branch_flatten (Flatten)       (None, 8192)         0           ['branch_batchnorm_2[0][0]']     \n",
      "                                                                                                  \n",
      " branch_flatten_1 (Flatten)     (None, 8192)         0           ['branch_batchnorm_5[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " branch_dense (Dense)           (None, 1024)         8389632     ['branch_flatten[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_2 (Dense)         (None, 1024)         8389632     ['branch_flatten_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1024)         2098176     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " branch_dropout (Dropout)       (None, 1024)         0           ['branch_dense[0][0]']           \n",
      "                                                                                                  \n",
      " branch_dropout_1 (Dropout)     (None, 1024)         0           ['branch_dense_2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          524800      ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " branch_dense_1 (Dense)         (None, 512)          524800      ['branch_dropout[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_3 (Dense)         (None, 512)          524800      ['branch_dropout_1[0][0]']       \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " branch_exit (Dense)            (None, 10)           5130        ['branch_dense_1[0][0]']         \n",
      "                                                                                                  \n",
      " branch_exit_1 (Dense)          (None, 10)           5130        ['branch_dense_3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,291,998\n",
      "Trainable params: 44,235,806\n",
      "Non-trainable params: 56,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 17ms/step - loss: 5.5428 - classification_loss: 0.8078 - branch_exit_loss: 2.3856 - branch_exit_1_loss: 2.3494 - classification_accuracy: 0.7815 - branch_exit_accuracy: 0.0982 - branch_exit_1_accuracy: 0.0969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.54280948638916,\n",
       " 0.8078320622444153,\n",
       " 2.3855762481689453,\n",
       " 2.349400520324707,\n",
       " 0.781499981880188,\n",
       " 0.0982000008225441,\n",
       " 0.09690000116825104]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "https://app.neptune.ai/cailen01/self-distilation/e/SEL-76\n",
      "Remember to stop your run once youve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 93s 61ms/step - loss: 2.2033 - classification_loss: 0.2370 - branch_exit_loss: 1.0691 - branch_exit_1_loss: 0.8972 - classification_accuracy: 0.9256 - branch_exit_accuracy: 0.6313 - branch_exit_1_accuracy: 0.6969 - val_loss: 2.7716 - val_classification_loss: 0.9554 - val_branch_exit_loss: 0.9493 - val_branch_exit_1_loss: 0.8669 - val_classification_accuracy: 0.7482 - val_branch_exit_accuracy: 0.6720 - val_branch_exit_1_accuracy: 0.7132\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 1.5858 - classification_loss: 0.1821 - branch_exit_loss: 0.7854 - branch_exit_1_loss: 0.6184 - classification_accuracy: 0.9413 - branch_exit_accuracy: 0.7287 - branch_exit_1_accuracy: 0.7902 - val_loss: 2.6759 - val_classification_loss: 0.8959 - val_branch_exit_loss: 0.9348 - val_branch_exit_1_loss: 0.8453 - val_classification_accuracy: 0.7852 - val_branch_exit_accuracy: 0.6876 - val_branch_exit_1_accuracy: 0.7190\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 1.4797 - classification_loss: 0.2679 - branch_exit_loss: 0.6668 - branch_exit_1_loss: 0.5449 - classification_accuracy: 0.9126 - branch_exit_accuracy: 0.7682 - branch_exit_1_accuracy: 0.8153 - val_loss: 2.3928 - val_classification_loss: 0.7652 - val_branch_exit_loss: 0.8551 - val_branch_exit_1_loss: 0.7725 - val_classification_accuracy: 0.7924 - val_branch_exit_accuracy: 0.7156 - val_branch_exit_1_accuracy: 0.7546\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 1.1218 - classification_loss: 0.1525 - branch_exit_loss: 0.5381 - branch_exit_1_loss: 0.4311 - classification_accuracy: 0.9510 - branch_exit_accuracy: 0.8141 - branch_exit_1_accuracy: 0.8543 - val_loss: 5.4272 - val_classification_loss: 2.1358 - val_branch_exit_loss: 1.7000 - val_branch_exit_1_loss: 1.5914 - val_classification_accuracy: 0.6176 - val_branch_exit_accuracy: 0.5524 - val_branch_exit_1_accuracy: 0.6146\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.9947 - classification_loss: 0.1714 - branch_exit_loss: 0.4483 - branch_exit_1_loss: 0.3750 - classification_accuracy: 0.9436 - branch_exit_accuracy: 0.8449 - branch_exit_1_accuracy: 0.8706 - val_loss: 2.4288 - val_classification_loss: 0.7939 - val_branch_exit_loss: 0.8796 - val_branch_exit_1_loss: 0.7553 - val_classification_accuracy: 0.7942 - val_branch_exit_accuracy: 0.7324 - val_branch_exit_1_accuracy: 0.7690\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 86s 61ms/step - loss: 0.7413 - classification_loss: 0.1107 - branch_exit_loss: 0.3410 - branch_exit_1_loss: 0.2896 - classification_accuracy: 0.9648 - branch_exit_accuracy: 0.8829 - branch_exit_1_accuracy: 0.9026 - val_loss: 3.0489 - val_classification_loss: 1.1216 - val_branch_exit_loss: 0.9966 - val_branch_exit_1_loss: 0.9308 - val_classification_accuracy: 0.7748 - val_branch_exit_accuracy: 0.7324 - val_branch_exit_1_accuracy: 0.7552\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.6566 - classification_loss: 0.1221 - branch_exit_loss: 0.2821 - branch_exit_1_loss: 0.2524 - classification_accuracy: 0.9605 - branch_exit_accuracy: 0.9036 - branch_exit_1_accuracy: 0.9157 - val_loss: 2.6818 - val_classification_loss: 0.9375 - val_branch_exit_loss: 0.9608 - val_branch_exit_1_loss: 0.7835 - val_classification_accuracy: 0.7928 - val_branch_exit_accuracy: 0.7440 - val_branch_exit_1_accuracy: 0.7818\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 0.4856 - classification_loss: 0.0890 - branch_exit_loss: 0.2098 - branch_exit_1_loss: 0.1868 - classification_accuracy: 0.9725 - branch_exit_accuracy: 0.9291 - branch_exit_1_accuracy: 0.9383 - val_loss: 3.4510 - val_classification_loss: 1.0011 - val_branch_exit_loss: 1.3311 - val_branch_exit_1_loss: 1.1188 - val_classification_accuracy: 0.7774 - val_branch_exit_accuracy: 0.7012 - val_branch_exit_1_accuracy: 0.7520\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 0.4630 - classification_loss: 0.0838 - branch_exit_loss: 0.1969 - branch_exit_1_loss: 0.1824 - classification_accuracy: 0.9740 - branch_exit_accuracy: 0.9348 - branch_exit_1_accuracy: 0.9401 - val_loss: 2.8382 - val_classification_loss: 0.8726 - val_branch_exit_loss: 1.0634 - val_branch_exit_1_loss: 0.9022 - val_classification_accuracy: 0.8054 - val_branch_exit_accuracy: 0.7574 - val_branch_exit_1_accuracy: 0.7780\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 92s 66ms/step - loss: 0.6634 - classification_loss: 0.2242 - branch_exit_loss: 0.2208 - branch_exit_1_loss: 0.2184 - classification_accuracy: 0.9277 - branch_exit_accuracy: 0.9295 - branch_exit_1_accuracy: 0.9279 - val_loss: 3.0061 - val_classification_loss: 0.9010 - val_branch_exit_loss: 1.0648 - val_branch_exit_1_loss: 1.0404 - val_classification_accuracy: 0.7634 - val_branch_exit_accuracy: 0.7326 - val_branch_exit_1_accuracy: 0.7578\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 92s 66ms/step - loss: 0.3750 - classification_loss: 0.1090 - branch_exit_loss: 0.1362 - branch_exit_1_loss: 0.1298 - classification_accuracy: 0.9652 - branch_exit_accuracy: 0.9545 - branch_exit_1_accuracy: 0.9578 - val_loss: 3.2283 - val_classification_loss: 1.0766 - val_branch_exit_loss: 1.1977 - val_branch_exit_1_loss: 0.9540 - val_classification_accuracy: 0.7804 - val_branch_exit_accuracy: 0.7464 - val_branch_exit_1_accuracy: 0.7730\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.3488 - classification_loss: 0.0729 - branch_exit_loss: 0.1355 - branch_exit_1_loss: 0.1404 - classification_accuracy: 0.9769 - branch_exit_accuracy: 0.9563 - branch_exit_1_accuracy: 0.9550 - val_loss: 3.4465 - val_classification_loss: 1.1967 - val_branch_exit_loss: 1.1751 - val_branch_exit_1_loss: 1.0747 - val_classification_accuracy: 0.7696 - val_branch_exit_accuracy: 0.7486 - val_branch_exit_1_accuracy: 0.7656\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.4292 - classification_loss: 0.1381 - branch_exit_loss: 0.1441 - branch_exit_1_loss: 0.1470 - classification_accuracy: 0.9586 - branch_exit_accuracy: 0.9549 - branch_exit_1_accuracy: 0.9532 - val_loss: 3.2167 - val_classification_loss: 1.0023 - val_branch_exit_loss: 1.1883 - val_branch_exit_1_loss: 1.0261 - val_classification_accuracy: 0.7874 - val_branch_exit_accuracy: 0.7476 - val_branch_exit_1_accuracy: 0.7852\n",
      "Epoch 14/30\n",
      "1407/1407 [==============================] - 91s 65ms/step - loss: 0.3298 - classification_loss: 0.0943 - branch_exit_loss: 0.1190 - branch_exit_1_loss: 0.1165 - classification_accuracy: 0.9714 - branch_exit_accuracy: 0.9617 - branch_exit_1_accuracy: 0.9643 - val_loss: 3.2724 - val_classification_loss: 1.0091 - val_branch_exit_loss: 1.1663 - val_branch_exit_1_loss: 1.0971 - val_classification_accuracy: 0.7738 - val_branch_exit_accuracy: 0.7418 - val_branch_exit_1_accuracy: 0.7744\n",
      "Epoch 15/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.3048 - classification_loss: 0.0763 - branch_exit_loss: 0.1228 - branch_exit_1_loss: 0.1056 - classification_accuracy: 0.9766 - branch_exit_accuracy: 0.9614 - branch_exit_1_accuracy: 0.9668 - val_loss: 3.4177 - val_classification_loss: 0.9905 - val_branch_exit_loss: 1.3310 - val_branch_exit_1_loss: 1.0962 - val_classification_accuracy: 0.7940 - val_branch_exit_accuracy: 0.7562 - val_branch_exit_1_accuracy: 0.7754\n",
      "Epoch 16/30\n",
      "1407/1407 [==============================] - 95s 68ms/step - loss: 0.3096 - classification_loss: 0.0882 - branch_exit_loss: 0.1072 - branch_exit_1_loss: 0.1142 - classification_accuracy: 0.9732 - branch_exit_accuracy: 0.9658 - branch_exit_1_accuracy: 0.9647 - val_loss: 3.9046 - val_classification_loss: 1.3042 - val_branch_exit_loss: 1.3817 - val_branch_exit_1_loss: 1.2187 - val_classification_accuracy: 0.7626 - val_branch_exit_accuracy: 0.7258 - val_branch_exit_1_accuracy: 0.7544\n",
      "Epoch 17/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.2972 - classification_loss: 0.0861 - branch_exit_loss: 0.1055 - branch_exit_1_loss: 0.1056 - classification_accuracy: 0.9730 - branch_exit_accuracy: 0.9670 - branch_exit_1_accuracy: 0.9675 - val_loss: 3.3237 - val_classification_loss: 0.9862 - val_branch_exit_loss: 1.2983 - val_branch_exit_1_loss: 1.0392 - val_classification_accuracy: 0.7912 - val_branch_exit_accuracy: 0.7502 - val_branch_exit_1_accuracy: 0.7758\n",
      "Epoch 18/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.2590 - classification_loss: 0.0777 - branch_exit_loss: 0.0921 - branch_exit_1_loss: 0.0892 - classification_accuracy: 0.9762 - branch_exit_accuracy: 0.9708 - branch_exit_1_accuracy: 0.9708 - val_loss: 4.2204 - val_classification_loss: 1.1773 - val_branch_exit_loss: 1.5298 - val_branch_exit_1_loss: 1.5133 - val_classification_accuracy: 0.7658 - val_branch_exit_accuracy: 0.7128 - val_branch_exit_1_accuracy: 0.7448\n",
      "Epoch 19/30\n",
      "1407/1407 [==============================] - 93s 66ms/step - loss: 0.2406 - classification_loss: 0.0685 - branch_exit_loss: 0.0912 - branch_exit_1_loss: 0.0810 - classification_accuracy: 0.9796 - branch_exit_accuracy: 0.9708 - branch_exit_1_accuracy: 0.9747 - val_loss: 4.3448 - val_classification_loss: 1.2662 - val_branch_exit_loss: 1.5998 - val_branch_exit_1_loss: 1.4787 - val_classification_accuracy: 0.7530 - val_branch_exit_accuracy: 0.7176 - val_branch_exit_1_accuracy: 0.7494\n",
      "Epoch 20/30\n",
      "1407/1407 [==============================] - 91s 65ms/step - loss: 0.3023 - classification_loss: 0.0899 - branch_exit_loss: 0.1040 - branch_exit_1_loss: 0.1085 - classification_accuracy: 0.9723 - branch_exit_accuracy: 0.9680 - branch_exit_1_accuracy: 0.9681 - val_loss: 4.0914 - val_classification_loss: 1.4305 - val_branch_exit_loss: 1.3850 - val_branch_exit_1_loss: 1.2759 - val_classification_accuracy: 0.7336 - val_branch_exit_accuracy: 0.7064 - val_branch_exit_1_accuracy: 0.7342\n",
      "Epoch 21/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.3348 - classification_loss: 0.1399 - branch_exit_loss: 0.0965 - branch_exit_1_loss: 0.0983 - classification_accuracy: 0.9579 - branch_exit_accuracy: 0.9706 - branch_exit_1_accuracy: 0.9699 - val_loss: 3.2998 - val_classification_loss: 0.8948 - val_branch_exit_loss: 1.2536 - val_branch_exit_1_loss: 1.1514 - val_classification_accuracy: 0.8028 - val_branch_exit_accuracy: 0.7580 - val_branch_exit_1_accuracy: 0.7800\n",
      "Epoch 22/30\n",
      "1407/1407 [==============================] - 91s 65ms/step - loss: 0.2689 - classification_loss: 0.1093 - branch_exit_loss: 0.0753 - branch_exit_1_loss: 0.0843 - classification_accuracy: 0.9709 - branch_exit_accuracy: 0.9763 - branch_exit_1_accuracy: 0.9740 - val_loss: 3.6899 - val_classification_loss: 1.0483 - val_branch_exit_loss: 1.3833 - val_branch_exit_1_loss: 1.2583 - val_classification_accuracy: 0.7862 - val_branch_exit_accuracy: 0.7540 - val_branch_exit_1_accuracy: 0.7788\n",
      "Epoch 23/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.2114 - classification_loss: 0.0642 - branch_exit_loss: 0.0802 - branch_exit_1_loss: 0.0670 - classification_accuracy: 0.9795 - branch_exit_accuracy: 0.9758 - branch_exit_1_accuracy: 0.9794 - val_loss: 3.7743 - val_classification_loss: 1.0360 - val_branch_exit_loss: 1.4561 - val_branch_exit_1_loss: 1.2822 - val_classification_accuracy: 0.7932 - val_branch_exit_accuracy: 0.7354 - val_branch_exit_1_accuracy: 0.7800\n",
      "Epoch 24/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.2342 - classification_loss: 0.0789 - branch_exit_loss: 0.0752 - branch_exit_1_loss: 0.0801 - classification_accuracy: 0.9764 - branch_exit_accuracy: 0.9762 - branch_exit_1_accuracy: 0.9769 - val_loss: 3.7076 - val_classification_loss: 0.9658 - val_branch_exit_loss: 1.3726 - val_branch_exit_1_loss: 1.3692 - val_classification_accuracy: 0.7746 - val_branch_exit_accuracy: 0.7380 - val_branch_exit_1_accuracy: 0.7606\n",
      "Epoch 25/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.2468 - classification_loss: 0.0901 - branch_exit_loss: 0.0802 - branch_exit_1_loss: 0.0764 - classification_accuracy: 0.9722 - branch_exit_accuracy: 0.9750 - branch_exit_1_accuracy: 0.9771 - val_loss: 3.5921 - val_classification_loss: 1.0433 - val_branch_exit_loss: 1.4148 - val_branch_exit_1_loss: 1.1340 - val_classification_accuracy: 0.7976 - val_branch_exit_accuracy: 0.7600 - val_branch_exit_1_accuracy: 0.7926\n",
      "Epoch 26/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 0.1852 - classification_loss: 0.0543 - branch_exit_loss: 0.0676 - branch_exit_1_loss: 0.0633 - classification_accuracy: 0.9842 - branch_exit_accuracy: 0.9791 - branch_exit_1_accuracy: 0.9813 - val_loss: 5.3991 - val_classification_loss: 1.3802 - val_branch_exit_loss: 2.2658 - val_branch_exit_1_loss: 1.7531 - val_classification_accuracy: 0.7322 - val_branch_exit_accuracy: 0.6522 - val_branch_exit_1_accuracy: 0.7100\n",
      "Epoch 27/30\n",
      "1407/1407 [==============================] - 99s 70ms/step - loss: 0.2026 - classification_loss: 0.0623 - branch_exit_loss: 0.0657 - branch_exit_1_loss: 0.0746 - classification_accuracy: 0.9806 - branch_exit_accuracy: 0.9798 - branch_exit_1_accuracy: 0.9779 - val_loss: 4.3557 - val_classification_loss: 1.2310 - val_branch_exit_loss: 1.6382 - val_branch_exit_1_loss: 1.4865 - val_classification_accuracy: 0.7572 - val_branch_exit_accuracy: 0.7086 - val_branch_exit_1_accuracy: 0.7478\n",
      "Epoch 28/30\n",
      "1407/1407 [==============================] - 98s 69ms/step - loss: 0.2257 - classification_loss: 0.0840 - branch_exit_loss: 0.0762 - branch_exit_1_loss: 0.0655 - classification_accuracy: 0.9743 - branch_exit_accuracy: 0.9768 - branch_exit_1_accuracy: 0.9796 - val_loss: 3.3404 - val_classification_loss: 0.8943 - val_branch_exit_loss: 1.2850 - val_branch_exit_1_loss: 1.1611 - val_classification_accuracy: 0.8048 - val_branch_exit_accuracy: 0.7602 - val_branch_exit_1_accuracy: 0.7990\n",
      "Epoch 29/30\n",
      "1407/1407 [==============================] - 98s 69ms/step - loss: 0.1708 - classification_loss: 0.0571 - branch_exit_loss: 0.0540 - branch_exit_1_loss: 0.0598 - classification_accuracy: 0.9828 - branch_exit_accuracy: 0.9827 - branch_exit_1_accuracy: 0.9826 - val_loss: 3.9919 - val_classification_loss: 1.1336 - val_branch_exit_loss: 1.4651 - val_branch_exit_1_loss: 1.3932 - val_classification_accuracy: 0.7856 - val_branch_exit_accuracy: 0.7546 - val_branch_exit_1_accuracy: 0.7846\n",
      "Epoch 30/30\n",
      "1407/1407 [==============================] - 101s 72ms/step - loss: 0.1939 - classification_loss: 0.0719 - branch_exit_loss: 0.0567 - branch_exit_1_loss: 0.0653 - classification_accuracy: 0.9792 - branch_exit_accuracy: 0.9826 - branch_exit_1_accuracy: 0.9804 - val_loss: 4.4447 - val_classification_loss: 1.1946 - val_branch_exit_loss: 1.9472 - val_branch_exit_1_loss: 1.3028 - val_classification_accuracy: 0.7542 - val_branch_exit_accuracy: 0.6986 - val_branch_exit_1_accuracy: 0.7648\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 20 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 20 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "tags = [\"branching\",\"resnet50\",\"adam\",\"e30\",\"bp:block1,block3\"]\n",
    "model.fit(train_ds, epochs =30, validation_data = validation_ds, parameters=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/resnet50_branching_adam.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8_branched\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1024)         2098176     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          524800      ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,215,818\n",
      "Trainable params: 26,162,698\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self distillation version\n",
    "<hr>\n",
    "The already existing model is loaded from the file, \"*.hdf5\", \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by name\n",
      "add Branch to branch point  conv2_block1_out\n",
      "inputShape TensorShape([None, 512])\n",
      "add Branch to branch point  conv2_block3_out\n",
      "inputShape TensorShape([None, 512])\n",
      "branches added, new outputs [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# branch_loss = IAD_loss(growth_callback)\n",
    "branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=6,restore_best_weights=True)\n",
    "earlyStop = _earlyStopping(monitor=[\"val_classification_accuracy\",\"val_branch_exit_accuracy\",\"val_branch_exit_1_accuracy\"],patience=6,restore_best_weights=True)\n",
    "# model = branching.Distill_BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\", custom_objects={})\n",
    "model = branching.Distill_BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\")\n",
    "\n",
    "### branch the model, no distillation\n",
    "# model.add_branches([_branch_conv1,_branch_conv1],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           )\n",
    "\n",
    "#efficientNet\n",
    "# block2b_add, block3b_add \n",
    "\n",
    "### branch and distill the model\n",
    "model.add_distill(teacher = \"classification\",\n",
    "                  branch_layers = [_branch_Distill,_branch_Distill],\n",
    "                  branch_points =  [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "                          ],\n",
    "                  )\n",
    "\n",
    "# model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss, branch_loss, branch_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "                  # optimizer=\"adam\",\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8_branched\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " branch_conv2d (Conv2D)         (None, 8, 8, 128)    32896       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_3 (Conv2D)       (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " branch_batchnorm (BatchNormali  (None, 8, 8, 128)   512         ['branch_conv2d[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " branch_batchnorm_3 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " branch_conv2d_1 (Conv2D)       (None, 8, 8, 128)    16512       ['branch_batchnorm[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_4 (Conv2D)       (None, 8, 8, 128)    16512       ['branch_batchnorm_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " branch_batchnorm_1 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_4 (BatchNorma  (None, 8, 8, 128)   512         ['branch_conv2d_4[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_2 (Conv2D)       (None, 4, 4, 512)    66048       ['branch_batchnorm_1[0][0]']     \n",
      "                                                                                                  \n",
      " branch_conv2d_5 (Conv2D)       (None, 4, 4, 512)    66048       ['branch_batchnorm_4[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " branch_batchnorm_2 (BatchNorma  (None, 4, 4, 512)   2048        ['branch_conv2d_2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_5 (BatchNorma  (None, 4, 4, 512)   2048        ['branch_conv2d_5[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " branch_flatten (Flatten)       (None, 8192)         0           ['branch_batchnorm_2[0][0]']     \n",
      "                                                                                                  \n",
      " branch_flatten_1 (Flatten)     (None, 8192)         0           ['branch_batchnorm_5[0][0]']     \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1024)         2098176     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " branch_dense (Dense)           (None, 1024)         8389632     ['branch_flatten[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_2 (Dense)         (None, 1024)         8389632     ['branch_flatten_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          524800      ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " branch_dropout (Dropout)       (None, 1024)         0           ['branch_dense[0][0]']           \n",
      "                                                                                                  \n",
      " branch_dropout_1 (Dropout)     (None, 1024)         0           ['branch_dense_2[0][0]']         \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " branch_dense_1 (Dense)         (None, 512)          524800      ['branch_dropout[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_3 (Dense)         (None, 512)          524800      ['branch_dropout_1[0][0]']       \n",
      "                                                                                                  \n",
      " branch_exit (SelfDistilEndpoin  (None, 10)          5120        ['branch_dense_1[0][0]',         \n",
      " t_2)                                                             'classification[0][0]']         \n",
      "                                                                                                  \n",
      " branch_exit_1 (SelfDistilEndpo  (None, 10)          5120        ['branch_dense_3[0][0]',         \n",
      " int_2)                                                           'classification[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,291,978\n",
      "Trainable params: 44,235,786\n",
      "Non-trainable params: 56,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/resnet50_branching_adam.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "https://app.neptune.ai/cailen01/self-distilation/e/SEL-75\n",
      "Remember to stop your run once youve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "1407/1407 [==============================] - 98s 65ms/step - loss: 2.5227 - classification_loss: 0.3284 - branch_exit_loss: 1.0527 - branch_exit_1_loss: 0.8929 - classification_accuracy: 0.9154 - branch_exit_accuracy: 0.6402 - branch_exit_1_accuracy: 0.7020 - branch_exit_distil: 0.1401 - branch_exit_1_distil: 0.1085 - val_loss: 2.9744 - val_classification_loss: 0.7613 - val_branch_exit_loss: 1.1458 - val_branch_exit_1_loss: 0.8755 - val_classification_accuracy: 0.7512 - val_branch_exit_accuracy: 0.6250 - val_branch_exit_1_accuracy: 0.7076 - val_branch_exit_distil: 0.1151 - val_branch_exit_1_distil: 0.0763\n",
      "Epoch 2/30\n",
      "1407/1407 [==============================] - 92s 65ms/step - loss: 1.7947 - classification_loss: 0.2443 - branch_exit_loss: 0.7588 - branch_exit_1_loss: 0.6081 - classification_accuracy: 0.9347 - branch_exit_accuracy: 0.7393 - branch_exit_1_accuracy: 0.7950 - branch_exit_distil: 0.1074 - branch_exit_1_distil: 0.0761 - val_loss: 2.3351 - val_classification_loss: 0.6192 - val_branch_exit_loss: 0.8459 - val_branch_exit_1_loss: 0.7207 - val_classification_accuracy: 0.7948 - val_branch_exit_accuracy: 0.7134 - val_branch_exit_1_accuracy: 0.7582 - val_branch_exit_distil: 0.0909 - val_branch_exit_1_distil: 0.0587\n",
      "Epoch 3/30\n",
      "1407/1407 [==============================] - 91s 64ms/step - loss: 1.5487 - classification_loss: 0.2357 - branch_exit_loss: 0.6422 - branch_exit_1_loss: 0.5050 - classification_accuracy: 0.9334 - branch_exit_accuracy: 0.7818 - branch_exit_1_accuracy: 0.8316 - branch_exit_distil: 0.0978 - branch_exit_1_distil: 0.0679 - val_loss: 2.4948 - val_classification_loss: 0.6914 - val_branch_exit_loss: 0.8573 - val_branch_exit_1_loss: 0.7753 - val_classification_accuracy: 0.7868 - val_branch_exit_accuracy: 0.7198 - val_branch_exit_1_accuracy: 0.7582 - val_branch_exit_distil: 0.0956 - val_branch_exit_1_distil: 0.0748\n",
      "Epoch 4/30\n",
      "1407/1407 [==============================] - 90s 64ms/step - loss: 1.3358 - classification_loss: 0.2186 - branch_exit_loss: 0.5361 - branch_exit_1_loss: 0.4284 - classification_accuracy: 0.9368 - branch_exit_accuracy: 0.8178 - branch_exit_1_accuracy: 0.8560 - branch_exit_distil: 0.0895 - branch_exit_1_distil: 0.0632 - val_loss: 2.6787 - val_classification_loss: 0.6440 - val_branch_exit_loss: 1.0193 - val_branch_exit_1_loss: 0.8353 - val_classification_accuracy: 0.7912 - val_branch_exit_accuracy: 0.6960 - val_branch_exit_1_accuracy: 0.7492 - val_branch_exit_distil: 0.1053 - val_branch_exit_1_distil: 0.0749\n",
      "Epoch 5/30\n",
      "1407/1407 [==============================] - 97s 69ms/step - loss: 1.1169 - classification_loss: 0.1694 - branch_exit_loss: 0.4392 - branch_exit_1_loss: 0.3664 - classification_accuracy: 0.9529 - branch_exit_accuracy: 0.8495 - branch_exit_1_accuracy: 0.8772 - branch_exit_distil: 0.0818 - branch_exit_1_distil: 0.0600 - val_loss: 2.8655 - val_classification_loss: 0.6972 - val_branch_exit_loss: 1.1171 - val_branch_exit_1_loss: 0.8522 - val_classification_accuracy: 0.7736 - val_branch_exit_accuracy: 0.6958 - val_branch_exit_1_accuracy: 0.7570 - val_branch_exit_distil: 0.1225 - val_branch_exit_1_distil: 0.0768\n",
      "Epoch 6/30\n",
      "1407/1407 [==============================] - 98s 69ms/step - loss: 0.8781 - classification_loss: 0.1240 - branch_exit_loss: 0.3400 - branch_exit_1_loss: 0.2869 - classification_accuracy: 0.9673 - branch_exit_accuracy: 0.8843 - branch_exit_1_accuracy: 0.9046 - branch_exit_distil: 0.0725 - branch_exit_1_distil: 0.0546 - val_loss: 2.6166 - val_classification_loss: 0.6013 - val_branch_exit_loss: 0.9733 - val_branch_exit_1_loss: 0.8618 - val_classification_accuracy: 0.8046 - val_branch_exit_accuracy: 0.7424 - val_branch_exit_1_accuracy: 0.7726 - val_branch_exit_distil: 0.1051 - val_branch_exit_1_distil: 0.0750\n",
      "Epoch 7/30\n",
      "1407/1407 [==============================] - 97s 69ms/step - loss: 0.7469 - classification_loss: 0.1152 - branch_exit_loss: 0.2662 - branch_exit_1_loss: 0.2455 - classification_accuracy: 0.9694 - branch_exit_accuracy: 0.9100 - branch_exit_1_accuracy: 0.9196 - branch_exit_distil: 0.0667 - branch_exit_1_distil: 0.0534 - val_loss: 2.6127 - val_classification_loss: 0.6329 - val_branch_exit_loss: 0.9682 - val_branch_exit_1_loss: 0.8255 - val_classification_accuracy: 0.8090 - val_branch_exit_accuracy: 0.7632 - val_branch_exit_1_accuracy: 0.7816 - val_branch_exit_distil: 0.1062 - val_branch_exit_1_distil: 0.0802\n",
      "Epoch 8/30\n",
      "1407/1407 [==============================] - 95s 68ms/step - loss: 0.6528 - classification_loss: 0.1118 - branch_exit_loss: 0.2314 - branch_exit_1_loss: 0.1974 - classification_accuracy: 0.9683 - branch_exit_accuracy: 0.9250 - branch_exit_1_accuracy: 0.9354 - branch_exit_distil: 0.0632 - branch_exit_1_distil: 0.0490 - val_loss: 2.9162 - val_classification_loss: 0.6820 - val_branch_exit_loss: 1.1180 - val_branch_exit_1_loss: 0.9275 - val_classification_accuracy: 0.7964 - val_branch_exit_accuracy: 0.7266 - val_branch_exit_1_accuracy: 0.7826 - val_branch_exit_distil: 0.1141 - val_branch_exit_1_distil: 0.0750\n",
      "Epoch 9/30\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 0.5661 - classification_loss: 0.0923 - branch_exit_loss: 0.1958 - branch_exit_1_loss: 0.1737 - classification_accuracy: 0.9755 - branch_exit_accuracy: 0.9347 - branch_exit_1_accuracy: 0.9440 - branch_exit_distil: 0.0591 - branch_exit_1_distil: 0.0452 - val_loss: 2.9503 - val_classification_loss: 0.7075 - val_branch_exit_loss: 1.0017 - val_branch_exit_1_loss: 1.0202 - val_classification_accuracy: 0.7992 - val_branch_exit_accuracy: 0.7650 - val_branch_exit_1_accuracy: 0.7828 - val_branch_exit_distil: 0.1251 - val_branch_exit_1_distil: 0.0954\n",
      "Epoch 10/30\n",
      "1407/1407 [==============================] - 95s 67ms/step - loss: 0.5434 - classification_loss: 0.0972 - branch_exit_loss: 0.1773 - branch_exit_1_loss: 0.1660 - classification_accuracy: 0.9724 - branch_exit_accuracy: 0.9440 - branch_exit_1_accuracy: 0.9470 - branch_exit_distil: 0.0564 - branch_exit_1_distil: 0.0465 - val_loss: 3.0079 - val_classification_loss: 0.6917 - val_branch_exit_loss: 1.0756 - val_branch_exit_1_loss: 1.0032 - val_classification_accuracy: 0.8048 - val_branch_exit_accuracy: 0.7562 - val_branch_exit_1_accuracy: 0.7794 - val_branch_exit_distil: 0.1333 - val_branch_exit_1_distil: 0.1043\n",
      "Epoch 11/30\n",
      "1407/1407 [==============================] - 89s 63ms/step - loss: 0.4592 - classification_loss: 0.0832 - branch_exit_loss: 0.1477 - branch_exit_1_loss: 0.1368 - classification_accuracy: 0.9754 - branch_exit_accuracy: 0.9548 - branch_exit_1_accuracy: 0.9571 - branch_exit_distil: 0.0502 - branch_exit_1_distil: 0.0413 - val_loss: 5.0379 - val_classification_loss: 2.2258 - val_branch_exit_loss: 1.3866 - val_branch_exit_1_loss: 1.0712 - val_classification_accuracy: 0.7614 - val_branch_exit_accuracy: 0.7206 - val_branch_exit_1_accuracy: 0.7712 - val_branch_exit_distil: 0.1997 - val_branch_exit_1_distil: 0.1546\n",
      "Epoch 12/30\n",
      "1407/1407 [==============================] - 88s 63ms/step - loss: 0.4621 - classification_loss: 0.0877 - branch_exit_loss: 0.1481 - branch_exit_1_loss: 0.1329 - classification_accuracy: 0.9750 - branch_exit_accuracy: 0.9532 - branch_exit_1_accuracy: 0.9587 - branch_exit_distil: 0.0517 - branch_exit_1_distil: 0.0417 - val_loss: 3.5286 - val_classification_loss: 0.7678 - val_branch_exit_loss: 1.3647 - val_branch_exit_1_loss: 1.1611 - val_classification_accuracy: 0.7944 - val_branch_exit_accuracy: 0.7366 - val_branch_exit_1_accuracy: 0.7804 - val_branch_exit_distil: 0.1349 - val_branch_exit_1_distil: 0.1006\n",
      "Epoch 13/30\n",
      "1407/1407 [==============================] - 91s 65ms/step - loss: 0.4254 - classification_loss: 0.0749 - branch_exit_loss: 0.1335 - branch_exit_1_loss: 0.1291 - classification_accuracy: 0.9784 - branch_exit_accuracy: 0.9580 - branch_exit_1_accuracy: 0.9603 - branch_exit_distil: 0.0474 - branch_exit_1_distil: 0.0407 - val_loss: 3.3336 - val_classification_loss: 0.6805 - val_branch_exit_loss: 1.3626 - val_branch_exit_1_loss: 1.0474 - val_classification_accuracy: 0.8148 - val_branch_exit_accuracy: 0.7396 - val_branch_exit_1_accuracy: 0.7902 - val_branch_exit_distil: 0.1466 - val_branch_exit_1_distil: 0.0974\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for the remaining 20 operations to synchronize with Neptune. Do not kill this process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 20 operations synced, thanks for waiting!\n"
     ]
    }
   ],
   "source": [
    "tags = [\"bsd\",\"resnet50\",\"adam\",\"e30\",\"bp:block1,block3\"]\n",
    "model.fit(train_ds, epochs =30, validation_data = validation_ds, parameters=tags,callbacks=[earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 18ms/step - loss: 2.7737 - classification_loss: 0.6953 - branch_exit_loss: 0.9887 - branch_exit_1_loss: 0.8953 - classification_accuracy: 0.7943 - branch_exit_accuracy: 0.7551 - branch_exit_1_accuracy: 0.7641 - branch_exit_distil: 0.1084 - branch_exit_1_distil: 0.0859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7737011909484863,\n",
       " 0.6952880620956421,\n",
       " 0.9886670708656311,\n",
       " 0.8953412175178528,\n",
       " 0.7943000197410583,\n",
       " 0.7551000118255615,\n",
       " 0.7641000151634216,\n",
       " 0.10835718363523483,\n",
       " 0.08592724800109863]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 25ms/step - loss: 2.2786 - classification_loss: 0.6563 - branch_exit_loss: 0.7290 - branch_exit_1_loss: 0.7308 - classification_accuracy: 0.7993 - branch_exit_accuracy: 0.7730 - branch_exit_1_accuracy: 0.7914 - branch_exit_distil: 0.0898 - branch_exit_1_distil: 0.0726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2785863876342773,\n",
       " 0.6562694907188416,\n",
       " 0.7289900779724121,\n",
       " 0.7308015823364258,\n",
       " 0.7993000149726868,\n",
       " 0.7730000019073486,\n",
       " 0.7914000153541565,\n",
       " 0.08977510780096054,\n",
       " 0.07261962443590164]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/resnet_1.9_adam.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "https://app.neptune.ai/cailen01/self-distilation/e/SEL-11\n",
      "Remember to stop your run once youve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/30\n",
      "   6/1406 [..............................] - ETA: 1:23 - loss: 8.2378 - classification_loss: 0.1864 - branch_exit_loss: 3.1480 - branch_exit_1_loss: 3.2163 - classification_accuracy: 0.9531 - branch_exit_accuracy: 0.1406 - branch_exit_1_accuracy: 0.1146 - branch_exit_distil: 0.8229 - branch_exit_1_distil: 0.8642WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0386s vs `on_train_batch_end` time: 0.0443s). Check your callbacks.\n",
      " 399/1406 [=======>......................] - ETA: 59s - loss: 3.5367 - classification_loss: 0.3619 - branch_exit_loss: 1.5062 - branch_exit_1_loss: 1.3280 - classification_accuracy: 0.9158 - branch_exit_accuracy: 0.4637 - branch_exit_1_accuracy: 0.5347 - branch_exit_distil: 0.1840 - branch_exit_1_distil: 0.1566"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_54532/787434926.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m            \u001b[1;34m\"loss_coef\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m            \"temperature\":10,}\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mearlyStop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Self_Distillation\\branching\\core_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_ds, validation_data, validation_freq, epochs, callbacks, saveName, freeze, custom_objects, parameters)\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m                 callbacks=[tensorboard_cb,callbacks, neptune_cbk])\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2957\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1854\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters={\"type\":\"SD\",\n",
    "           \"loss\":\"Adam\",\n",
    "           \"threshold\":\"entropy\",\n",
    "           \"loss_coef\":1.9,\n",
    "           \"temperature\":10,}\n",
    "model.fit(train_ds, epochs =30, validation_data = validation_ds, callbacks=[earlyStop],parameters=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/resnet_CE_entropy_finetuned.hdf5\", custom_objects={\"Distill_BranchModel\": branching.Distill_BranchModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)            (None, 2048)         0           ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1024)         2098176     ['flatten_8[0][0]']              \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 512)          524800      ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,215,818\n",
      "Trainable params: 26,162,698\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 5s 17ms/step - loss: 5.5853 - classification_loss: 1.6418 - branch_exit_loss: 1.7552 - branch_exit_1_loss: 1.9198 - classification_accuracy: 0.6998 - branch_exit_accuracy: 0.6943 - branch_exit_1_accuracy: 0.7099 - branch_exit_distil: 0.1491 - branch_exit_1_distil: 0.1193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.585251331329346,\n",
       " 1.6418087482452393,\n",
       " 1.755229115486145,\n",
       " 1.9198211431503296,\n",
       " 0.6998196840286255,\n",
       " 0.6943109035491943,\n",
       " 0.7099359035491943,\n",
       " 0.14910893142223358,\n",
       " 0.11928417533636093]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputShape TensorShape([None, 512])\n",
      "inputShape TensorShape([None, 512])\n"
     ]
    }
   ],
   "source": [
    "# lambda_callback = lambda_update(1000,0,max_t = 0.01)\n",
    "# growth_callback = growth_update(100,0,max_t = 0.1, starting_epoch =0)\n",
    "\n",
    "# auxlossMetric = auxLoss(growth_callback)\n",
    "# branch_loss = loss_wrapper(growth_callback)\n",
    "branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# model = tf.keras.models.load_model(\"./models/journal_models/resnet_EDL_e15_g100.hdf5\",custom_objects={\"BranchModel\":brevis.BranchModel,\"auxloss\":auxlossMetric,\"growth_callback\":growth_callback,\"custom_loss_function\":branch_loss})\n",
    "model = tf.keras.models.load_model(\"./models/resnet_1.9_sgd.hdf5\",custom_objects={\"Distill_BranchModel\":branching.Distill_BranchModel,\"SelfDistilEndpoint_2\":SelfDistilEndpoint_2, \"custom_loss_function\":branch_loss})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 12s 22ms/step - loss: 2.2786 - classification_loss: 0.6563 - branch_exit_loss: 0.7290 - branch_exit_1_loss: 0.7308 - accuracy: 0.7914 - branch_exit_distil: 0.0898 - branch_exit_1_distil: 0.0726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2785863876342773,\n",
       " 0.6562695503234863,\n",
       " 0.7289900779724121,\n",
       " 0.7308015823364258,\n",
       " 0.7914000153541565,\n",
       " 0.7914000153541565,\n",
       " 0.7914000153541565,\n",
       " 0.08977510780096054,\n",
       " 0.07261963933706284]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the branches on the test dataset, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(model, input_set, stopping_point=None,num_classes=10, values =['energy', 'entropy', 'calibration']):\n",
    "    '''\n",
    "        Function for collecting the model's predictions on a test set. \n",
    "        Returns a list of DataFrames for each exit of the model.    \n",
    "    '''\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "    print(\"outputs\",num_outputs)\n",
    "    print(values)\n",
    "    #     train_ds, test_ds, validation_ds = (dataset)\n",
    "    Results=[]\n",
    "    Pred=[]\n",
    "    Labels =[]\n",
    "    Uncert = []\n",
    "    Outputs = pd.DataFrame()\n",
    "    Energy = []\n",
    "    Energy_softmax = []\n",
    "    Energy_evidence = []\n",
    "    Energy_alpha = []\n",
    "    Energy_Mass = []\n",
    "    Entropy = []\n",
    "    pAcc=[]\n",
    "    calibration=[]\n",
    "\n",
    "    conf=[]\n",
    "    entropy_of_exp=[]\n",
    "    expected_entropy=[]\n",
    "    mutual_info=[]\n",
    "    epkl=[]\n",
    "    dentropy=[]\n",
    "    if 'energy' in values:\n",
    "        print(True)\n",
    "    for i in range(num_outputs):\n",
    "        Results.append([])\n",
    "        Pred.append([])\n",
    "        Labels.append([])\n",
    "        Uncert.append([])\n",
    "        Energy.append([])\n",
    "        Energy_softmax.append([])\n",
    "        Energy_evidence.append([])\n",
    "        Energy_alpha.append([])\n",
    "        Energy_Mass.append([])\n",
    "        Entropy.append([])\n",
    "        pAcc.append([])\n",
    "        calibration.append([])\n",
    "\n",
    "        conf.append([])\n",
    "        entropy_of_exp.append([])\n",
    "        expected_entropy.append([])\n",
    "        mutual_info.append([])\n",
    "        epkl.append([])\n",
    "        dentropy.append([])\n",
    "        \n",
    "    for i, (x,y) in enumerate(input_set):\n",
    "        if stopping_point and i > stopping_point:\n",
    "            break\n",
    "        try:\n",
    "            print(\"prediction: {} of {}\".format(i,len(input_set)),end='\\r')\n",
    "        except:\n",
    "            print(\"prediction: {}\".format(i),end='\\r')\n",
    "            pass\n",
    "        predictions = model.predict(x)\n",
    "        if num_outputs > 1:\n",
    "            _predictions = predictions[0]\n",
    "        else:\n",
    "            _predictions = [predictions]\n",
    "        # print(_predictions)\n",
    "        for k, outputs in enumerate(_predictions):\n",
    "            \n",
    "            # print(\"outputs \", k, outputs)\n",
    "            for j, prediction in enumerate(outputs):\n",
    "               \n",
    "                Results[k].append(np.argmax(prediction))\n",
    "                Labels[k].append(np.argmax(y[j]))\n",
    "                \n",
    "                if 'energy' in values:\n",
    "                    Energy[k].append( -(logsumexp(np.array(prediction))))\n",
    "                if 'entropy' in values:\n",
    "                    Entropy[k].append(branching.utils.calcEntropy_Tensors2(tf.nn.softmax(prediction)).numpy())\n",
    "                if 'calibration' in values:\n",
    "                    calibration[k].append(np.amax(tf.nn.softmax(prediction).numpy()))\n",
    "                if 'uncert' in values:\n",
    "                    evidence =tf.nn.softplus(prediction)\n",
    "                    alpha = evidence +1\n",
    "                    S = sum(alpha)\n",
    "                    E = alpha - 1\n",
    "                    Mass = alpha / S\n",
    "                    u = num_classes / S\n",
    "                    Uncert[k].append(u.numpy().mean())\n",
    "                # Entropy[k].append(brevis.utils.calcEntropy_Tensors2(tf.nn.softmax(prediction)).numpy())\n",
    "                # dirch = evaluate.dirichlet_prior_network_uncertainty([prediction])\n",
    "                # # print(dirch)\n",
    "                # conf[k].append(dirch[\"confidence_alea_uncert.\"])\n",
    "                # entropy_of_exp[k].append(dirch[\"entropy_of_expected\"])\n",
    "                # expected_entropy[k].append(dirch[\"expected_entropy\"])\n",
    "                # mutual_info[k].append(dirch[\"mutual_information\"])\n",
    "                # epkl[k].append(dirch[\"EPKL\"])\n",
    "                # dentropy[k].append(dirch[\"differential_entropy\"])\n",
    "    Outputs=[]\n",
    "    for j in range(num_outputs):\n",
    "#         \"probs\":Pred[j],\n",
    "        # df = pd.DataFrame({\"x\":Results[j],\"y\":Labels[j],'sum':Sum[j],'uncert':Uncert[j],\"belief masses\":Evidence[j]})\n",
    "        results = {\"x\":Results[j],\"y\":Labels[j]}\n",
    "        if 'energy' in values:\n",
    "            results[\"energy\"]=Energy[j]\n",
    "        if 'entropy' in values:\n",
    "            results['entropy']=Entropy[j]\n",
    "        if 'calibration' in values:\n",
    "            results['calibration']=calibration[j]\n",
    "        if 'uncert' in values:\n",
    "            results['uncert']=Uncert[j]\n",
    "#         {\"x\":Results[j],\"y\":Labels[j],\n",
    "#                         # \"confidence_alea_uncert\":conf[j],\n",
    "#                         # \"entropy_of_expected\":entropy_of_exp[j],\n",
    "#                         # \"expected_entropy\":expected_entropy[j],\n",
    "#                         # \"mutual_information\":mutual_info[j],\n",
    "#                         # \"EPKL\":epkl[j],\n",
    "#                         # \"differential_entropy\":dentropy[j],\n",
    "#                       }\n",
    "        # print(results)\n",
    "        df = pd.DataFrame(results)\n",
    "        conditions = [df['x'] == df['y'],df['x'] != df['y']]\n",
    "        choices = [1, 0]\n",
    "        #create new column in DataFrame that displays results of comparisons\n",
    "        df['correct'] = np.int32(np.select(conditions, choices, default=None))\n",
    "        Outputs.append(df)\n",
    "    return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 3\n",
      "['entropy']\n",
      "prediction: 312 of 313\r"
     ]
    }
   ],
   "source": [
    "#if EDL\n",
    "output_ID= getPredictions(model, test_ds,  values =['entropy'], stopping_point=None)\n",
    "#if CE\n",
    "# output_ID= evaluate.getPredictions(model, test_ds,  values =['entropy'], stopping_point=None)\n",
    "for i in output_ID:\n",
    "    i['outlier']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 3\n",
      "['entropy']\n",
      "prediction: 312 of 313\r"
     ]
    }
   ],
   "source": [
    "# #if EDL\n",
    "# output_OOD= getPredictions(model, test_ds100,  values =['entropy'], stopping_point=None)\n",
    "# #if CE\n",
    "output_OOD= getPredictions(model, test_ds100,  values =['entropy'], stopping_point=None)\n",
    "for i in output_OOD:\n",
    "    i['correct']=0\n",
    "    i['outlier']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, plot_precision_recall_curve\n",
    "from numpy import sqrt, argmax\n",
    "def calc_AUC(output_df,metrics=['energy'],plot=False, pos_label = 0):\n",
    "    '''\n",
    "    AUC calculation function for list of output dataframes\n",
    "    returns a list of threshold for the gmean of each set of outputs.    \n",
    "    '''\n",
    "    lessThanMetrics = [\"uncert\",\"energy\",\"entropy\"]\n",
    "    _thresholds = []\n",
    "    y_test = np.int32(output_df['correct'])\n",
    "    plots = []\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for metric in metrics:    \n",
    "        # print(\"metric\", metric)\n",
    "        lr_auc = roc_auc_score(y_test, output_df[metric])\n",
    "        if metric in lessThanMetrics:\n",
    "            pos_label = 0\n",
    "        else:\n",
    "            pos_label = 1\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, output_df[metric],pos_label=pos_label)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        # print(gmeans)\n",
    "        # locate the index of the largest g-mean\n",
    "        ix = argmax(gmeans)\n",
    "        threshold = thresholds[ix]\n",
    "        if plot:\n",
    "            print(metric,\" lr_auc\",lr_auc, 'Best Threshold={}, G-Mean={}, TPR={}, FPR={}'.format(threshold, gmeans[ix],tpr[ix],fpr[ix]))\n",
    "        _thresholds.append(threshold)\n",
    "        # plot the roc curve for the model\n",
    "        plots.append({\"fpr\":fpr,\"tpr\":tpr,\"label\":metric, \"ix\":ix})\n",
    "    if plot:\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        for plot in plots:\n",
    "            ix = plot['ix']\n",
    "            plt.plot(plot[\"fpr\"], plot[\"tpr\"],  label=plot['label'])\n",
    "\n",
    "            plt.scatter(plot[\"fpr\"][ix], plot[\"tpr\"][ix], marker='o', color='black')\n",
    "        # axis labels\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(metric)\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "    return _thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateID(ID,metrics=[\"energy\"], threshold=None, exit=-1, legend=[\"In Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1']):\n",
    "    '''\n",
    "    Build an evaluation plot of the branched model's performance on ID and OOD datasets.\n",
    "\n",
    "    ::Variables::\n",
    "    ID: in-distribution dataset\n",
    "    OOD: out of distribution dataset\n",
    "    metrics: list of strings of metrics to evaluate branch results with. can be any of the following: [\"gmean\", \"mean\", \"PR_AUC\"]\n",
    "    exit: #if a specific exit number is specified, only output the results of that exit. counts from 0 - N, with 0 being the main exit. -1 returns all exits\n",
    "    legend: specify a legend to use for the plot\n",
    "    main_exit_included: specify if the last exit must answer all inputs recieved, if False, it will use the threshold to accept and reject inputs\n",
    "    plot: choose to produce a plot or just the table of branch results\n",
    "    exit_labels: what labels to use for the exits, defaults to \"exit_N\" \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for j, metric in enumerate(metrics):\n",
    "        print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "        rollOver_ID_indices = pd.Index([])\n",
    "        Exit_Name=[]\n",
    "        _ID = ID.copy()\n",
    "        _ID.append(_ID.pop(0))\n",
    "        Accepted_df = pd.DataFrame()\n",
    "        Input_ID=[]\n",
    "        Accepted_list =[]\n",
    "        Accepted_ID_list = []\n",
    "        Acceptance_correct =[]\n",
    "        Input_predictions =[]\n",
    "        Accepted_Ratio_list=[]\n",
    "        Accepted_Accuracy_list=[]\n",
    "        Branch_flops = []\n",
    "        Thresholds=[]\n",
    "        Test_accuracy =[]\n",
    "        Rollover_accuracy=[]\n",
    "        Results=[]\n",
    "        Accepted_Accuracy=[]\n",
    "        Rejected_Input=[]\n",
    "        Accepted_Ratio=[]\n",
    "        if exit > 0: #if a specific exit number is specified, only output the results of that exit.\n",
    "            _ID = [_ID[max(exit-1,0)]]\n",
    "            exit_labels=['exit_{}'.format(exit)]\n",
    "        for i, output_ID in enumerate(_ID): \n",
    "            Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "            if threshold:\n",
    "                if type(threshold) is list:\n",
    "                    if i >= len(threshold): #no threshold in the array so treat as None.\n",
    "                        continue\n",
    "                    _threshold = threshold[i]\n",
    "                    print(\"threshold\",_threshold)\n",
    "                else:\n",
    "                    _threshold = threshold\n",
    "                if _threshold == \"mean\":\n",
    "                    Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                    _threshold = np.array(Correct[metric]).mean()\n",
    "                if _threshold == \"gmean\":\n",
    "                    AUC_thresholds = calc_AUC(output_ID, metrics=metric, plot = False)\n",
    "                    _threshold = AUC_thresholds[j]\n",
    "                if _threshold == \"PR_AUC\":\n",
    "                    precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                    _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                else:\n",
    "                    _threshold = np.float32(_threshold)\n",
    "            if len(rollOver_ID_indices)>0:\n",
    "                output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "            \n",
    "            legend = [\"Branch Threshold\",\"Correct ID Predictions\",\"Incorrect ID Predictions\"]\n",
    "            Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "            Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "            if plot:\n",
    "                _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                plt.title(metric.capitalize() + \" Outliers\", weight=\"bold\")\n",
    "                # plt.legend(legend)\n",
    "                plt.xlabel(metric.capitalize() + \" Score\", weight=\"bold\")\n",
    "                plt.ylabel(\"Frequency\", weight=\"bold\")\n",
    "                plt.legend(legend,frameon=True)\n",
    "                ## arrow annotation\n",
    "                if lessThanMetrics:\n",
    "                    ymax = plt.gca().get_ylim()\n",
    "                    xmax = plt.gca().get_xlim()\n",
    "                    ywidth = abs(ymax[0] - ymax[1])\n",
    "                    xwidth = abs(xmax[0] - xmax[1])\n",
    "                    plt.text(max(_threshold- xwidth/4,xmax[0]) , (ywidth/1.5) + ywidth/60 ,\"Accepted Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold - xwidth/4, ywidth/1.5), xytext=(_threshold, ywidth/1.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                    plt.text(min(_threshold + xwidth/80,xmax[1]), (ywidth/2)+ ywidth/60,\"Rejected Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold + xwidth/4, ywidth/2), xytext=(_threshold, ywidth/2),  arrowprops=dict(arrowstyle=\"->\"))\n",
    "                else:\n",
    "                    plt.annotate(\"\", xy=(_threshold, 100), xytext=(_threshold, 0), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                plt.show()\n",
    "            if main_exit_included and i == len(_ID)-1 :\n",
    "                Exit_Name.append(\"Main_exit\")\n",
    "                _threshold\n",
    "                if plot:\n",
    "                    print(\"main_exit\")\n",
    "                ID_accepted = output_ID\n",
    "                ID_rejected = None\n",
    "                accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                rejected_correct = None\n",
    "                accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                rejected_incorrect = None\n",
    "                accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                overall_accepted_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                _threshold = \"NA\"\n",
    "            else:\n",
    "                if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                else: ### metrics that require greater than metric\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                rollOver_ID_indices = ID_rejected.index\n",
    "                if i >= len(exit_labels):\n",
    "                    exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                print(exit_labels)\n",
    "                Exit_Name.append(exit_labels[i])\n",
    "                \n",
    "            Thresholds.append(_threshold)\n",
    "            \n",
    "            Results.append(accepted_correct + accepted_incorrect)\n",
    "            Input_ID.append(len(output_ID))\n",
    "            Accepted_ID_list.append(len(ID_accepted))\n",
    "            Accepted_Accuracy.append((len(accepted_correct)/len(ID_accepted)))\n",
    "            Acceptance_correct.append(len(accepted_correct))\n",
    "            if type(ID_rejected) is not type(None):\n",
    "                Rejected_Input.append(len(ID_rejected)/len(output_ID))\n",
    "            else:\n",
    "                Rejected_Input.append(0)\n",
    "            Accepted_Ratio.append(len(ID_accepted)/len(output_ID))\n",
    "            \n",
    "        df = pd.DataFrame({\n",
    "        \"Exit_Name\":Exit_Name,\n",
    "        \"ID_Inputs\":Input_ID,\n",
    "        \"Test_Accuracy\":Test_accuracy,\n",
    "        \"Threshold\":Thresholds,\n",
    "        \"Accepted_Input\":Accepted_ID_list,\n",
    "        \"Accepted_Correct\":Acceptance_correct,\n",
    "        \"Accepted_Accuracy\":Accepted_Accuracy,\n",
    "        \"Rejected_Input\":Rejected_Input,\n",
    "        \"Accepted %\": Accepted_Ratio,\n",
    "                        })\n",
    "        with pd.option_context('expand_frame_repr', False):\n",
    "            print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  Test_Accuracy Threshold  Accepted Input  Accepted_Correct  Accepted Accuracy  Rejected Input  Accepted %\n",
      "0     exit_1      10000         0.7730  0.674982            6003              5560           0.926204        0.399700    0.600300\n",
      "1     exit_2       3997         0.7914  0.411693            1243              1017           0.818182        0.689017    0.310983\n",
      "2  Main_exit       2754         0.7993        NA            2754              1537           0.558097        0.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "#SD adam optimizer\n",
    "EvaluateID(output_ID,metrics=[\"entropy\"], threshold=\"gmean\", exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  Test_Accuracy Threshold  Accepted_Input  Accepted_Correct  Accepted_Accuracy  Rejected_Input  Accepted %\n",
      "0     exit_1      10000         0.7839  0.414696            6168              5780           0.937095        0.383200    0.616800\n",
      "1     exit_2       3832         0.8017   0.32181            1265              1033           0.816601        0.669885    0.330115\n",
      "2  Main_exit       2567         0.8097        NA            2567              1368           0.532918        0.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "#SD sgd optimizer\n",
    "EvaluateID(output_ID,metrics=[\"entropy\"], threshold=\"gmean\", exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateOOD(ID,OOD,metrics=[\"energy\"], threshold=None, exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1']):\n",
    "    '''\n",
    "    Build an evaluation plot of the branched model's performance on ID and OOD datasets.\n",
    "\n",
    "    ::Variables::\n",
    "    ID: in-distribution dataset\n",
    "    OOD: out of distribution dataset\n",
    "    metrics: list of strings of metrics to evaluate branch results with. can be any of the following: [\"gmean\", \"mean\", \"PR_AUC\"]\n",
    "    exit: #if a specific exit number is specified, only output the results of that exit. counts from 0 - N, with 0 being the main exit. -1 returns all exits\n",
    "    legend: specify a legend to use for the plot\n",
    "    main_exit_included: specify if the last exit must answer all inputs recieved, if False, it will use the threshold to accept and reject inputs\n",
    "    plot: choose to produce a plot or just the table of branch results\n",
    "    exit_labels: what labels to use for the exits, defaults to \"exit_N\" \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for j, metric in enumerate(metrics):\n",
    "        print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "        rollOver_ID_indices = pd.Index([])\n",
    "        rollOver_OOD_indices = pd.Index([])\n",
    "        Exit_Name=[]\n",
    "        _ID = ID.copy()\n",
    "        _OOD = OOD.copy()\n",
    "        _ID.append(_ID.pop(0))\n",
    "        _OOD.append(_OOD.pop(0))\n",
    "        Accepted_df = pd.DataFrame()\n",
    "        Input_ID=[]\n",
    "        Input_OOD=[]\n",
    "        Accepted_list =[]\n",
    "        Accepted_ID_list = []\n",
    "        Accepted_OOD_list = []\n",
    "        Acceptance_correct =[]\n",
    "        Input_predictions =[]\n",
    "        Accepted_Ratio_list=[]\n",
    "        Accepted_Accuracy_list=[]\n",
    "        Branch_flops = []\n",
    "        Thresholds=[]\n",
    "        Test_accuracy =[]\n",
    "        Rollover_accuracy=[]\n",
    "        Results=[]\n",
    "        \n",
    "        if exit > 0: #if a specific exit number is specified, only output the results of that exit.\n",
    "            _ID = [_ID[max(exit-1,0)]]\n",
    "            _OOD = [_OOD[max(exit-1,0)]]\n",
    "            exit_labels=['exit_{}'.format(exit)]\n",
    "        for i, (output_ID, output_OOD) in enumerate(zip(_ID, _OOD)): \n",
    "            Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "            if threshold:\n",
    "                if type(threshold) is list:\n",
    "                    if i >= len(threshold): #no threshold in the array so treat as None.\n",
    "                        continue\n",
    "                    _threshold = threshold[i]\n",
    "                    print(\"threshold\",_threshold)\n",
    "                else:\n",
    "                    _threshold = threshold\n",
    "                if _threshold == \"mean\":\n",
    "                    Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                    _threshold = np.array(Correct[metric]).mean()\n",
    "                if _threshold == \"gmean\":\n",
    "                    AUC_thresholds = evaluate.calc_AUC(output_ID, metrics=metric, plot = False)\n",
    "                    _threshold = AUC_thresholds[j]\n",
    "                if _threshold == \"PR_AUC\":\n",
    "                    precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                    _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                else:\n",
    "                    _threshold = np.float32(_threshold)\n",
    "\n",
    "            if len(rollOver_ID_indices)>0:\n",
    "                # print(\"rollover enabled, {} ID predictions provided\".format(len(rollOver_ID_indices)))\n",
    "                output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "            if len(rollOver_OOD_indices)>0:\n",
    "                # if plot:\n",
    "                # print(\"rollover enabled, {} OOD predictions provided\".format(len(rollOver_OOD_indices)))\n",
    "                output_OOD = output_OOD.iloc[rollOver_OOD_indices]\n",
    "            \n",
    "            legend = [\"Branch Threshold\",\"Correct ID Predictions\",\"Incorrect ID Predictions\", \"OOD Inputs\"]\n",
    "            Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "            Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "            if plot:\n",
    "                \n",
    "                _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(output_OOD[metric].tolist(), bins=100,color=\"grey\",alpha=0.5)  # arguments are passed to np.histogram\n",
    "\n",
    "            if plot:\n",
    "                plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                plt.title(metric.capitalize() + \" Outliers\", weight=\"bold\")\n",
    "                # plt.legend(legend)\n",
    "                plt.xlabel(metric.capitalize() + \" Score\", weight=\"bold\")\n",
    "                plt.ylabel(\"Frequency\", weight=\"bold\")\n",
    "                plt.legend(legend,frameon=True)\n",
    "                \n",
    "                ## arrow annotation\n",
    "                if lessThanMetrics:\n",
    "                    ymax = plt.gca().get_ylim()\n",
    "                    xmax = plt.gca().get_xlim()\n",
    "                    ywidth = abs(ymax[0] - ymax[1])\n",
    "                    xwidth = abs(xmax[0] - xmax[1])\n",
    "                    print(ymax, ywidth)\n",
    "                    print(xmax, _threshold- xmax[1]/10 )\n",
    "                    \n",
    "                    plt.text(max(_threshold- xwidth/4,xmax[0]) , (ywidth/1.5) + ywidth/60 ,\"Accepted Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold - xwidth/4, ywidth/1.5), xytext=(_threshold, ywidth/1.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                    plt.text(min(_threshold + xwidth/80,xmax[1]), (ywidth/2)+ ywidth/60,\"Rejected Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold + xwidth/4, ywidth/2), xytext=(_threshold, ywidth/2),  arrowprops=dict(arrowstyle=\"->\"))\n",
    "                else:\n",
    "                    plt.annotate(\"\", xy=(_threshold, 100), xytext=(_threshold, 0), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                plt.show()\n",
    "            if main_exit_included and i == len(_ID)-1 :\n",
    "                Exit_Name.append(\"Main_exit\")\n",
    "                _threshold\n",
    "                if plot:\n",
    "                    print(\"main_exit\")\n",
    "                OOD_accepted = output_OOD\n",
    "                OOD_rejected = None\n",
    "                ID_accepted = output_ID\n",
    "                ID_rejected = None\n",
    "                accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                rejected_correct = None\n",
    "                accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                rejected_incorrect = None\n",
    "                accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                _threshold = \"NA\"\n",
    "            else:\n",
    "                if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() <= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() > _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                else: ### metrics that require greater than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() >= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() < _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                rollOver_ID_indices = ID_rejected.index\n",
    "                rollOver_OOD_indices = OOD_rejected.index\n",
    "                if i >= len(exit_labels):\n",
    "                    exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                print(exit_labels)\n",
    "                Exit_Name.append(exit_labels[i])\n",
    "            Thresholds.append(_threshold)\n",
    "            \n",
    "            Results.append(accepted_correct + accepted_incorrect)\n",
    "            Input_ID.append(len(output_ID))\n",
    "            Input_OOD.append(len(output_OOD))\n",
    "            Accepted_ID_list.append(len(ID_accepted))\n",
    "            Accepted_OOD_list.append(len(OOD_accepted))\n",
    "            Accepted_Ratio_list.append(len(ID_accepted)/(len(ID_accepted) + len(OOD_accepted)))\n",
    "            Acceptance_correct.append(len(accepted_correct))\n",
    "            Accepted_Accuracy_list.append(overall_accepted_acc)\n",
    "        df = pd.DataFrame({\n",
    "        \"Exit_Name\":Exit_Name,\n",
    "        \"ID_Inputs\":Input_ID,\n",
    "        \"OOD_Inputs\":Input_OOD,\n",
    "        \"Test_Accuracy\":Test_accuracy,\n",
    "        # \"RollOver_Accuracy\":Rollover_accuracy,\n",
    "        \"Threshold\":Thresholds,\n",
    "        \"Accepted ID\":Accepted_ID_list,\n",
    "        \"Accepted OOD\":Accepted_OOD_list,\n",
    "            \n",
    "        \"Accepted_Correct\":Acceptance_correct,\n",
    "        \"Accepted_ID_Ratio\":Accepted_Ratio_list,\n",
    "        \"Acceptance_Accuracy\":Accepted_Accuracy_list,\n",
    "\n",
    "        # \"Flops\":Branch_flops,\n",
    "        # \"Cost Ratio\":,                                  \n",
    "                        })\n",
    "        with pd.option_context('expand_frame_repr', False):\n",
    "            print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "entropy  lr_auc 0.1851665014322264 Best Threshold=3.2169156074523926, G-Mean=0.7438669421517965, TPR=0.7729468599033816, FPR=0.2841189267585207\n",
      "['exit_1']\n",
      "entropy  lr_auc 0.15083821891144336 Best Threshold=3.216921091079712, G-Mean=0.7772581912673745, TPR=0.8258746948738812, FPR=0.2684964200477327\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.17654578571077134 Best Threshold=3.2195048332214355, G-Mean=0.753350748265277, TPR=0.815243415802075, FPR=0.30384307445956765\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.6895  3.216916         5642          2922              4936           0.658804             0.576366\n",
      "1     exit_2       4358        7078         0.7542  3.216921         1587          1311              1341           0.547619             0.462733\n",
      "2  Main_exit       2771        5767         0.7494        NA         2771          5767              1374           0.324549             0.160928\n"
     ]
    }
   ],
   "source": [
    "#Branching\n",
    "evaluate.buildCompareDistribPlot(output_ID,output_OOD,metrics=[\"entropy\"], threshold=\"gmean\",  legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=False,exit_labels=['exit_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "entropy  lr_auc 0.1745180817264434 Best Threshold=0.2529903054237366, G-Mean=0.7519762116695488, TPR=0.7970600244997958, FPR=0.29055754204741097\n",
      "['exit_1']\n",
      "entropy  lr_auc 0.1611685337555885 Best Threshold=0.3943634331226349, G-Mean=0.7656904359381372, TPR=0.7859262399321747, FPR=0.25402434236356497\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.14933635380085053 Best Threshold=3.2343547344207764, G-Mean=0.7792128893780099, TPR=0.8186679630529898, FPR=0.2583406773259474\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.7551   0.25299         5855          2361              5357           0.712634             0.652020\n",
      "1     exit_2       4145        7639         0.7641  0.394363         1436          1416              1142           0.503506             0.400421\n",
      "2  Main_exit       2709        6223         0.7943        NA         2709          6223              1471           0.303292             0.164689\n"
     ]
    }
   ],
   "source": [
    "#BSD\n",
    "evaluate.buildCompareDistribPlot(output_ID,output_OOD,metrics=[\"entropy\"], threshold=\"gmean\",  legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=False,exit_labels=['exit_1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "632aef774cc0760417fa29704a5cf9562c90ea600d77237eb2969e3f571ea566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
