{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = tf.keras.models.clone_model(student)\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            student_loss = student_loss #* self.alpha\n",
    "            distillation_loss = (distillation_loss *1000) #* (1 - self.alpha)\n",
    "            #loss = self.alpha * student_loss + ((1 - self.alpha) * (distillation_loss *1000))\n",
    "            loss=student_loss +distillation_loss\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227), include_targets=False, categorical=True)\n",
    "train_ds, test_ds, validation_ds = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 4s 13ms/step - loss: 0.6905 - accuracy: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6905280947685242, 0.7939703464508057]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_teacher = tf.keras.models.load_model(\"models/alexNetv6_logits_teacher.hdf5\")\n",
    "model_teacher.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the student model with the teacher model supplying additional loss signals.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(227,227,3))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(10, activation='softmax')(x)\n",
    "student = keras.Model(inputs=(inputs), outputs=[x], name=\"alexnet\")\n",
    "student.compile( loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "            optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "            metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "student.save(\"student.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt  1\n",
      "312/312 [==============================] - 4s 14ms/step - loss: 7.1167 - categorical_accuracy: 0.0780\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 89s 53ms/step - loss: 1.7467 - categorical_accuracy: 0.4096 - val_loss: 1.2503 - val_categorical_accuracy: 0.5573\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 1.2556 - categorical_accuracy: 0.5479 - val_loss: 1.3371 - val_categorical_accuracy: 0.5403\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 1.0625 - categorical_accuracy: 0.6236 - val_loss: 1.0110 - val_categorical_accuracy: 0.6354\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 90s 54ms/step - loss: 0.9296 - categorical_accuracy: 0.6709 - val_loss: 1.1506 - val_categorical_accuracy: 0.6042\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 88s 52ms/step - loss: 0.8296 - categorical_accuracy: 0.7064 - val_loss: 0.8810 - val_categorical_accuracy: 0.6941\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.7438 - categorical_accuracy: 0.7396 - val_loss: 0.7549 - val_categorical_accuracy: 0.7382\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 0.7690 - categorical_accuracy: 0.7338\n",
      "attempt  2\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 7.1167 - categorical_accuracy: 0.0780\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 85s 50ms/step - loss: 1.7869 - categorical_accuracy: 0.3951 - val_loss: 1.3295 - val_categorical_accuracy: 0.5292\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 84s 50ms/step - loss: 1.3001 - categorical_accuracy: 0.5359 - val_loss: 1.1225 - val_categorical_accuracy: 0.6174\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 84s 50ms/step - loss: 1.1117 - categorical_accuracy: 0.6024 - val_loss: 1.0919 - val_categorical_accuracy: 0.6138\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.9646 - categorical_accuracy: 0.6582 - val_loss: 1.2377 - val_categorical_accuracy: 0.5843\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.8517 - categorical_accuracy: 0.6964 - val_loss: 1.0270 - val_categorical_accuracy: 0.6458\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.7552 - categorical_accuracy: 0.7323 - val_loss: 0.8211 - val_categorical_accuracy: 0.7167\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 0.8599 - categorical_accuracy: 0.7067\n",
      "attempt  3\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 7.1167 - categorical_accuracy: 0.0780\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 1.7809 - categorical_accuracy: 0.3960 - val_loss: 1.2800 - val_categorical_accuracy: 0.5447\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 1.3109 - categorical_accuracy: 0.5286 - val_loss: 1.1444 - val_categorical_accuracy: 0.6010\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 1.1193 - categorical_accuracy: 0.6012 - val_loss: 1.1212 - val_categorical_accuracy: 0.6106\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.9747 - categorical_accuracy: 0.6561 - val_loss: 0.9098 - val_categorical_accuracy: 0.6835\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 86s 52ms/step - loss: 0.8657 - categorical_accuracy: 0.6917 - val_loss: 0.8970 - val_categorical_accuracy: 0.6795\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 86s 52ms/step - loss: 0.7734 - categorical_accuracy: 0.7277 - val_loss: 0.8236 - val_categorical_accuracy: 0.7137\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 0.8146 - categorical_accuracy: 0.7140\n",
      "attempt  4\n",
      "312/312 [==============================] - 4s 14ms/step - loss: 7.1167 - categorical_accuracy: 0.0780\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 87s 52ms/step - loss: 1.7789 - categorical_accuracy: 0.3952 - val_loss: 1.3110 - val_categorical_accuracy: 0.5359\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 1.3081 - categorical_accuracy: 0.5326 - val_loss: 1.1291 - val_categorical_accuracy: 0.5990\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 1.1158 - categorical_accuracy: 0.6026 - val_loss: 1.1074 - val_categorical_accuracy: 0.6108\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 0.9731 - categorical_accuracy: 0.6536 - val_loss: 0.9397 - val_categorical_accuracy: 0.6711\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 87s 52ms/step - loss: 0.8570 - categorical_accuracy: 0.6963 - val_loss: 0.8438 - val_categorical_accuracy: 0.7041\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 0.7664 - categorical_accuracy: 0.7304 - val_loss: 0.8005 - val_categorical_accuracy: 0.7204\n",
      "312/312 [==============================] - 4s 14ms/step - loss: 0.8102 - categorical_accuracy: 0.7243\n",
      "attempt  5\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 7.1167 - categorical_accuracy: 0.0780\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 87s 52ms/step - loss: 1.8014 - categorical_accuracy: 0.3901 - val_loss: 1.3874 - val_categorical_accuracy: 0.5108\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 89s 54ms/step - loss: 1.3186 - categorical_accuracy: 0.5275 - val_loss: 1.4315 - val_categorical_accuracy: 0.4938\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 94s 57ms/step - loss: 1.1269 - categorical_accuracy: 0.5992 - val_loss: 1.1005 - val_categorical_accuracy: 0.6062\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 96s 58ms/step - loss: 0.9865 - categorical_accuracy: 0.6508 - val_loss: 1.0409 - val_categorical_accuracy: 0.6354\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 96s 58ms/step - loss: 0.8773 - categorical_accuracy: 0.6886 - val_loss: 0.8689 - val_categorical_accuracy: 0.6937\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 104s 64ms/step - loss: 0.7790 - categorical_accuracy: 0.7249 - val_loss: 0.7628 - val_categorical_accuracy: 0.7380\n",
      "312/312 [==============================] - 5s 15ms/step - loss: 0.7635 - categorical_accuracy: 0.7336\n"
     ]
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "for i in range(5):\n",
    "    print(\"attempt \",i+1)\n",
    "\n",
    "\n",
    "# for i in range (10):\n",
    "    student_copy = tf.keras.models.load_model(\"student.hdf5\")\n",
    "    # student_copy.compile( loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    #         optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "    #         metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "    #     )\n",
    "    student_copy.evaluate(test_ds)\n",
    "    student_copy.fit(train_ds,validation_data = validation_ds, epochs=6,verbose=1)\n",
    "    student_copy.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 4s 14ms/step - loss: 7.1469 - categorical_accuracy: 0.0793\n",
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 89s 52ms/step - loss: 1.7696 - categorical_accuracy: 0.3982 - val_loss: 1.3803 - val_categorical_accuracy: 0.5078\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 87s 51ms/step - loss: 1.2896 - categorical_accuracy: 0.5401 - val_loss: 1.2661 - val_categorical_accuracy: 0.5561\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 86s 52ms/step - loss: 1.1046 - categorical_accuracy: 0.6055 - val_loss: 1.0094 - val_categorical_accuracy: 0.6466\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 86s 51ms/step - loss: 0.9591 - categorical_accuracy: 0.6612 - val_loss: 1.1284 - val_categorical_accuracy: 0.6112\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 84s 50ms/step - loss: 0.8531 - categorical_accuracy: 0.7000 - val_loss: 0.8965 - val_categorical_accuracy: 0.6851\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 85s 51ms/step - loss: 0.7630 - categorical_accuracy: 0.7308 - val_loss: 0.8025 - val_categorical_accuracy: 0.7210\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 0.8252 - categorical_accuracy: 0.7164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8251988291740417, 0.7164463400840759]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "# for i in range(3):\n",
    "\n",
    "\n",
    "\n",
    "# for i in range (10):\n",
    "loaded_student = tf.keras.models.load_model(\"student.hdf5\")\n",
    "student_copy = loaded_student\n",
    "student_copy.compile( loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "        metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "    )\n",
    "student_copy.evaluate(test_ds)\n",
    "student_copy.fit(train_ds,validation_data = validation_ds, epochs=6,verbose=1)\n",
    "student_copy.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createDistiller(alpha=1):\n",
    "    loaded_student = tf.keras.models.load_model(\"student.hdf5\")\n",
    "    distiller = Distiller(student=loaded_student, teacher=model_teacher)\n",
    "    distiller.compile(\n",
    "        optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "        metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "        student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "\n",
    "        distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "        alpha=0.1,\n",
    "        temperature=10,\n",
    "    )\n",
    "    return distiller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 123s 64ms/step - categorical_accuracy: 0.3330 - student_loss: 1.7594 - distillation_loss: 0.3424 - val_categorical_accuracy: 0.5531 - val_student_loss: 1.5255\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 93s 56ms/step - categorical_accuracy: 0.5348 - student_loss: 1.2696 - distillation_loss: 0.2561 - val_categorical_accuracy: 0.6012 - val_student_loss: 1.6228\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 93s 57ms/step - categorical_accuracy: 0.6117 - student_loss: 1.0755 - distillation_loss: 0.2148 - val_categorical_accuracy: 0.6550 - val_student_loss: 1.6163\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 95s 58ms/step - categorical_accuracy: 0.6681 - student_loss: 0.9364 - distillation_loss: 0.1850 - val_categorical_accuracy: 0.6591 - val_student_loss: 1.5364\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 94s 57ms/step - categorical_accuracy: 0.7059 - student_loss: 0.8237 - distillation_loss: 0.1609 - val_categorical_accuracy: 0.7342 - val_student_loss: 1.4752\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 94s 57ms/step - categorical_accuracy: 0.7413 - student_loss: 0.7407 - distillation_loss: 0.1424 - val_categorical_accuracy: 0.7484 - val_student_loss: 1.3604\n",
      "312/312 [==============================] - 4s 13ms/step - categorical_accuracy: 0.7399 - student_loss: 0.7532\n",
      "results:  [0.7398838400840759, 1.142507791519165]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(6):\n",
    "# print(\"run: \",i+1)\n",
    "distiller = createDistiller(0.3)\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=6,verbose=1)\n",
    "# Evaluate student on test dataset\n",
    "print(\"results: \",distiller.evaluate(test_ds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 100s 60ms/step - categorical_accuracy: 0.3229 - student_loss: 1.7962 - distillation_loss: 0.3497 - val_categorical_accuracy: 0.4838 - val_student_loss: 1.6217\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 99s 60ms/step - categorical_accuracy: 0.5199 - student_loss: 1.2901 - distillation_loss: 0.2617 - val_categorical_accuracy: 0.4451 - val_student_loss: 2.3735\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 100s 61ms/step - categorical_accuracy: 0.6002 - student_loss: 1.0906 - distillation_loss: 0.2181 - val_categorical_accuracy: 0.6661 - val_student_loss: 1.5698\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 99s 60ms/step - categorical_accuracy: 0.6634 - student_loss: 0.9341 - distillation_loss: 0.1840 - val_categorical_accuracy: 0.6767 - val_student_loss: 1.4279\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 101s 62ms/step - categorical_accuracy: 0.7107 - student_loss: 0.8198 - distillation_loss: 0.1594 - val_categorical_accuracy: 0.7434 - val_student_loss: 1.1230\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 102s 63ms/step - categorical_accuracy: 0.7454 - student_loss: 0.7290 - distillation_loss: 0.1397 - val_categorical_accuracy: 0.7370 - val_student_loss: 1.3668\n",
      "312/312 [==============================] - 4s 14ms/step - categorical_accuracy: 0.7331 - student_loss: 0.7799\n",
      "results:  [0.7330729365348816, 1.0371853113174438]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(6):\n",
    "# print(\"run: \",i+1)\n",
    "distiller = createDistiller()\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=6,verbose=1)\n",
    "# Evaluate student on test dataset\n",
    "print(\"results: \",distiller.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_student = tf.keras.models.load_model(\"student.hdf5\")\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "    student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the same student model without the teacher\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1406/1406 [==============================] - 79s 46ms/step - loss: 2.2295 - categorical_accuracy: 0.3287\n",
      "Epoch 2/6\n",
      "1406/1406 [==============================] - 79s 47ms/step - loss: 1.3622 - categorical_accuracy: 0.5138\n",
      "Epoch 3/6\n",
      "1406/1406 [==============================] - 80s 47ms/step - loss: 1.1460 - categorical_accuracy: 0.5923\n",
      "Epoch 4/6\n",
      "1406/1406 [==============================] - 79s 47ms/step - loss: 0.9913 - categorical_accuracy: 0.6485\n",
      "Epoch 5/6\n",
      "1406/1406 [==============================] - 80s 47ms/step - loss: 0.8587 - categorical_accuracy: 0.6945\n",
      "Epoch 6/6\n",
      "1406/1406 [==============================] - 80s 47ms/step - loss: 0.7676 - categorical_accuracy: 0.7273\n",
      "312/312 [==============================] - 4s 13ms/step - loss: 1.0059 - categorical_accuracy: 0.6460\n",
      "results:  [1.0058716535568237, 0.6460336446762085]\n"
     ]
    }
   ],
   "source": [
    "# Train student as doen usually\n",
    "# for i in range(6):\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(10, activation='softmax')(x)\n",
    "student_scratch = keras.Model(inputs=(inputs), outputs=[x], name=\"alexnet\")\n",
    "\n",
    "student_scratch.compile(\n",
    "    optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.CategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# Train and evaluate student trained from scratch.\n",
    "student_scratch.fit(train_ds, epochs=6,verbose=1)\n",
    "#     student_scratch.evaluate(x_test, y_test)\n",
    "print(\"results: \",student_scratch.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from running: <br>\n",
    "1 [0.5782251358032227, 1.4982712268829346] <br>\n",
    "2 [1.342477798461914, 0.5252403616905212] <br>\n",
    "3 0.5658053159713745 <br>\n",
    "4 0.5724158883094788 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 4s 13ms/step - loss: 1.6139 - categorical_accuracy: 0.3922\n",
      "results:  [1.6138664484024048, 0.39222756028175354]\n"
     ]
    }
   ],
   "source": [
    "print(\"results: \",student_scratch.evaluate(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8590\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1038 - sparse_categorical_accuracy: 0.9688\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9750\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06662680953741074, 0.9783999919891357]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_2 = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(16, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
    "        layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "student_2.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "# Train and evaluate student trained from scratch.\n",
    "student_2.fit(x_train, y_train, epochs=3)\n",
    "student_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
