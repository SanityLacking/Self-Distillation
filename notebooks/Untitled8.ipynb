{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a6f9f0-b098-4ffb-a1c3-b6a65797e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from  tensorflow import keras \n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import brevis\n",
    "from brevis import branches\n",
    "from brevis import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16855547-e209-4cde-a40f-2a8753a74026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, validation_ds = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa03ec5-a0a6-4bea-afb7-7bcfbcb27a6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preset: Other\n",
      "Model: \"alexnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       147840    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 256)       98560     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " main_path124 (Dense)        (None, 124)               508028    \n",
      "                                                                 \n",
      " main_path64 (Dense)         (None, 64)                8000      \n",
      "                                                                 \n",
      " exit (Dense)                (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,056,134\n",
      "Trainable params: 40,053,382\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanity\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# ### first branch\n",
    "\n",
    "\n",
    "# branch_exit = Branch(tf.compat.v1.get_default_graph().unique_name(\"branch_e\"))(x,targets)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"main_path124\"))(x)\n",
    "x = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"main_path64\"))(x)\n",
    "x = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"exit\"))(x)\n",
    "\n",
    "\n",
    "# model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "model = brevis.BranchModel(inputs=(inputs), outputs=[x], name=\"alexnet\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "# student_model.save(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# model.fit(train_ds, validation_ds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99dfdc5-a7a3-4680-a373-90cf11cf393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  max_pooling2d\n",
      "add Branch to branch point  max_pooling2d_1\n",
      "add Branch to branch point  dense\n",
      "branch added <brevis.core_v2.BranchModel object at 0x0000018213352BC8>\n",
      "branch_softmax :  True\n",
      "branch_softmax_1 :  True\n",
      "branch_softmax_2 :  True\n",
      "\n",
      "preset: Other\n",
      "Model: \"alexnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 227, 227, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 55, 55, 96)   34944       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 55, 55, 96)  384         ['conv2d_1[0][0]']               \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 27, 27, 96)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 27, 27, 256)  614656      ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 27, 27, 256)  1024       ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 256)  0          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 13, 13, 384)  885120      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 13, 13, 384)  1536       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 13, 13, 384)  147840      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 13, 13, 384)  1536       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 13, 13, 256)  98560       ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 13, 13, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 256)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 9216)         0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4096)         37752832    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4096)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " branch_flatten (Flatten)       (None, 69984)        0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " branch_flatten_1 (Flatten)     (None, 43264)        0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " branch_flatten_2 (Flatten)     (None, 4096)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4096)         16781312    ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " branch124 (Dense)              (None, 124)          8678140     ['branch_flatten[0][0]']         \n",
      "                                                                                                  \n",
      " branch124_1 (Dense)            (None, 124)          5364860     ['branch_flatten_1[0][0]']       \n",
      "                                                                                                  \n",
      " branch124_2 (Dense)            (None, 124)          508028      ['branch_flatten_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4096)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " branch64 (Dense)               (None, 64)           8000        ['branch124[0][0]']              \n",
      "                                                                                                  \n",
      " targets (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " branch64_1 (Dense)             (None, 64)           8000        ['branch124_1[0][0]']            \n",
      "                                                                                                  \n",
      " branch64_2 (Dense)             (None, 64)           8000        ['branch124_2[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           40970       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " branch_softmax (CrossEntropyEn  (None, 10)          640         ['branch64[0][0]',               \n",
      " dpoint)                                                          'targets[0][0]']                \n",
      "                                                                                                  \n",
      " branch_softmax_1 (CrossEntropy  (None, 10)          640         ['branch64_1[0][0]',             \n",
      " Endpoint)                                                        'targets[0][0]']                \n",
      "                                                                                                  \n",
      " branch_softmax_2 (CrossEntropy  (None, 10)          640         ['branch64_2[0][0]',             \n",
      " Endpoint)                                                        'targets[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70,938,686\n",
      "Trainable params: 70,935,934\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "brevisModel = (brevis.BranchModel(name=\"../models/alexNetv6_logits.hdf5\", custom_objects={})\n",
    "            .add_branches(branches.branch.newBranch_flatten_evidence,\n",
    "                          [\"max_pooling2d\",\n",
    "                            \"max_pooling2d_1\",\n",
    "                            \"dense\"],\n",
    "                          target_input=True,loop=False)\n",
    "            )\n",
    "brevisModel.compile(loss=loss_fn, optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")\n",
    "brevisModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9834e210-e95e-470a-9adc-7f3ecbcff706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 7.6283 - dense_2_loss: 2.2712 - branch_softmax_3_loss: 1.4688 - branch_softmax_4_loss: 1.2005 - branch_softmax_5_loss: 0.4167 - dense_2_1_loss: 2.2711 - dense_2_accuracy: 0.9147 - branch_softmax_3_accuracy: 0.4910 - branch_softmax_4_accuracy: 0.5878 - branch_softmax_5_accuracy: 0.8711 - dense_2_1_accuracy: 0.9148 - branch_softmax_3_evidence: 0.0187 - branch_softmax_3_mean_ev_succ: 0.1993 - branch_softmax_3_mean_ev_fail: 0.1763 - branch_softmax_4_evidence: 0.0206 - branch_softmax_4_mean_ev_succ: 0.2430 - branch_softmax_4_mean_ev_fail: 0.1582 - branch_softmax_5_evidence: 0.1452 - branch_softmax_5_mean_ev_succ: 1.5817 - branch_softmax_5_mean_ev_fail: 0.4048\n",
      "Epoch 1: saving model to models\\alexnet_branched.hdf5.hdf5\n",
      "1406/1406 [==============================] - 278s 195ms/step - loss: 7.6283 - dense_2_loss: 2.2712 - branch_softmax_3_loss: 1.4688 - branch_softmax_4_loss: 1.2005 - branch_softmax_5_loss: 0.4167 - dense_2_1_loss: 2.2711 - dense_2_accuracy: 0.9147 - branch_softmax_3_accuracy: 0.4910 - branch_softmax_4_accuracy: 0.5878 - branch_softmax_5_accuracy: 0.8711 - dense_2_1_accuracy: 0.9148 - branch_softmax_3_evidence: 0.0187 - branch_softmax_3_mean_ev_succ: 0.1993 - branch_softmax_3_mean_ev_fail: 0.1763 - branch_softmax_4_evidence: 0.0206 - branch_softmax_4_mean_ev_succ: 0.2430 - branch_softmax_4_mean_ev_fail: 0.1582 - branch_softmax_5_evidence: 0.1452 - branch_softmax_5_mean_ev_succ: 1.5817 - branch_softmax_5_mean_ev_fail: 0.4048 - val_loss: 11.5752 - val_dense_2_loss: 3.0026 - val_branch_softmax_3_loss: 1.2837 - val_branch_softmax_4_loss: 1.2837 - val_branch_softmax_5_loss: 3.0026 - val_dense_2_1_loss: 3.0026 - val_dense_2_accuracy: 0.1012 - val_branch_softmax_3_accuracy: 0.5445 - val_branch_softmax_4_accuracy: 0.5445 - val_branch_softmax_5_accuracy: 0.1012 - val_dense_2_1_accuracy: 0.1012 - val_branch_softmax_3_evidence: 0.0062 - val_branch_softmax_3_mean_ev_succ: 0.0697 - val_branch_softmax_3_mean_ev_fail: 0.0540 - val_branch_softmax_4_evidence: 0.0000e+00 - val_branch_softmax_4_mean_ev_succ: 0.0000e+00 - val_branch_softmax_4_mean_ev_fail: 0.0000e+00 - val_branch_softmax_5_evidence: 0.0000e+00 - val_branch_softmax_5_mean_ev_succ: 0.0000e+00 - val_branch_softmax_5_mean_ev_fail: 0.0000e+00\n",
      "<keras.callbacks.History object at 0x0000026BB8B26588>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x26bd81cd2c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brevisModel.fit(train_ds,validation_ds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa7267c-6468-4361-bacd-7b4dfba0c495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 5.3521 - dense_2_loss: 2.2724 - branch_softmax_loss: 1.4721 - branch_softmax_1_loss: 1.1961 - branch_softmax_2_loss: 0.4114 - dense_2_accuracy: 0.9139 - branch_softmax_accuracy: 0.4911 - branch_softmax_1_accuracy: 0.5876 - branch_softmax_2_accuracy: 0.8696 - branch_softmax_evidence: 0.0235 - branch_softmax_mean_ev_succ: 0.2495 - branch_softmax_mean_ev_fail: 0.2198 - branch_softmax_1_evidence: 0.0202 - branch_softmax_1_mean_ev_succ: 0.2400 - branch_softmax_1_mean_ev_fail: 0.1494 - branch_softmax_2_evidence: 0.1329 - branch_softmax_2_mean_ev_succ: 1.4388 - branch_softmax_2_mean_ev_fail: 0.3764\n",
      "Epoch 1: saving model to models\\alexnet_branched.hdf5.hdf5\n",
      "1406/1406 [==============================] - 209s 144ms/step - loss: 5.3521 - dense_2_loss: 2.2724 - branch_softmax_loss: 1.4721 - branch_softmax_1_loss: 1.1961 - branch_softmax_2_loss: 0.4114 - dense_2_accuracy: 0.9139 - branch_softmax_accuracy: 0.4911 - branch_softmax_1_accuracy: 0.5876 - branch_softmax_2_accuracy: 0.8696 - branch_softmax_evidence: 0.0235 - branch_softmax_mean_ev_succ: 0.2495 - branch_softmax_mean_ev_fail: 0.2198 - branch_softmax_1_evidence: 0.0202 - branch_softmax_1_mean_ev_succ: 0.2400 - branch_softmax_1_mean_ev_fail: 0.1494 - branch_softmax_2_evidence: 0.1329 - branch_softmax_2_mean_ev_succ: 1.4388 - branch_softmax_2_mean_ev_fail: 0.3764 - val_loss: 9.7463 - val_dense_2_loss: 3.0026 - val_branch_softmax_loss: 3.0026 - val_branch_softmax_1_loss: 3.0026 - val_branch_softmax_2_loss: 0.7386 - val_dense_2_accuracy: 0.1012 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1012 - val_branch_softmax_2_accuracy: 0.7859 - val_branch_softmax_evidence: 0.0000e+00 - val_branch_softmax_mean_ev_succ: 0.0000e+00 - val_branch_softmax_mean_ev_fail: 0.0000e+00 - val_branch_softmax_1_evidence: 0.0000e+00 - val_branch_softmax_1_mean_ev_succ: 0.0000e+00 - val_branch_softmax_1_mean_ev_fail: 0.0000e+00 - val_branch_softmax_2_evidence: 0.1197 - val_branch_softmax_2_mean_ev_succ: 1.4795 - val_branch_softmax_2_mean_ev_fail: 0.1637\n",
      "<keras.callbacks.History object at 0x000001821AFA7E08>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x182026f2608>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "brevisModel.fit(train_ds,validation_ds,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa53a902-120f-4822-925d-d71a83c6c0e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "  1/312 [..............................] - ETA: 6:27 - loss: 14.0744 - exit_loss: 4.9234 - branch_softmax_loss: 9.1511 - exit_accuracy: 0.1250 - branch_softmax_accuracy: 0.0625input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "  3/312 [..............................] - ETA: 10s - loss: 13.0188 - exit_loss: 4.9445 - branch_softmax_loss: 8.0743 - exit_accuracy: 0.0625 - branch_softmax_accuracy: 0.1042 input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "  5/312 [..............................] - ETA: 10s - loss: 12.9640 - exit_loss: 5.0646 - branch_softmax_loss: 7.8994 - exit_accuracy: 0.0625 - branch_softmax_accuracy: 0.1063input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "  7/312 [..............................] - ETA: 10s - loss: 12.9893 - exit_loss: 5.1556 - branch_softmax_loss: 7.8337 - exit_accuracy: 0.0670 - branch_softmax_accuracy: 0.1161input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "  9/312 [..............................] - ETA: 10s - loss: 13.3499 - exit_loss: 5.4153 - branch_softmax_loss: 7.9346 - exit_accuracy: 0.0694 - branch_softmax_accuracy: 0.1007input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 11/312 [>.............................] - ETA: 10s - loss: 13.3383 - exit_loss: 5.3220 - branch_softmax_loss: 8.0163 - exit_accuracy: 0.0824 - branch_softmax_accuracy: 0.0966input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 13/312 [>.............................] - ETA: 10s - loss: 13.3373 - exit_loss: 5.4477 - branch_softmax_loss: 7.8896 - exit_accuracy: 0.0745 - branch_softmax_accuracy: 0.0986input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 15/312 [>.............................] - ETA: 10s - loss: 13.1478 - exit_loss: 5.3710 - branch_softmax_loss: 7.7768 - exit_accuracy: 0.0792 - branch_softmax_accuracy: 0.1021input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 17/312 [>.............................] - ETA: 10s - loss: 13.2700 - exit_loss: 5.3923 - branch_softmax_loss: 7.8777 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.0974input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 19/312 [>.............................] - ETA: 10s - loss: 13.2568 - exit_loss: 5.3820 - branch_softmax_loss: 7.8748 - exit_accuracy: 0.0822 - branch_softmax_accuracy: 0.0954input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 21/312 [=>............................] - ETA: 10s - loss: 13.2735 - exit_loss: 5.4414 - branch_softmax_loss: 7.8320 - exit_accuracy: 0.0789 - branch_softmax_accuracy: 0.0952input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 23/312 [=>............................] - ETA: 10s - loss: 13.1425 - exit_loss: 5.3936 - branch_softmax_loss: 7.7489 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.0978input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 25/312 [=>............................] - ETA: 10s - loss: 13.0793 - exit_loss: 5.3953 - branch_softmax_loss: 7.6840 - exit_accuracy: 0.0838 - branch_softmax_accuracy: 0.1013input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 27/312 [=>............................] - ETA: 10s - loss: 12.9008 - exit_loss: 5.3650 - branch_softmax_loss: 7.5358 - exit_accuracy: 0.0810 - branch_softmax_accuracy: 0.1100input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 29/312 [=>............................] - ETA: 9s - loss: 12.9370 - exit_loss: 5.3688 - branch_softmax_loss: 7.5682 - exit_accuracy: 0.0808 - branch_softmax_accuracy: 0.1078 input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 31/312 [=>............................] - ETA: 9s - loss: 12.9468 - exit_loss: 5.4088 - branch_softmax_loss: 7.5380 - exit_accuracy: 0.0806 - branch_softmax_accuracy: 0.1069input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 33/312 [==>...........................] - ETA: 9s - loss: 12.9532 - exit_loss: 5.3816 - branch_softmax_loss: 7.5716 - exit_accuracy: 0.0795 - branch_softmax_accuracy: 0.1023input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 35/312 [==>...........................] - ETA: 9s - loss: 12.9990 - exit_loss: 5.3748 - branch_softmax_loss: 7.6242 - exit_accuracy: 0.0768 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 37/312 [==>...........................] - ETA: 9s - loss: 12.9884 - exit_loss: 5.3810 - branch_softmax_loss: 7.6074 - exit_accuracy: 0.0760 - branch_softmax_accuracy: 0.1014input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 39/312 [==>...........................] - ETA: 9s - loss: 12.9878 - exit_loss: 5.3686 - branch_softmax_loss: 7.6191 - exit_accuracy: 0.0745 - branch_softmax_accuracy: 0.1002input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 41/312 [==>...........................] - ETA: 9s - loss: 13.0015 - exit_loss: 5.3869 - branch_softmax_loss: 7.6146 - exit_accuracy: 0.0739 - branch_softmax_accuracy: 0.0983input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 43/312 [===>..........................] - ETA: 9s - loss: 12.9972 - exit_loss: 5.4187 - branch_softmax_loss: 7.5785 - exit_accuracy: 0.0719 - branch_softmax_accuracy: 0.0974input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 45/312 [===>..........................] - ETA: 9s - loss: 12.9962 - exit_loss: 5.4351 - branch_softmax_loss: 7.5610 - exit_accuracy: 0.0743 - branch_softmax_accuracy: 0.0986input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 47/312 [===>..........................] - ETA: 9s - loss: 12.9487 - exit_loss: 5.4270 - branch_softmax_loss: 7.5218 - exit_accuracy: 0.0745 - branch_softmax_accuracy: 0.1011input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 49/312 [===>..........................] - ETA: 9s - loss: 12.8556 - exit_loss: 5.3765 - branch_softmax_loss: 7.4790 - exit_accuracy: 0.0772 - branch_softmax_accuracy: 0.1001input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 51/312 [===>..........................] - ETA: 9s - loss: 12.8203 - exit_loss: 5.3745 - branch_softmax_loss: 7.4459 - exit_accuracy: 0.0784 - branch_softmax_accuracy: 0.1005input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 53/312 [====>.........................] - ETA: 9s - loss: 12.8598 - exit_loss: 5.3636 - branch_softmax_loss: 7.4962 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1002input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 55/312 [====>.........................] - ETA: 9s - loss: 12.8616 - exit_loss: 5.3588 - branch_softmax_loss: 7.5028 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.0989input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 57/312 [====>.........................] - ETA: 9s - loss: 12.8506 - exit_loss: 5.3608 - branch_softmax_loss: 7.4898 - exit_accuracy: 0.0773 - branch_softmax_accuracy: 0.0992input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 59/312 [====>.........................] - ETA: 9s - loss: 12.8433 - exit_loss: 5.3577 - branch_softmax_loss: 7.4856 - exit_accuracy: 0.0768 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 61/312 [====>.........................] - ETA: 9s - loss: 12.8784 - exit_loss: 5.3824 - branch_softmax_loss: 7.4959 - exit_accuracy: 0.0763 - branch_softmax_accuracy: 0.0999input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 63/312 [=====>........................] - ETA: 8s - loss: 12.8564 - exit_loss: 5.3638 - branch_softmax_loss: 7.4925 - exit_accuracy: 0.0784 - branch_softmax_accuracy: 0.1012input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 65/312 [=====>........................] - ETA: 8s - loss: 12.8719 - exit_loss: 5.3540 - branch_softmax_loss: 7.5178 - exit_accuracy: 0.0769 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 67/312 [=====>........................] - ETA: 8s - loss: 12.8806 - exit_loss: 5.3719 - branch_softmax_loss: 7.5087 - exit_accuracy: 0.0765 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 69/312 [=====>........................] - ETA: 8s - loss: 12.9184 - exit_loss: 5.4035 - branch_softmax_loss: 7.5149 - exit_accuracy: 0.0774 - branch_softmax_accuracy: 0.0983input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 71/312 [=====>........................] - ETA: 8s - loss: 12.8977 - exit_loss: 5.3959 - branch_softmax_loss: 7.5018 - exit_accuracy: 0.0775 - branch_softmax_accuracy: 0.0982input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 73/312 [======>.......................] - ETA: 8s - loss: 12.9039 - exit_loss: 5.3997 - branch_softmax_loss: 7.5042 - exit_accuracy: 0.0775 - branch_softmax_accuracy: 0.0989input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 75/312 [======>.......................] - ETA: 8s - loss: 12.8912 - exit_loss: 5.3954 - branch_softmax_loss: 7.4958 - exit_accuracy: 0.0775 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 77/312 [======>.......................] - ETA: 8s - loss: 12.8962 - exit_loss: 5.3849 - branch_softmax_loss: 7.5113 - exit_accuracy: 0.0779 - branch_softmax_accuracy: 0.0986input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 79/312 [======>.......................] - ETA: 8s - loss: 12.9089 - exit_loss: 5.3927 - branch_softmax_loss: 7.5162 - exit_accuracy: 0.0783 - branch_softmax_accuracy: 0.0985input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 81/312 [======>.......................] - ETA: 8s - loss: 12.8917 - exit_loss: 5.3716 - branch_softmax_loss: 7.5201 - exit_accuracy: 0.0799 - branch_softmax_accuracy: 0.0976input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 83/312 [======>.......................] - ETA: 8s - loss: 12.8503 - exit_loss: 5.3513 - branch_softmax_loss: 7.4990 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.0979input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 85/312 [=======>......................] - ETA: 8s - loss: 12.8543 - exit_loss: 5.3559 - branch_softmax_loss: 7.4985 - exit_accuracy: 0.0805 - branch_softmax_accuracy: 0.0982input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 87/312 [=======>......................] - ETA: 8s - loss: 12.8547 - exit_loss: 5.3666 - branch_softmax_loss: 7.4881 - exit_accuracy: 0.0797 - branch_softmax_accuracy: 0.0991input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 89/312 [=======>......................] - ETA: 7s - loss: 12.8544 - exit_loss: 5.3771 - branch_softmax_loss: 7.4774 - exit_accuracy: 0.0797 - branch_softmax_accuracy: 0.0990input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 91/312 [=======>......................] - ETA: 7s - loss: 12.8631 - exit_loss: 5.3863 - branch_softmax_loss: 7.4768 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.0996input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 93/312 [=======>......................] - ETA: 7s - loss: 12.8671 - exit_loss: 5.3978 - branch_softmax_loss: 7.4693 - exit_accuracy: 0.0786 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 95/312 [========>.....................] - ETA: 7s - loss: 12.8607 - exit_loss: 5.3923 - branch_softmax_loss: 7.4684 - exit_accuracy: 0.0789 - branch_softmax_accuracy: 0.0987input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 97/312 [========>.....................] - ETA: 7s - loss: 12.8430 - exit_loss: 5.3857 - branch_softmax_loss: 7.4573 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.0992input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      " 99/312 [========>.....................] - ETA: 7s - loss: 12.8615 - exit_loss: 5.4100 - branch_softmax_loss: 7.4515 - exit_accuracy: 0.0786 - branch_softmax_accuracy: 0.0991input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "101/312 [========>.....................] - ETA: 7s - loss: 12.8789 - exit_loss: 5.4144 - branch_softmax_loss: 7.4646 - exit_accuracy: 0.0786 - branch_softmax_accuracy: 0.0984input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "103/312 [========>.....................] - ETA: 7s - loss: 12.8575 - exit_loss: 5.4059 - branch_softmax_loss: 7.4516 - exit_accuracy: 0.0780 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "105/312 [=========>....................] - ETA: 7s - loss: 12.8441 - exit_loss: 5.4103 - branch_softmax_loss: 7.4338 - exit_accuracy: 0.0777 - branch_softmax_accuracy: 0.1003input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "107/312 [=========>....................] - ETA: 7s - loss: 12.8230 - exit_loss: 5.4043 - branch_softmax_loss: 7.4187 - exit_accuracy: 0.0780 - branch_softmax_accuracy: 0.1005input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "109/312 [=========>....................] - ETA: 7s - loss: 12.8249 - exit_loss: 5.3994 - branch_softmax_loss: 7.4255 - exit_accuracy: 0.0786 - branch_softmax_accuracy: 0.1003input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "111/312 [=========>....................] - ETA: 7s - loss: 12.8405 - exit_loss: 5.4080 - branch_softmax_loss: 7.4325 - exit_accuracy: 0.0783 - branch_softmax_accuracy: 0.0988input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "113/312 [=========>....................] - ETA: 7s - loss: 12.8446 - exit_loss: 5.4089 - branch_softmax_loss: 7.4357 - exit_accuracy: 0.0791 - branch_softmax_accuracy: 0.0990input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "115/312 [==========>...................] - ETA: 7s - loss: 12.8444 - exit_loss: 5.4190 - branch_softmax_loss: 7.4254 - exit_accuracy: 0.0788 - branch_softmax_accuracy: 0.0989input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "117/312 [==========>...................] - ETA: 6s - loss: 12.8543 - exit_loss: 5.4283 - branch_softmax_loss: 7.4260 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.0986input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "119/312 [==========>...................] - ETA: 6s - loss: 12.8493 - exit_loss: 5.4339 - branch_softmax_loss: 7.4155 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "121/312 [==========>...................] - ETA: 6s - loss: 12.8566 - exit_loss: 5.4391 - branch_softmax_loss: 7.4175 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.0992input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "123/312 [==========>...................] - ETA: 6s - loss: 12.8475 - exit_loss: 5.4405 - branch_softmax_loss: 7.4070 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "125/312 [===========>..................] - ETA: 6s - loss: 12.8472 - exit_loss: 5.4447 - branch_softmax_loss: 7.4025 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.1010input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "127/312 [===========>..................] - ETA: 6s - loss: 12.8210 - exit_loss: 5.4317 - branch_softmax_loss: 7.3893 - exit_accuracy: 0.0785 - branch_softmax_accuracy: 0.1024input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "129/312 [===========>..................] - ETA: 6s - loss: 12.8168 - exit_loss: 5.4155 - branch_softmax_loss: 7.4013 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.1020input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "131/312 [===========>..................] - ETA: 6s - loss: 12.8196 - exit_loss: 5.4153 - branch_softmax_loss: 7.4043 - exit_accuracy: 0.0794 - branch_softmax_accuracy: 0.1019input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "133/312 [===========>..................] - ETA: 6s - loss: 12.8304 - exit_loss: 5.4224 - branch_softmax_loss: 7.4081 - exit_accuracy: 0.0792 - branch_softmax_accuracy: 0.1008input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "135/312 [===========>..................] - ETA: 6s - loss: 12.8393 - exit_loss: 5.4226 - branch_softmax_loss: 7.4167 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1012input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "137/312 [============>.................] - ETA: 6s - loss: 12.8453 - exit_loss: 5.4346 - branch_softmax_loss: 7.4107 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1017input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "139/312 [============>.................] - ETA: 6s - loss: 12.8565 - exit_loss: 5.4395 - branch_softmax_loss: 7.4170 - exit_accuracy: 0.0794 - branch_softmax_accuracy: 0.1009input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "141/312 [============>.................] - ETA: 6s - loss: 12.8574 - exit_loss: 5.4357 - branch_softmax_loss: 7.4217 - exit_accuracy: 0.0793 - branch_softmax_accuracy: 0.1008input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "143/312 [============>.................] - ETA: 6s - loss: 12.8510 - exit_loss: 5.4367 - branch_softmax_loss: 7.4143 - exit_accuracy: 0.0791 - branch_softmax_accuracy: 0.1001input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "145/312 [============>.................] - ETA: 5s - loss: 12.8470 - exit_loss: 5.4346 - branch_softmax_loss: 7.4125 - exit_accuracy: 0.0789 - branch_softmax_accuracy: 0.0998input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "147/312 [=============>................] - ETA: 5s - loss: 12.8309 - exit_loss: 5.4225 - branch_softmax_loss: 7.4083 - exit_accuracy: 0.0795 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "149/312 [=============>................] - ETA: 5s - loss: 12.8497 - exit_loss: 5.4336 - branch_softmax_loss: 7.4162 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.0998input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "151/312 [=============>................] - ETA: 5s - loss: 12.8659 - exit_loss: 5.4397 - branch_softmax_loss: 7.4262 - exit_accuracy: 0.0797 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "153/312 [=============>................] - ETA: 5s - loss: 12.8686 - exit_loss: 5.4483 - branch_softmax_loss: 7.4202 - exit_accuracy: 0.0795 - branch_softmax_accuracy: 0.0999input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "155/312 [=============>................] - ETA: 5s - loss: 12.8705 - exit_loss: 5.4494 - branch_softmax_loss: 7.4211 - exit_accuracy: 0.0788 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "157/312 [==============>...............] - ETA: 5s - loss: 12.8494 - exit_loss: 5.4440 - branch_softmax_loss: 7.4054 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.1009input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "159/312 [==============>...............] - ETA: 5s - loss: 12.8631 - exit_loss: 5.4526 - branch_softmax_loss: 7.4105 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "161/312 [==============>...............] - ETA: 5s - loss: 12.8740 - exit_loss: 5.4545 - branch_softmax_loss: 7.4194 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.1007input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "163/312 [==============>...............] - ETA: 5s - loss: 12.8698 - exit_loss: 5.4498 - branch_softmax_loss: 7.4200 - exit_accuracy: 0.0794 - branch_softmax_accuracy: 0.1005input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "165/312 [==============>...............] - ETA: 5s - loss: 12.8614 - exit_loss: 5.4474 - branch_softmax_loss: 7.4141 - exit_accuracy: 0.0790 - branch_softmax_accuracy: 0.1004input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "167/312 [===============>..............] - ETA: 5s - loss: 12.8502 - exit_loss: 5.4433 - branch_softmax_loss: 7.4070 - exit_accuracy: 0.0795 - branch_softmax_accuracy: 0.1009input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "169/312 [===============>..............] - ETA: 5s - loss: 12.8369 - exit_loss: 5.4414 - branch_softmax_loss: 7.3955 - exit_accuracy: 0.0799 - branch_softmax_accuracy: 0.1010input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "171/312 [===============>..............] - ETA: 5s - loss: 12.8442 - exit_loss: 5.4395 - branch_softmax_loss: 7.4047 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1012input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "173/312 [===============>..............] - ETA: 4s - loss: 12.8471 - exit_loss: 5.4377 - branch_softmax_loss: 7.4094 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1010input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "175/312 [===============>..............] - ETA: 4s - loss: 12.8463 - exit_loss: 5.4342 - branch_softmax_loss: 7.4121 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.1014input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "177/312 [================>.............] - ETA: 4s - loss: 12.8397 - exit_loss: 5.4221 - branch_softmax_loss: 7.4175 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.1012input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "179/312 [================>.............] - ETA: 4s - loss: 12.8346 - exit_loss: 5.4178 - branch_softmax_loss: 7.4168 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.1018input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "181/312 [================>.............] - ETA: 4s - loss: 12.8306 - exit_loss: 5.4144 - branch_softmax_loss: 7.4161 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.1022input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "183/312 [================>.............] - ETA: 4s - loss: 12.8245 - exit_loss: 5.4064 - branch_softmax_loss: 7.4181 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1021input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "185/312 [================>.............] - ETA: 4s - loss: 12.8087 - exit_loss: 5.4028 - branch_softmax_loss: 7.4060 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.1022input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "187/312 [================>.............] - ETA: 4s - loss: 12.8170 - exit_loss: 5.4091 - branch_softmax_loss: 7.4080 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.1023input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "189/312 [=================>............] - ETA: 4s - loss: 12.8110 - exit_loss: 5.3970 - branch_softmax_loss: 7.4140 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.1020input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "191/312 [=================>............] - ETA: 4s - loss: 12.8113 - exit_loss: 5.3995 - branch_softmax_loss: 7.4118 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.1018input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "193/312 [=================>............] - ETA: 4s - loss: 12.8133 - exit_loss: 5.4071 - branch_softmax_loss: 7.4062 - exit_accuracy: 0.0801 - branch_softmax_accuracy: 0.1017input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "195/312 [=================>............] - ETA: 4s - loss: 12.8207 - exit_loss: 5.4101 - branch_softmax_loss: 7.4107 - exit_accuracy: 0.0800 - branch_softmax_accuracy: 0.1016input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "197/312 [=================>............] - ETA: 4s - loss: 12.8255 - exit_loss: 5.4121 - branch_softmax_loss: 7.4134 - exit_accuracy: 0.0799 - branch_softmax_accuracy: 0.1014input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "199/312 [==================>...........] - ETA: 4s - loss: 12.8083 - exit_loss: 5.4019 - branch_softmax_loss: 7.4065 - exit_accuracy: 0.0799 - branch_softmax_accuracy: 0.1022input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "201/312 [==================>...........] - ETA: 3s - loss: 12.8123 - exit_loss: 5.4025 - branch_softmax_loss: 7.4098 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1023input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "203/312 [==================>...........] - ETA: 3s - loss: 12.8173 - exit_loss: 5.3976 - branch_softmax_loss: 7.4197 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1019input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "205/312 [==================>...........] - ETA: 3s - loss: 12.8067 - exit_loss: 5.3920 - branch_softmax_loss: 7.4148 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1023input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "207/312 [==================>...........] - ETA: 3s - loss: 12.8081 - exit_loss: 5.3915 - branch_softmax_loss: 7.4165 - exit_accuracy: 0.0794 - branch_softmax_accuracy: 0.1022input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "209/312 [===================>..........] - ETA: 3s - loss: 12.8026 - exit_loss: 5.3891 - branch_softmax_loss: 7.4135 - exit_accuracy: 0.0795 - branch_softmax_accuracy: 0.1021input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "211/312 [===================>..........] - ETA: 3s - loss: 12.8121 - exit_loss: 5.3907 - branch_softmax_loss: 7.4214 - exit_accuracy: 0.0789 - branch_softmax_accuracy: 0.1013input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "213/312 [===================>..........] - ETA: 3s - loss: 12.8188 - exit_loss: 5.3905 - branch_softmax_loss: 7.4283 - exit_accuracy: 0.0788 - branch_softmax_accuracy: 0.1011input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "215/312 [===================>..........] - ETA: 3s - loss: 12.8246 - exit_loss: 5.3940 - branch_softmax_loss: 7.4305 - exit_accuracy: 0.0792 - branch_softmax_accuracy: 0.1007input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "216/312 [===================>..........] - ETA: 3s - loss: 12.8221 - exit_loss: 5.3924 - branch_softmax_loss: 7.4297 - exit_accuracy: 0.0794 - branch_softmax_accuracy: 0.1005input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "218/312 [===================>..........] - ETA: 3s - loss: 12.8261 - exit_loss: 5.3884 - branch_softmax_loss: 7.4377 - exit_accuracy: 0.0800 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "220/312 [====================>.........] - ETA: 3s - loss: 12.8209 - exit_loss: 5.3912 - branch_softmax_loss: 7.4298 - exit_accuracy: 0.0801 - branch_softmax_accuracy: 0.1007input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "222/312 [====================>.........] - ETA: 3s - loss: 12.8141 - exit_loss: 5.3894 - branch_softmax_loss: 7.4247 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1008input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "224/312 [====================>.........] - ETA: 3s - loss: 12.8213 - exit_loss: 5.3880 - branch_softmax_loss: 7.4333 - exit_accuracy: 0.0805 - branch_softmax_accuracy: 0.1007input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "226/312 [====================>.........] - ETA: 3s - loss: 12.8118 - exit_loss: 5.3866 - branch_softmax_loss: 7.4253 - exit_accuracy: 0.0808 - branch_softmax_accuracy: 0.1011input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "228/312 [====================>.........] - ETA: 2s - loss: 12.7996 - exit_loss: 5.3857 - branch_softmax_loss: 7.4139 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.1013input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "230/312 [=====================>........] - ETA: 2s - loss: 12.7942 - exit_loss: 5.3775 - branch_softmax_loss: 7.4167 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1010input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "232/312 [=====================>........] - ETA: 2s - loss: 12.7924 - exit_loss: 5.3778 - branch_softmax_loss: 7.4146 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1009input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "234/312 [=====================>........] - ETA: 2s - loss: 12.7979 - exit_loss: 5.3807 - branch_softmax_loss: 7.4172 - exit_accuracy: 0.0805 - branch_softmax_accuracy: 0.1010input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "236/312 [=====================>........] - ETA: 2s - loss: 12.7984 - exit_loss: 5.3796 - branch_softmax_loss: 7.4188 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1008input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "238/312 [=====================>........] - ETA: 2s - loss: 12.7998 - exit_loss: 5.3869 - branch_softmax_loss: 7.4129 - exit_accuracy: 0.0800 - branch_softmax_accuracy: 0.1006input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "240/312 [======================>.......] - ETA: 2s - loss: 12.8055 - exit_loss: 5.3916 - branch_softmax_loss: 7.4139 - exit_accuracy: 0.0799 - branch_softmax_accuracy: 0.1005input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "242/312 [======================>.......] - ETA: 2s - loss: 12.8133 - exit_loss: 5.3938 - branch_softmax_loss: 7.4196 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.1002input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "244/312 [======================>.......] - ETA: 2s - loss: 12.8181 - exit_loss: 5.3933 - branch_softmax_loss: 7.4248 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "246/312 [======================>.......] - ETA: 2s - loss: 12.8187 - exit_loss: 5.3927 - branch_softmax_loss: 7.4260 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "248/312 [======================>.......] - ETA: 2s - loss: 12.8212 - exit_loss: 5.4011 - branch_softmax_loss: 7.4201 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.1002input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "250/312 [=======================>......] - ETA: 2s - loss: 12.8201 - exit_loss: 5.4048 - branch_softmax_loss: 7.4153 - exit_accuracy: 0.0800 - branch_softmax_accuracy: 0.1002input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "252/312 [=======================>......] - ETA: 2s - loss: 12.8287 - exit_loss: 5.4131 - branch_softmax_loss: 7.4156 - exit_accuracy: 0.0796 - branch_softmax_accuracy: 0.1001input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "254/312 [=======================>......] - ETA: 2s - loss: 12.8208 - exit_loss: 5.4087 - branch_softmax_loss: 7.4121 - exit_accuracy: 0.0798 - branch_softmax_accuracy: 0.1003input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "256/312 [=======================>......] - ETA: 1s - loss: 12.8282 - exit_loss: 5.4047 - branch_softmax_loss: 7.4234 - exit_accuracy: 0.0801 - branch_softmax_accuracy: 0.1001input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "258/312 [=======================>......] - ETA: 1s - loss: 12.8249 - exit_loss: 5.4024 - branch_softmax_loss: 7.4225 - exit_accuracy: 0.0801 - branch_softmax_accuracy: 0.0999input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "260/312 [========================>.....] - ETA: 1s - loss: 12.8329 - exit_loss: 5.3995 - branch_softmax_loss: 7.4334 - exit_accuracy: 0.0805 - branch_softmax_accuracy: 0.0994input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "262/312 [========================>.....] - ETA: 1s - loss: 12.8258 - exit_loss: 5.3968 - branch_softmax_loss: 7.4290 - exit_accuracy: 0.0804 - branch_softmax_accuracy: 0.0997input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "264/312 [========================>.....] - ETA: 1s - loss: 12.8341 - exit_loss: 5.3978 - branch_softmax_loss: 7.4364 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.0992input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "266/312 [========================>.....] - ETA: 1s - loss: 12.8304 - exit_loss: 5.4046 - branch_softmax_loss: 7.4258 - exit_accuracy: 0.0802 - branch_softmax_accuracy: 0.0989input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "268/312 [========================>.....] - ETA: 1s - loss: 12.8313 - exit_loss: 5.4021 - branch_softmax_loss: 7.4292 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "270/312 [========================>.....] - ETA: 1s - loss: 12.8320 - exit_loss: 5.3999 - branch_softmax_loss: 7.4321 - exit_accuracy: 0.0808 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "272/312 [=========================>....] - ETA: 1s - loss: 12.8283 - exit_loss: 5.3982 - branch_softmax_loss: 7.4301 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.0994input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "274/312 [=========================>....] - ETA: 1s - loss: 12.8227 - exit_loss: 5.3995 - branch_softmax_loss: 7.4232 - exit_accuracy: 0.0805 - branch_softmax_accuracy: 0.0996input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "276/312 [=========================>....] - ETA: 1s - loss: 12.8256 - exit_loss: 5.3949 - branch_softmax_loss: 7.4307 - exit_accuracy: 0.0806 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "278/312 [=========================>....] - ETA: 1s - loss: 12.8252 - exit_loss: 5.3916 - branch_softmax_loss: 7.4336 - exit_accuracy: 0.0810 - branch_softmax_accuracy: 0.0991input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "280/312 [=========================>....] - ETA: 1s - loss: 12.8269 - exit_loss: 5.3919 - branch_softmax_loss: 7.4350 - exit_accuracy: 0.0818 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "282/312 [==========================>...] - ETA: 1s - loss: 12.8360 - exit_loss: 5.3912 - branch_softmax_loss: 7.4449 - exit_accuracy: 0.0816 - branch_softmax_accuracy: 0.0993input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "284/312 [==========================>...] - ETA: 0s - loss: 12.8371 - exit_loss: 5.3923 - branch_softmax_loss: 7.4448 - exit_accuracy: 0.0814 - branch_softmax_accuracy: 0.0990input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "286/312 [==========================>...] - ETA: 0s - loss: 12.8359 - exit_loss: 5.3933 - branch_softmax_loss: 7.4426 - exit_accuracy: 0.0811 - branch_softmax_accuracy: 0.0990input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "288/312 [==========================>...] - ETA: 0s - loss: 12.8357 - exit_loss: 5.3941 - branch_softmax_loss: 7.4417 - exit_accuracy: 0.0811 - branch_softmax_accuracy: 0.0985input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "290/312 [==========================>...] - ETA: 0s - loss: 12.8365 - exit_loss: 5.3960 - branch_softmax_loss: 7.4405 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.0991input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "292/312 [===========================>..] - ETA: 0s - loss: 12.8353 - exit_loss: 5.3964 - branch_softmax_loss: 7.4389 - exit_accuracy: 0.0803 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "294/312 [===========================>..] - ETA: 0s - loss: 12.8379 - exit_loss: 5.3995 - branch_softmax_loss: 7.4384 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.0999input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "296/312 [===========================>..] - ETA: 0s - loss: 12.8353 - exit_loss: 5.3997 - branch_softmax_loss: 7.4357 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.1001input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "298/312 [===========================>..] - ETA: 0s - loss: 12.8421 - exit_loss: 5.4002 - branch_softmax_loss: 7.4418 - exit_accuracy: 0.0807 - branch_softmax_accuracy: 0.0996input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "300/312 [===========================>..] - ETA: 0s - loss: 12.8410 - exit_loss: 5.4024 - branch_softmax_loss: 7.4386 - exit_accuracy: 0.0810 - branch_softmax_accuracy: 0.0998input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "302/312 [============================>.] - ETA: 0s - loss: 12.8439 - exit_loss: 5.4002 - branch_softmax_loss: 7.4436 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.0995input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "304/312 [============================>.] - ETA: 0s - loss: 12.8404 - exit_loss: 5.4012 - branch_softmax_loss: 7.4391 - exit_accuracy: 0.0811 - branch_softmax_accuracy: 0.1000input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "306/312 [============================>.] - ETA: 0s - loss: 12.8420 - exit_loss: 5.4027 - branch_softmax_loss: 7.4393 - exit_accuracy: 0.0811 - branch_softmax_accuracy: 0.0998input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "308/312 [============================>.] - ETA: 0s - loss: 12.8454 - exit_loss: 5.4086 - branch_softmax_loss: 7.4368 - exit_accuracy: 0.0810 - branch_softmax_accuracy: 0.0996input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "310/312 [============================>.] - ETA: 0s - loss: 12.8457 - exit_loss: 5.4089 - branch_softmax_loss: 7.4368 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.0996input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "input_1\n",
      "conv2d\n",
      "conv2d\n",
      "batch_normalization\n",
      "batch_normalization\n",
      "max_pooling2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_1\n",
      "batch_normalization_1\n",
      "batch_normalization_1\n",
      "max_pooling2d_1\n",
      "max_pooling2d_1\n",
      "conv2d_2\n",
      "conv2d_2\n",
      "batch_normalization_2\n",
      "batch_normalization_2\n",
      "conv2d_3\n",
      "conv2d_3\n",
      "batch_normalization_3\n",
      "batch_normalization_3\n",
      "conv2d_4\n",
      "conv2d_4\n",
      "batch_normalization_4\n",
      "batch_normalization_4\n",
      "max_pooling2d_2\n",
      "max_pooling2d_2\n",
      "flatten\n",
      "flatten\n",
      "dense\n",
      "dense\n",
      "branch_flatten\n",
      "branch124\n",
      "dropout\n",
      "branch64\n",
      "main_path124\n",
      "branch_output\n",
      "main_path64\n",
      "branch_softmax\n",
      "exit\n",
      "targets\n",
      "312/312 [==============================] - 12s 35ms/step - loss: 12.8419 - exit_loss: 5.4054 - branch_softmax_loss: 7.4365 - exit_accuracy: 0.0809 - branch_softmax_accuracy: 0.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[12.841876029968262,\n",
       " 5.4054155349731445,\n",
       " 7.43646240234375,\n",
       " 0.08092948794364929,\n",
       " 0.09965945780277252]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "708a5a19-1a03-4aef-92ab-2d25d0e0fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets already present?  False\n",
      "added targets\n",
      "\n",
      "preset: Other\n",
      "Model: \"branch_model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 227, 227, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 55, 55, 96)   34944       ['input_19[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 55, 55, 96)  384         ['conv2d_45[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 27, 27, 96)  0           ['batch_normalization_45[1][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 27, 27, 256)  614656      ['max_pooling2d_27[1][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 27, 27, 256)  1024       ['conv2d_46[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 13, 13, 256)  0          ['batch_normalization_46[1][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 13, 13, 384)  885120      ['max_pooling2d_28[1][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_47[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 13, 13, 384)  147840      ['batch_normalization_47[1][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_48[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 13, 13, 256)  98560       ['batch_normalization_48[1][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_49[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 6, 6, 256)   0           ['batch_normalization_49[1][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_9 (Flatten)            (None, 9216)         0           ['max_pooling2d_29[1][0]']       \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 4096)         37752832    ['flatten_9[1][0]']              \n",
      "                                                                                                  \n",
      " branch_flatten_9 (Flatten)     (None, 4096)         0           ['dense_9[1][0]']                \n",
      "                                                                                                  \n",
      " branch124_9 (Dense)            (None, 124)          508028      ['branch_flatten_9[0][0]']       \n",
      "                                                                                                  \n",
      " branch64_9 (Dense)             (None, 64)           8000        ['branch124_9[0][0]']            \n",
      "                                                                                                  \n",
      " branch_output_9 (Dense)        (None, 10)           650         ['branch64_9[0][0]']             \n",
      "                                                                                                  \n",
      " branch_softmax_9 (Softmax)     (None, 10)           0           ['branch_output_9[0][0]']        \n",
      "                                                                                                  \n",
      " branch_finished_9 (branch_fini  (None, 4096)        0           ['dense_9[1][0]',                \n",
      " shed)                                                            'branch_softmax_9[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 4096)         0           ['branch_finished_9[0][0]']      \n",
      "                                                                                                  \n",
      " main_path124_9 (Dense)         (None, 124)          508028      ['dropout_9[1][0]']              \n",
      "                                                                                                  \n",
      " main_path64_9 (Dense)          (None, 64)           8000        ['main_path124_9[1][0]']         \n",
      "                                                                                                  \n",
      " targets (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " exit_9 (Dense)                 (None, 10)           650         ['main_path64_9[1][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,572,812\n",
      "Trainable params: 516,678\n",
      "Non-trainable params: 40,056,134\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "identifier= ['dense_13']\n",
    "layers = [l for l in model.layers]\n",
    "# print(layers)\n",
    "\n",
    "inputs =[]\n",
    "# x =  model.inputs[0]\n",
    "\n",
    "outputs = []\n",
    "\n",
    "ready = False\n",
    "target_input = True\n",
    "for i in model.inputs:\n",
    "    if i.name == \"targets\":\n",
    "        ready = True\n",
    "        # print\n",
    "    inputs.append(i)\n",
    "if target_input:\n",
    "    print(\"targets already present? \",ready)\n",
    "\n",
    "    if not ready:\n",
    "        print(\"added targets\")\n",
    "        targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "        inputs.append(targets) #shape is (1,) for sparse_categorical_crossentropy\n",
    "    else:\n",
    "        targets = model.get_layer('targets').output\n",
    "\n",
    "x = layers[0].output\n",
    "for i in range(1,len(layers)):\n",
    "    # if i == layer_id:\n",
    "        # x = new_layer(x)\n",
    "    # else:\n",
    "        # print(\"input: \", layers[i].input)\n",
    "        # print(\"inputX \", type(x))\n",
    "        # if type(x) is not list :\n",
    "            # print(\"yes\")\n",
    "        # inputs = layers[i].input\n",
    "        if \"dense\" in layers[i].name:\n",
    "            x = layers[i](x)\n",
    "            new_branch = branches.branch.newBranch_flatten(x,targets = targets)\n",
    "            outputs.append(new_branch)\n",
    "            x = branches.branch.branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,new_branch)\n",
    "        else:        \n",
    "            x = layers[i](x)\n",
    "        #find branch point\n",
    "#         if layers[i].name in identifier:\n",
    "#             print(\"add Branch to branch point \",layer.name)\n",
    "#             new_branch = brevis.branches.branch.newBranch_flatten(layer.output,targets = targets)\n",
    "#             x = branch.branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,new_branch)\n",
    "outputs.append(x)\n",
    "new_model = brevis.BranchModel(inputs=[inputs], outputs=[outputs])\n",
    "new_model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "new_model.summary()# train_ds, test_ds, validation_ds = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac30c756-b05c-4719-b771-74e37f349cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 7s 23ms/step - loss: 4.5976 - branch_softmax_9_loss: 3.0916 - exit_9_loss: 1.5059 - branch_softmax_9_accuracy: 0.0917 - exit_9_accuracy: 0.4722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.597559452056885,\n",
       " 3.0916459560394287,\n",
       " 1.505914330482483,\n",
       " 0.09174679219722748,\n",
       " 0.47215545177459717]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(train_ds, validation_ds, 1)\n",
    "new_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83ecb0db-9b66-49f9-b6ce-5a2b2ab398dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 2.8050 - branch_softmax_9_loss: 1.2571 - exit_9_loss: 1.5479 - branch_softmax_9_accuracy: 0.5469 - exit_9_accuracy: 0.4564\n",
      "Epoch 1: saving model to models\\branch_model_9_branched.hdf5.hdf5\n",
      "1406/1406 [==============================] - 84s 57ms/step - loss: 2.8050 - branch_softmax_9_loss: 1.2571 - exit_9_loss: 1.5479 - branch_softmax_9_accuracy: 0.5469 - exit_9_accuracy: 0.4564 - val_loss: 2.6666 - val_branch_softmax_9_loss: 1.1525 - val_exit_9_loss: 1.5141 - val_branch_softmax_9_accuracy: 0.5915 - val_exit_9_accuracy: 0.4784\n",
      "<keras.callbacks.History object at 0x0000022C705CC048>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x22cfdd6e648>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(train_ds, validation_ds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9ecab-05d2-4575-81f0-47b19ccc1606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f828ea7-1a2f-4e98-b2cd-f94fe780ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# x = model.inputs\n",
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i)\n",
    "#     if i <1:\n",
    "#         continue\n",
    "# # for i in range(len(new_model.layers)):\n",
    "#     print(\"layer\", layer, \"x\",x)\n",
    "#     x = layer(x)\n",
    "#     if exact == True:\n",
    "#         if layer.name in identifier:\n",
    "\n",
    "#             print(\"add Branch to branch point \",layer.name)\n",
    "#             new_branch = customBranch[min(branches, len(customBranch)-1)](layer.output,targets = targets)\n",
    "#             x = branch.branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,new_branch)\n",
    "#             # try:\n",
    "#                 # new_model.layers[i+1].inputs.append(branch_flag)\n",
    "#             # except:\n",
    "#                 # print(\"no layer after branch point\")\n",
    "#             outputs.append(new_branch)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ab61a98-ee04-48f0-b935-161f3391fc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(model, identifier =[\"\"], customBranch = [],exact = True, target_input= True, compact = False):\n",
    "        \"\"\" add branches to the provided model, aka modifying an existing model to include branches.\n",
    "            identifier: takes a list of names of layers to branch on is blank, branches will be added to all layers except the input and final layer. Can be a list of layer numbers, following the numbering format of model.layers[]\n",
    "            If identifier is not blank, a branch will be added to each layer with identifier in its name. (identifier = \"dense\", all dense layers will be branched.)\n",
    "            Warning! individual layers are defined according to how TF defines them. this means that for layers that would be normally grouped, they will be treated as individual layers (conv2d, pooling, flatten, etc)\n",
    "            customBranch: optional function that can be passed to provide a custom branch to be inserted. Check \"newBranch\" function for default shape of branches and how to build custom branching function. Can be provided as a list and each branch will iterate through provided customBranches, repeating last the last branch until function completes\n",
    "        \"\"\"\n",
    "        # model = keras.Model([model.input], [model_old.output], name=\"{}_branched\".format(model_old.name))\n",
    "        # model.summary()\n",
    "\n",
    "        # outputs = [model.outputs]\n",
    "        # outputs.append(newBranch(model.layers[6].output))\n",
    "        # new_model = keras.Model([model.input], outputs, name=\"{}_branched\".format(model.name))\n",
    "        # new_model.summary()\n",
    "        outputs = []\n",
    "        for i in model.outputs:\n",
    "            outputs.append(i)\n",
    "        \n",
    "        inputs = []\n",
    "        ready = False\n",
    "        \n",
    "        targets= None\n",
    "        \n",
    "        for i in model.inputs:\n",
    "            if i.name == \"targets\":\n",
    "                ready = True\n",
    "            inputs.append(i)\n",
    "        if target_input:\n",
    "            print(\"targets already present? \",ready)\n",
    "\n",
    "            if not ready:\n",
    "                print(\"added targets\")\n",
    "                targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "                inputs.append(targets) #shape is (1,) for sparse_categorical_crossentropy\n",
    "            else:\n",
    "                targets = model.get_layer('targets').output\n",
    "\n",
    "        #add targets as an input to the model so it can be used for the custom losses.\n",
    "        #   input size is the size of the     \n",
    "        #add target input \n",
    "        new_model = brevis.BranchModel(inputs=inputs, outputs=outputs,name = model.name, transfer=model.transfer, custom_objects=model.custom_objects)\n",
    "\n",
    "        # outputs = []\n",
    "\n",
    "\n",
    "        old_output = outputs\n",
    "        # outputs.append(i in model.outputs) #get model outputs that already exist \n",
    "\n",
    "        if type(identifier) != list:\n",
    "            identifier = [identifier]\n",
    "\n",
    "        if type(customBranch) != list:\n",
    "            customBranch = [customBranch]\n",
    "        if len(customBranch) == 0:\n",
    "            customBranch = [branch.newBranch_flatten]\n",
    "        branches = 0\n",
    "        # print(customBranch)\n",
    "        if len(identifier) > 0:\n",
    "            # print(\"Matching Branchpoint by id number\")\n",
    "            if type(identifier[0]) == int:\n",
    "                for i in identifier: \n",
    "                    try:\n",
    "                        outputs.append(customBranch[min(branches, len(customBranch))-1](new_model.layers[i].output,targets = targets))\n",
    "                        branches=branches+1\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                print(\"Matching Branchpoint by name, exact: \",exact)\n",
    "                x = new_model.outputs\n",
    "                # x = layer(x[0])\n",
    "                x = new_model.layers[0].output\n",
    "                # print(\"input\", x)\n",
    "                for i, layer in enumerate(new_model.layers):\n",
    "                    print(i)\n",
    "                    \n",
    "                    if i <1:\n",
    "                        continue\n",
    "                # for i in range(len(new_model.layers)):\n",
    "                    print(\"layer\", layer, \"x\",x)\n",
    "                    x = layer(x)\n",
    "                    if exact == True:\n",
    "                        \n",
    "                        if layer.name in identifier:\n",
    "                            \n",
    "                            print(\"add Branch to branch point \",layer.name)\n",
    "                            new_branch = customBranch[min(branches, len(customBranch)-1)](layer.output,targets = targets)\n",
    "                            x = branch.branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,new_branch)\n",
    "                            # try:\n",
    "                                # new_model.layers[i+1].inputs.append(branch_flag)\n",
    "                            # except:\n",
    "                                # print(\"no layer after branch point\")\n",
    "                            outputs.append(new_branch)\n",
    "                            \n",
    "                            branches=branches+1\n",
    "                    else:\n",
    "                        if any(id in new_model.layers[i].name for id in identifier):\n",
    "                            print(\"add Branch to branch point \",new_model.layers[i].name)\n",
    "                            outputs.append(customBranch[min(branches, len(customBranch)-1)](new_model.layers[i].output,targets = targets))\n",
    "                            branches=branches+1\n",
    "        else: #if identifier is blank or empty\n",
    "            # print(\"nothing\")\n",
    "            for i in range(1-len(new_model.layers)-1):\n",
    "                # print(new_model.layers[i].name)\n",
    "                # if \"dense\" in new_model.layers[i].name:\n",
    "                # outputs = newBranch(new_model.layers[i].output,outputs)\n",
    "                outputs = customBranch[min(branches, len(customBranch))-1](new_model.layers[i].output,outputs,targets = targets)\n",
    "                branches=branches+1\n",
    "            # for j in range(len(new_model.layers[i].inbound_nodes)):\n",
    "            #     print(dir(new_model.layers[i].inbound_nodes[j]))\n",
    "            #     print(\"inboundNode: \" + new_model.layers[i].inbound_nodes[j].name)\n",
    "            #     print(\"outboundNode: \" + new_model.layers[i].outbound_nodes[j].name)\n",
    "        # print(outputs)\n",
    "        # print(new_model.input)\n",
    "        # outputs.pop(0)\n",
    "        # print(outputs)\n",
    "        # input_layer = layers.Input(batch_shape=new_model.layers[0].input_shape)\n",
    "        new_model = brevis.BranchModel([inputs], [outputs], name = new_model.name, transfer = new_model.transfer, custom_objects=new_model.custom_objects)\n",
    "        new_model.branch_active=model.branch_active        \n",
    "        # new_model.summary()\n",
    "\n",
    "        return new_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff98524e-599d-4e85-8177-3e41877bb2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by name, exact:  True\n",
      "0\n",
      "1\n",
      "layer <keras.layers.convolutional.Conv2D object at 0x000001CBE47DDE48> x KerasTensor(type_spec=TensorSpec(shape=(None, 227, 227, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "2\n",
      "layer <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CBE46C8A48> x KerasTensor(type_spec=TensorSpec(shape=(None, 55, 55, 96), dtype=tf.float32, name=None), name='conv2d_1/Relu:0', description=\"created by layer 'conv2d_1'\")\n",
      "3\n",
      "layer <keras.layers.pooling.MaxPooling2D object at 0x000001CBE4935088> x KerasTensor(type_spec=TensorSpec(shape=(None, 55, 55, 96), dtype=tf.float32, name=None), name='batch_normalization/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization'\")\n",
      "4\n",
      "layer <keras.layers.convolutional.Conv2D object at 0x000001CBE49359C8> x KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 96), dtype=tf.float32, name=None), name='max_pooling2d/MaxPool:0', description=\"created by layer 'max_pooling2d'\")\n",
      "5\n",
      "layer <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CBE4912708> x KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 256), dtype=tf.float32, name=None), name='conv2d_2/Relu:0', description=\"created by layer 'conv2d_2'\")\n",
      "6\n",
      "layer <keras.layers.pooling.MaxPooling2D object at 0x000001CBE4779CC8> x KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 256), dtype=tf.float32, name=None), name='batch_normalization_1/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_1'\")\n",
      "7\n",
      "layer <keras.layers.convolutional.Conv2D object at 0x000001CBE492C288> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 256), dtype=tf.float32, name=None), name='max_pooling2d_1/MaxPool:0', description=\"created by layer 'max_pooling2d_1'\")\n",
      "8\n",
      "layer <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CBE492CB88> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 384), dtype=tf.float32, name=None), name='conv2d_3/Relu:0', description=\"created by layer 'conv2d_3'\")\n",
      "9\n",
      "layer <keras.layers.convolutional.Conv2D object at 0x000001CBE491B648> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 384), dtype=tf.float32, name=None), name='batch_normalization_2/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_2'\")\n",
      "10\n",
      "layer <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CBE491BFC8> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 384), dtype=tf.float32, name=None), name='conv2d_4/Relu:0', description=\"created by layer 'conv2d_4'\")\n",
      "11\n",
      "layer <keras.layers.convolutional.Conv2D object at 0x000001CBE491AA48> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 384), dtype=tf.float32, name=None), name='batch_normalization_3/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_3'\")\n",
      "12\n",
      "layer <keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001CBE47E2548> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 256), dtype=tf.float32, name=None), name='conv2d_5/Relu:0', description=\"created by layer 'conv2d_5'\")\n",
      "13\n",
      "layer <keras.layers.pooling.MaxPooling2D object at 0x000001CBE47E2EC8> x KerasTensor(type_spec=TensorSpec(shape=(None, 13, 13, 256), dtype=tf.float32, name=None), name='batch_normalization_4/FusedBatchNormV3:0', description=\"created by layer 'batch_normalization_4'\")\n",
      "14\n",
      "layer <keras.layers.core.flatten.Flatten object at 0x000001CBE47D5508> x KerasTensor(type_spec=TensorSpec(shape=(None, 6, 6, 256), dtype=tf.float32, name=None), name='max_pooling2d_2/MaxPool:0', description=\"created by layer 'max_pooling2d_2'\")\n",
      "15\n",
      "layer <keras.layers.core.dense.Dense object at 0x000001CBE47D5AC8> x KerasTensor(type_spec=TensorSpec(shape=(None, 9216), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
      "16\n",
      "layer <keras.layers.core.dropout.Dropout object at 0x000001CBE47DC288> x KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dense/Relu:0', description=\"created by layer 'dense'\")\n",
      "17\n",
      "layer <keras.layers.core.dense.Dense object at 0x000001CBE47DC788> x KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "18\n",
      "layer <keras.layers.core.dropout.Dropout object at 0x000001CBE47DCF08> x KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dense_1/Relu:0', description=\"created by layer 'dense_1'\")\n",
      "19\n",
      "layer <keras.engine.input_layer.InputLayer object at 0x000001CBE4801C48> x KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='dropout_1/Identity:0', description=\"created by layer 'dropout_1'\")\n",
      "20\n",
      "layer <keras.layers.core.dense.Dense object at 0x000001CBE4807488> x KerasTensor(type_spec=TensorSpec(shape=(None, 4096), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'targets'\")\n",
      "WARNING:tensorflow:BranchModel model inputs must come from `tf.keras.Input` (thus holding past layer metadata). They cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"alexnet\" was not an Input tensor, it was generated by layer \"targets\".\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='targets'), name='targets', description=\"created by layer 'targets'\")\n",
      "Model: \"alexnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 384)       147840    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 256)       98560     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,361,738\n",
      "Trainable params: 56,358,986\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n",
      "\n",
      "preset: Other\n",
      "done\n",
      "Model: \"alexnet\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 55, 55, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 27, 27, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 384)       147840    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 13, 13, 256)       98560     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,361,738\n",
      "Trainable params: 56,358,986\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "# loss_fn = loss_function()\n",
    "brevisModel = brevis.BranchModel(name=\"../models/alexNetv6_logits.hdf5\")\n",
    "brevisModel.branch_active = True\n",
    "print(brevisModel.branch_active)\n",
    "add(brevisModel, [ brevis.branches.branch.newBranch_flatten          ],\n",
    "                            # brevis.branches.branch.branch_conv2d_entropy,\n",
    "                            # brevis.branches.branch.newBranch_flatten],                         \n",
    "                           [\"max_pooling2d\",\n",
    "                            # \"max_pooling2d_1\",\n",
    "                            # \"dense\"\n",
    "                           ],target_input=True)\n",
    "brevisModel.summary()\n",
    "brevisModel.compile(loss=[\"CategoricalCrossentropy\",loss_fn,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")\n",
    "print(\"done\")\n",
    "brevisModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfcdd8f-93cd-4325-8aef-1efd79a1a060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, validation_ds = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e9471ee8-8d66-4645-92f2-d1568d1b9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# This function to generate evidence is used for the first example\n",
    "def relu_evidence(logits):\n",
    "    return tf.nn.relu(logits)\n",
    "\n",
    "# This one usually works better and used for the second and third examples\n",
    "# For general settings and different datasets, you may try this one first\n",
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits,-10,10))\n",
    "\n",
    "# This one is another alternative and \n",
    "# usually behaves better than the relu_evidence \n",
    "def softplus_evidence(logits):\n",
    "    return tf.nn.softplus(logits)\n",
    "\n",
    "def KL(alpha):\n",
    "    # print(\"K:\",K)\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    S_beta = tf.reduce_sum(beta,axis=1,keepdims=True)\n",
    "    lnB = tf.compat.v1.lgamma(S_alpha) - tf.reduce_sum(tf.compat.v1.lgamma(alpha),axis=1,keepdims=True)\n",
    "    lnB_uni = tf.reduce_sum(tf.compat.v1.lgamma(beta),axis=1,keepdims=True) - tf.compat.v1.lgamma(S_beta)\n",
    "\n",
    "    dg0 = tf.compat.v1.digamma(S_alpha)\n",
    "    dg1 = tf.compat.v1.digamma(alpha)\n",
    "\n",
    "    kl = tf.reduce_sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "    # print(\"kl\", kl)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8c331170-6138-4e2b-96c1-c00f976c3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence\n",
    "loss_fn = brevis.utils.evidence_crossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62d81f8f-e616-4755-98ec-b64b3b99dc4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prevLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19624/654703115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m#     x = self.exit(x, targets)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#     return x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch_flatten\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch124\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranchLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranchLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prevLayer' is not defined"
     ]
    }
   ],
   "source": [
    "class EvidenceEndpoint_Model(tf.keras.Model):\n",
    "\n",
    "        def __init__(self,prevLayer, targets,name=''):\n",
    "            super().__init__(name=name)\n",
    "\n",
    "            \n",
    "            # self.layer.name = name\n",
    "            # self.name=tf.compat.v1.get_default_graph().unique_name(\"branch\")\n",
    "            # self.branchLayer1 = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))\n",
    "            # self.branchLayer2 = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))\n",
    "            # self.branchLayer3 = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))\n",
    "            # self.exit =branches.branch.CrossEntropyEndpoint(10,name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "            # print(tf.shape(prevLayer))\n",
    "            # inputs = keras.Input(prevLayer)(prevLayer)\n",
    "            # targets = keras.Input(shape=(10,))\n",
    "            branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "            branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "            branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "            output = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer, targets)\n",
    "#             # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer))\n",
    "\n",
    "#             # model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "            model = tf.keras.Model(inputs=(prevLayer,targets), outputs=[output], name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "            self.__dict__.update(model.__dict__)\n",
    "            \n",
    "        # def call(self, input_tensor, targets, training=False):\n",
    "        #     x = self.branchLayer1(input_tensor)\n",
    "        #     x = tf.nn.relu(x)\n",
    "        #     x = self.branchLayer2(x)\n",
    "        #     x = tf.nn.relu(x)\n",
    "        #     x = self.branchLayer3(x)\n",
    "        #     x = self.exit(x, targets)\n",
    "        #     return x\n",
    "    branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "    branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "    branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "    output = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer, targets)\n",
    "    #             # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer))\n",
    "\n",
    "    #             # model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "    model = tf.keras.Model(inputs=(prevLayer,targets), outputs=[output], name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "\n",
    "    \n",
    "        \n",
    "def newBranch_flatten_evidence(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "        \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "            NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "        \"\"\" \n",
    "        branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "        branchLayer = layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "        branchLayer = layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "        output = branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer, targets)\n",
    "        # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ae6fe4a-cc49-46f5-bfd0-928b2c763d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_map_graph_network\n",
      "conv2d_47 :  18   input_39 :  19\n",
      "batch_normalization_47 :  17   conv2d_47 :  18\n",
      "max_pooling2d_41 :  16   batch_normalization_47 :  17\n",
      "conv2d_48 :  15   max_pooling2d_41 :  16\n",
      "batch_normalization_48 :  14   conv2d_48 :  15\n",
      "max_pooling2d_42 :  13   batch_normalization_48 :  14\n",
      "conv2d_49 :  12   max_pooling2d_42 :  13\n",
      "batch_normalization_49 :  11   conv2d_49 :  12\n",
      "conv2d_50 :  10   batch_normalization_49 :  11\n",
      "batch_normalization_50 :  9   conv2d_50 :  10\n",
      "conv2d_51 :  8   batch_normalization_50 :  9\n",
      "batch_normalization_51 :  7   conv2d_51 :  8\n",
      "max_pooling2d_43 :  6   batch_normalization_51 :  7\n",
      "flatten_3 :  5   max_pooling2d_43 :  6\n",
      "dense_3 :  4   flatten_3 :  5\n",
      "dropout_3 :  3   dense_3 :  4\n",
      "main_path124_3 :  2   dropout_3 :  3\n",
      "main_path64_3 :  1   main_path124_3 :  2\n",
      "exit_3 :  0   main_path64_3 :  1\n",
      "branch_e_18 :  12   max_pooling2d_42 :  13\n",
      "branch_e_18 :  12   input_40 :  1\n",
      "\n",
      "preset: Other\n",
      "Model: \"alexnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_39 (InputLayer)          [(None, 227, 227, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 55, 55, 96)   34944       ['input_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 55, 55, 96)  384         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_41 (MaxPooling2D  (None, 27, 27, 96)  0           ['batch_normalization_47[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 27, 27, 256)  614656      ['max_pooling2d_41[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 27, 27, 256)  1024       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooling2D  (None, 13, 13, 256)  0          ['batch_normalization_48[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 13, 13, 384)  885120      ['max_pooling2d_42[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 13, 13, 384)  147840      ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 13, 13, 256)  98560       ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooling2D  (None, 6, 6, 256)   0           ['batch_normalization_51[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 9216)         0           ['max_pooling2d_43[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4096)         37752832    ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4096)         0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " main_path124_3 (Dense)         (None, 124)          508028      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " main_path64_3 (Dense)          (None, 64)           8000        ['main_path124_3[0][0]']         \n",
      "                                                                                                  \n",
      " input_40 (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " exit_3 (Dense)                 (None, 10)           650         ['main_path64_3[0][0]']          \n",
      "                                                                                                  \n",
      " branch_e_18 (Branch)           (None, 10)           5373500     ['max_pooling2d_42[0][0]',       \n",
      "                                                                  'input_40[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,429,634\n",
      "Trainable params: 45,426,882\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class Branch(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,name=''):\n",
    "        super().__init__(name=name)\n",
    "        self.layer = keras.layers.Layer(name=name)\n",
    "        # self.layer.name = name\n",
    "        self.branch_exit = True\n",
    "        self.evidence = brevis.utils.softplus_evidence\n",
    "        self.threshold = 0 \n",
    "        \n",
    "        # self.name=tf.compat.v1.get_default_graph().unique_name(\"branch\")\n",
    "        self.branchLayer1 = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))\n",
    "        self.branchLayer2 = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))\n",
    "        self.branchLayer3 = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))\n",
    "        self.exit = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))\n",
    "        \n",
    "        # self.exit =keras.layers.Dense(10,name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "\n",
    "    def call(self, input_tensor,targets):\n",
    "        x = self.branchLayer1(input_tensor)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.branchLayer2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.branchLayer3(x)\n",
    "        x = self.exit(x,targets)\n",
    "        return x\n",
    "                \n",
    "\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# ### first branch\n",
    "\n",
    "\n",
    "branch_exit = Branch(tf.compat.v1.get_default_graph().unique_name(\"branch_e\"))(x,targets)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"main_path124\"))(x)\n",
    "x = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"main_path64\"))(x)\n",
    "x = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"exit\"))(x)\n",
    "\n",
    "\n",
    "# model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "model = brevis.BranchModel(inputs=(inputs,targets), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "# student_model.save(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ecd7bb52-d681-4bc1-8aae-185089971590",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "Epoch 1/3\n",
      " 421/1406 [=======>......................] - ETA: 1:08 - loss: 12.5582 - exit_3_loss: 1.8282 - branch_e_18_loss: 10.7299 - exit_3_accuracy: 0.3317 - branch_e_18_accuracy: 0.0996 - branch_softmax_16_evidence: 57.4969 - branch_softmax_16_mean_ev_succ: 549.2438 - branch_softmax_16_mean_ev_fail: 574.1542"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8168/2216415865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\core_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_ds, validation_ds, epochs, callbacks, saveName, transfer, customOptions)\u001b[0m\n\u001b[0;32m    526\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m                 callbacks=[tensorboard_cb,checkpoint])\n\u001b[0m\u001b[0;32m    529\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1019\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[0;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1312\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2888\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3688\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3689\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;31m# Run forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \"\"\"\n\u001b[0;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 452\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\core_v2.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m                 \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mx_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_output_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8168/1230218461.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, input_tensor, targets)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranchLayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\branches\\branches.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, labels, learning_rate)\u001b[0m\n\u001b[0;32m    540\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0mtruth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[0mmatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m             \u001b[1;31m# total_evidence = tf.reduce_sum(evidence,1, keepdims=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mmean_succ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevidence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1e-20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1920\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mincompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m   \"\"\"\n\u001b[1;32m-> 1922\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[1;34m(x, y, incompatible_shape_error, name)\u001b[0m\n\u001b[0;32m   3300\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m   3301\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Equal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"incompatible_shape_error\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3302\u001b[1;33m         incompatible_shape_error)\n\u001b[0m\u001b[0;32m   3303\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3304\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_ds, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e35973ac-96b6-4724-bef8-80eb510a5b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_e_3 :  True\n"
     ]
    }
   ],
   "source": [
    "model.set_branchExits(True)\n",
    "model.set_branch_thresholds({'branch_e_2':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb64c3e-c28b-47e5-a28b-367746c10301",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_ds.take(1)\n",
    "x = x.get_single_element()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ffb9d78-2577-4297-82e8-844cf6c914d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.7 ms ± 769 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = model.predict(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96f2fa49-c84b-4bd1-b2e0-d1d0a09f295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preset: Other\n",
      "Model: \"alexnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)          [(None, 227, 227, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 55, 55, 96)   34944       ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 55, 55, 96)  384         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_19 (MaxPooling2D  (None, 27, 27, 96)  0           ['batch_normalization_29[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 27, 27, 256)  614656      ['max_pooling2d_19[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 27, 27, 256)  1024       ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 13, 13, 256)  0          ['batch_normalization_30[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " branch_flatten_6 (Flatten)     (None, 43264)        0           ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " branch124_6 (Dense)            (None, 124)          5364860     ['branch_flatten_6[0][0]']       \n",
      "                                                                                                  \n",
      " branch64_6 (Dense)             (None, 64)           8000        ['branch124_6[0][0]']            \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " branch_softmax_6 (CrossEntropy  (None, 10)          640         ['branch64_6[0][0]',             \n",
      " Endpoint)                                                        'input_16[0][0]']               \n",
      "                                                                                                  \n",
      " branch_finished_3 (branch_fini  (None, 13, 13, 256)  0          ['max_pooling2d_20[0][0]',       \n",
      " shed)                                                            'branch_softmax_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 13, 13, 384)  885120      ['branch_finished_3[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 13, 13, 384)  147840      ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 13, 13, 256)  98560       ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 6, 6, 256)   0           ['batch_normalization_33[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 9216)         0           ['max_pooling2d_21[0][0]']       \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 4096)         37752832    ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 4096)         0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 4096)         16781312    ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 4096)         0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 10)           40970       ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 61,735,238\n",
      "Trainable params: 61,732,486\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# class Branch(tf.keras.Model):\n",
    "\n",
    "#     def __init__(self,name=''):\n",
    "#         super().__init__(name=name)\n",
    "#         self.layer = keras.layers.Layer(name=name)\n",
    "#         # self.layer.name = name\n",
    "#         self.branch_exit = True\n",
    "#         # self.name=tf.compat.v1.get_default_graph().unique_name(\"branch\")\n",
    "#         self.branchLayer1 = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))\n",
    "#         self.branchLayer2 = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))\n",
    "#         self.branchLayer3 = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))\n",
    "#         self.exit = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))\n",
    "#         # self.exit =keras.layers.Dense(10,name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "\n",
    "#     def call(self, input_tensor,targets):\n",
    "#         x = self.branchLayer1(input_tensor)\n",
    "#         x = tf.nn.relu(x)\n",
    "#         x = self.branchLayer2(x)\n",
    "#         x = tf.nn.relu(x)\n",
    "#         x = self.branchLayer3(x)\n",
    "#         x = self.exit(x,targets)\n",
    "#         return x           \n",
    "\n",
    "class Branch(branches.branch.CrossEntropyEndpoint):\n",
    "    '''\n",
    "    an all in one branch that contains the stem of the branch within this layer. The purpose of this design is to have all the layers complete at the same depth level rather\n",
    "    then happening in conjunction with the main path.\n",
    "    potential issues with transparency, managing loss backpropagation.. needs more testing.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, num_outputs, name=''):\n",
    "        super().__init__(name=name, num_outputs = num_outputs)\n",
    "        # self.layer = keras.layers.Layer(name=name)\n",
    "        # self.branch_exit = True\n",
    "        print(self.name)\n",
    "        # self.name=tf.compat.v1.get_default_graph().unique_name(\"branch\")\n",
    "        self.branchLayer1 = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))\n",
    "        self.branchLayer2 = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))\n",
    "        self.branchLayer3 = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))\n",
    "        self.exit = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))\n",
    "        # self.exit =keras.layers.Dense(10,name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(64), self.num_outputs])\n",
    "        \n",
    "    def call(self, input_tensor,targets):\n",
    "        x = self.branchLayer1(input_tensor)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.branchLayer2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.branchLayer3(x)\n",
    "        x = super().call(x,targets)\n",
    "        # x = self.exit(x,targets)\n",
    "        return x  \n",
    "    \n",
    "    \n",
    "# class branch_finished(keras.layers.Reshape):\n",
    "\n",
    "    \n",
    "#     def __init__(self, target_shape, name=''):\n",
    "#         super().__init__(target_shape = name=name)\n",
    "        \n",
    "#     def call(self, input_tensor, branch_result):        \n",
    "#         return input_tensor\n",
    "\n",
    "class branch_finished(keras.layers.Dropout):\n",
    "\n",
    "    def __init__(self, rate=0, name=''):\n",
    "        super().__init__(rate =rate, name=name)\n",
    "        \n",
    "    def call(self, input_tensor,branch_result):\n",
    "        result = super().call(input_tensor)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# ### first branch\n",
    "\n",
    "branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "branch_exit = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer,targets)\n",
    "\n",
    "branch_finish = branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,branch_exit)\n",
    "# branch_exit = Branch(10, tf.compat.v1.get_default_graph().unique_name(\"branch_e\"))(x,targets)\n",
    "\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(branch_finish)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "model = brevis.BranchModel(inputs=(inputs,targets), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "model.compile(loss=['categorical_crossentropy',loss_fn], optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "# student_model.save(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87db9b5f-1cff-45b2-ac3c-ce6ef134e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by name, exact:  True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"conv2d_1\" (type Conv2D).\n\n'list' object has no attribute 'shape'\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 227, 227, 3), dtype=float32)', 'tf.Tensor(shape=(None, 10), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22712/2645273938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                             \u001b[1;31m# \"max_pooling2d_1\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                             \u001b[1;31m# \"dense\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                            ],target_input=True)\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mbrevisModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbrevisModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CategoricalCrossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\core_v2.py\u001b[0m in \u001b[0;36madd_branches\u001b[1;34m(self, branchName, branchPoints, exact, target_input, compact)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;31m# [\"max_pooling2d\",\"max_pooling2d_1\",\"dense\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# branch.newBranch_flatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[0mnewModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbranchPoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbranchName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompact\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch added\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\branches\\branches.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(model, identifier, customBranch, exact, target_input, compact)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;31m# for i in range(len(new_model.layers)):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mexact\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_causal\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Apply causal padding to inputs for Conv1D.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"conv2d_1\" (type Conv2D).\n\n'list' object has no attribute 'shape'\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 227, 227, 3), dtype=float32)', 'tf.Tensor(shape=(None, 10), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "# loss_fn = loss_function()\n",
    "brevisModel = brevis.BranchModel(name=\"../models/alexNetv6_logits.hdf5\")\n",
    "brevisModel.branch_active = True\n",
    "print(brevisModel.branch_active)\n",
    "brevisModel.add_branches([ brevis.branches.branch.newBranch_flatten          ],\n",
    "                            # brevis.branches.branch.branch_conv2d_entropy,\n",
    "                            # brevis.branches.branch.newBranch_flatten],                         \n",
    "                           [\"max_pooling2d\",\n",
    "                            # \"max_pooling2d_1\",\n",
    "                            # \"dense\"\n",
    "                           ],target_input=True)\n",
    "brevisModel.summary()\n",
    "brevisModel.compile(loss=[\"CategoricalCrossentropy\",loss_fn,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")\n",
    "print(\"done\")\n",
    "brevisModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cace4200-bc30-4336-8737-6811ea03ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preset: Other\n",
      "Model: \"alexnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 227, 227, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 55, 55, 96)   34944       ['input_33[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 55, 55, 96)  384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 27, 27, 96)  0           ['batch_normalization_35[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 27, 27, 256)  614656      ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 27, 27, 256)  1024       ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 13, 13, 256)  0          ['batch_normalization_36[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 13, 13, 384)  885120      ['max_pooling2d_23[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 13, 13, 384)  147840      ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 13, 13, 384)  1536       ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 13, 13, 256)  98560       ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 6, 6, 256)   0           ['batch_normalization_39[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 9216)         0           ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 4096)         37752832    ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 4096)         0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 4096)         16781312    ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 4096)         0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 10)           40970       ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 56,361,738\n",
      "Trainable params: 56,358,986\n",
      "Non-trainable params: 2,752\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.engine import node as node_module\n",
    "from kerassurgeon.operations import delete_layer, insert_layer, delete_channels\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "branchPoint = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# ### first branch\n",
    "\n",
    "# branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# branch_exit = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer,targets)\n",
    "\n",
    "# branch_finish = branch_finished(0,name=tf.compat.v1.get_default_graph().unique_name(\"branch_finished\"))(x,branch_exit)\n",
    "# # branch_exit = Branch(10, tf.compat.v1.get_default_graph().unique_name(\"branch_e\"))(x,targets)\n",
    "\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(branchPoint)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# model = keras.Model(inputs=(inputs), outputs=[x,branch_exit], name=\"alexnet\")\n",
    "model = brevis.BranchModel(inputs=(inputs,targets), outputs=[x], name=\"alexnet\")\n",
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "model.compile(loss=['categorical_crossentropy',loss_fn], optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "# student_model.save(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c67b4bab-1b9f-403a-ae24-8050f908605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 227, 227, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 55, 55, 96)       384       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 27, 27, 96)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " INSERT (Dropout)            (None, 27, 27, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 27, 27, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 13, 13, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 13, 13, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 13, 13, 384)       147840    \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 13, 13, 384)      1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 13, 13, 256)       98560     \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 13, 13, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " input_34 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,361,738\n",
      "Trainable params: 56,358,986\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def insert_intermediate_layer_in_keras(model, layer_id, new_layer):\n",
    "    from keras.models import Model\n",
    "\n",
    "    layers = [l for l in model.layers]\n",
    "\n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i == layer_id:\n",
    "            x = new_layer(x)\n",
    "        x = layers[i](x)\n",
    "\n",
    "    new_model = Model(inputs=layers[0].input, outputs=x)\n",
    "    return new_model\n",
    "\n",
    "x = keras.layers.Dropout(0.5,name = \"INSERT\")\n",
    "new_model = insert_intermediate_layer_in_keras(model,5,x)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ae7806-3603-425c-a8b4-a7692ff7a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = brevis.dataset.prepare.test_set(tf.keras.datasets.cifar10.load_data(),1,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1159379b-9685-440e-bad5-ba2fa8460ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch_softmax_6 :  True\n",
      "branch_softmax_6 set to:  0\n"
     ]
    }
   ],
   "source": [
    "model.set_branchExits(True)\n",
    "model.set_branch_thresholds({'branch_softmax_6':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d3c72a3-2355-4c9b-9894-d2a63703a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_set.take(1)\n",
    "x = x.get_single_element()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8893a9bc-3ae0-45bc-8137-dcb3a75de49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32), [array([[  7.6376023, -25.24926  ,   1.3352499,  -9.766134 , -17.689587 ,\n",
      "          4.134639 ,  -5.897874 , -17.91811  , -13.5564375,  16.874842 ]],\n",
      "      dtype=float32), array([[  7.6376023, -25.24926  ,   1.3352499,  -9.766134 , -17.689587 ,\n",
      "          4.134639 ,  -5.897874 , -17.91811  , -13.5564375,  16.874842 ]],\n",
      "      dtype=float32)]]\n",
      "tf.Tensor([[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "result = model.predict(x[0])\n",
    "print(result)\n",
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e71f90-0d38-4aa6-8854-2099d9da9905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.9 ms ± 1.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "result = model.predict(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e313cf28-c79a-40ad-8a4b-14e764cdf272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 3.2385 - dense_17_loss: 1.6986 - branch_softmax_6_loss: 1.5399 - dense_17_accuracy: 0.4289 - branch_softmax_6_accuracy: 0.4630 - branch_softmax_6_evidence: 0.0213 - branch_softmax_6_mean_ev_succ: 0.2212 - branch_softmax_6_mean_ev_fail: 0.2099\n",
      "Epoch 1: saving model to models\\alexnet_branched.hdf5.hdf5\n",
      "1406/1406 [==============================] - 136s 93ms/step - loss: 3.2385 - dense_17_loss: 1.6986 - branch_softmax_6_loss: 1.5399 - dense_17_accuracy: 0.4289 - branch_softmax_6_accuracy: 0.4630 - branch_softmax_6_evidence: 0.0213 - branch_softmax_6_mean_ev_succ: 0.2212 - branch_softmax_6_mean_ev_fail: 0.2099 - val_loss: 2.5721 - val_dense_17_loss: 1.3276 - val_branch_softmax_6_loss: 1.2444 - val_dense_17_accuracy: 0.5300 - val_branch_softmax_6_accuracy: 0.5649 - val_branch_softmax_6_evidence: 0.0084 - val_branch_softmax_6_mean_ev_succ: 0.0838 - val_branch_softmax_6_mean_ev_fail: 0.0852\n",
      "<keras.callbacks.History object at 0x000001AD93A98FC8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x1adbb3077c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_ds, 1,transfer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c14c9939-7cc1-4416-97c7-640371bbfc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "1406/1406 [==============================] - ETA: 0s - loss: 3.2513 - dense_14_loss: 1.7132 - branch_softmax_5_loss: 1.5380 - dense_14_accuracy: 0.4258 - branch_softmax_5_accuracy: 0.4601 - branch_softmax_5_evidence: 0.0210 - branch_softmax_5_mean_ev_succ: 0.2225 - branch_softmax_5_mean_ev_fail: 0.1990\n",
      "Epoch 1: saving model to models\\alexnet_branched.hdf5.hdf5\n",
      "1406/1406 [==============================] - 128s 88ms/step - loss: 3.2513 - dense_14_loss: 1.7132 - branch_softmax_5_loss: 1.5380 - dense_14_accuracy: 0.4258 - branch_softmax_5_accuracy: 0.4601 - branch_softmax_5_evidence: 0.0210 - branch_softmax_5_mean_ev_succ: 0.2225 - branch_softmax_5_mean_ev_fail: 0.1990 - val_loss: 2.5119 - val_dense_14_loss: 1.2622 - val_branch_softmax_5_loss: 1.2497 - val_dense_14_accuracy: 0.5493 - val_branch_softmax_5_accuracy: 0.5541 - val_branch_softmax_5_evidence: 0.0107 - val_branch_softmax_5_mean_ev_succ: 0.1103 - val_branch_softmax_5_mean_ev_fail: 0.1040\n",
      "<keras.callbacks.History object at 0x000001AD9B127B08>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x1adbb295508>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,validation_ds, 1,transfer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5865ef5c-1bb4-4c14-8328-d9d18c9a9069",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Inputs to a layer should be tensors. Got: <keras.layers.core.lambda_layer.Lambda object at 0x0000024F56DDA908>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19624/1883487169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# branch = model(x,targets,name=\"branch\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# ### first branch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch_flatten\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch124\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranchLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mbranchLayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"branch64\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbranchLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# have a `shape` attribute.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <keras.layers.core.lambda_layer.Lambda object at 0x0000024F56DDA908>"
     ]
    }
   ],
   "source": [
    "def makebranch(prevLayer,targets):\n",
    "    branch = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "    branch = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branch)\n",
    "    branch = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branch)\n",
    "    output = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branch, targets)\n",
    "    return output\n",
    "\n",
    "# class newBranch(prevLayer,targets):\n",
    "#     def __init__(self):\n",
    "#         super(newBranch, self).__init__()\n",
    "        \n",
    "#         branch = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#         branch = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branch)\n",
    "#         branch = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branch)\n",
    "#         output = brevis.branches.branch.CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branch, targets)\n",
    "#         self.scale = tf.Variable(1.)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         return inputs * self.scale\n",
    "    \n",
    "\n",
    "    \n",
    "seed = 42\n",
    "# random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# x = keras.layers.Flatten()(x)\n",
    "# x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "branch = keras.layers.Lambda(lambda j,y: makebranch(j,y),x,targets)\n",
    "\n",
    "# branch = model(x,targets,name=\"branch\")\n",
    "# ### first branch\n",
    "branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branch)\n",
    "branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "x = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "\n",
    "\n",
    "student_model = keras.Model(inputs=(inputs), outputs=[x,branch], name=\"alexnet\")\n",
    "\n",
    "new_model = keras.Model(student_model.inputs, student_model.outputs, name=student_model.name)\n",
    "new_model.summary()\n",
    "\n",
    "# student_model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "# student_model.save(\"models/alexNetv6_second_Exit.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6ed81a-8a86-4dc3-81f5-0f2bb5d2a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(model,  customBranch = [],identifier =[\"\"], exact = True, target_input= True, compact = False):\n",
    "        \"\"\" add branches to the provided model, aka modifying an existing model to include branches.\n",
    "            identifier: takes a list of names of layers to branch on is blank, branches will be added to all layers except the input and final layer. Can be a list of layer numbers, following the numbering format of model.layers[]\n",
    "            If identifier is not blank, a branch will be added to each layer with identifier in its name. (identifier = \"dense\", all dense layers will be branched.)\n",
    "            Warning! individual layers are defined according to how TF defines them. this means that for layers that would be normally grouped, they will be treated as individual layers (conv2d, pooling, flatten, etc)\n",
    "            customBranch: optional function that can be passed to provide a custom branch to be inserted. Check \"newBranch\" function for default shape of branches and how to build custom branching function. Can be provided as a list and each branch will iterate through provided customBranches, repeating last the last branch until function completes\n",
    "        \"\"\"\n",
    "        # model = keras.Model([model.input], [model_old.output], name=\"{}_branched\".format(model_old.name))\n",
    "        # model.summary()\n",
    "\n",
    "        # outputs = [model.outputs]\n",
    "        # outputs.append(newBranch(model.layers[6].output))\n",
    "        # new_model = keras.Model([model.input], outputs, name=\"{}_branched\".format(model.name))\n",
    "        # new_model.summary()\n",
    "        outputs = []\n",
    "        for i in model.outputs:\n",
    "            outputs.append(i)\n",
    "        print(\"outputs\", outputs)\n",
    "        inputs = []\n",
    "        ready = False\n",
    "        \n",
    "        targets= None\n",
    "        \n",
    "        for i in model.inputs:\n",
    "            if i.name == \"targets\":\n",
    "                ready = True\n",
    "            inputs.append(i)\n",
    "        if target_input:\n",
    "            print(\"targets already present? \",ready)\n",
    "\n",
    "            if not ready:\n",
    "                print(\"added targets\")\n",
    "                targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "                inputs.append(targets) #shape is (1,) for sparse_categorical_crossentropy\n",
    "            else:\n",
    "                targets = model.get_layer('targets').output\n",
    "\n",
    "        #add targets as an input to the model so it can be used for the custom losses.\n",
    "        #   input size is the size of the     \n",
    "        #add target input \n",
    "        new_model = brevis.BranchModel(inputs=inputs, outputs=outputs,name = model.name, transfer=model.transfer, custom_objects=model.custom_objects)\n",
    "\n",
    "        # outputs = []\n",
    "\n",
    "\n",
    "        old_output = outputs\n",
    "        # outputs.append(i in model.outputs) #get model outputs that already exist \n",
    "\n",
    "        if type(identifier) != list:\n",
    "            identifier = [identifier]\n",
    "\n",
    "        if type(customBranch) != list:\n",
    "            customBranch = [customBranch]\n",
    "        if len(customBranch) == 0:\n",
    "            customBranch = [branch.newBranch_flatten]\n",
    "        branches = 0\n",
    "        # print(customBranch)\n",
    "        if len(identifier) > 0:\n",
    "            # print(\"Matching Branchpoint by id number\")\n",
    "            if type(identifier[0]) == int:\n",
    "                for i in identifier: \n",
    "                    try:\n",
    "                        outputs.append(customBranch[min(branches, len(customBranch))-1](new_model.layers[i].output,targets = targets))\n",
    "                        branches=branches+1\n",
    "                    except:\n",
    "                        pass\n",
    "            else:\n",
    "                print(\"Matching Branchpoint by name\")\n",
    "                for i in range(len(new_model.layers)):\n",
    "                    # print(new_model.layers[i].name)\n",
    "                    if exact == True:\n",
    "                        if new_model.layers[i].name in identifier:\n",
    "                            print(\"add Branch to branch point \",new_model.layers[i].name)\n",
    "                            outputs.append(customBranch[min(branches, len(customBranch)-1)](new_model.layers[i].output,targets = targets).outputs)\n",
    "                            branches=branches+1\n",
    "                    else:\n",
    "                        if any(id in new_model.layers[i].name for id in identifier):\n",
    "                            print(\"add Branch to branch point \",new_model.layers[i].name)\n",
    "                            outputs.append(customBranch[min(branches, len(customBranch)-1)](new_model.layers[i].output,targets = targets))\n",
    "                            branches=branches+1\n",
    "        else: #if identifier is blank or empty\n",
    "            # print(\"nothing\")\n",
    "            for i in range(1-len(new_model.layers)-1):\n",
    "                # print(new_model.layers[i].name)\n",
    "                # if \"dense\" in new_model.layers[i].name:\n",
    "                # outputs = newBranch(new_model.layers[i].output,outputs)\n",
    "                outputs = customBranch[min(branches, len(customBranch))-1](new_model.layers[i].output,outputs,targets = targets)\n",
    "                branches=branches+1\n",
    "            # for j in range(len(new_model.layers[i].inbound_nodes)):\n",
    "            #     print(dir(new_model.layers[i].inbound_nodes[j]))\n",
    "            #     print(\"inboundNode: \" + new_model.layers[i].inbound_nodes[j].name)\n",
    "            #     print(\"outboundNode: \" + new_model.layers[i].outbound_nodes[j].name)\n",
    "        # print(outputs)\n",
    "        # print(new_model.input)\n",
    "        # outputs.pop(0)\n",
    "        # print(outputs)\n",
    "        # input_layer = layers.Input(batch_shape=new_model.layers[0].input_shape)\n",
    "        print(outputs)\n",
    "        new_model = brevis.BranchModel([inputs], [outputs], name = new_model.name, transfer = new_model.transfer, custom_objects=new_model.custom_objects)\n",
    "\n",
    "        new_model.branch_active=model.branch_active        \n",
    "        # new_model.summary()\n",
    "\n",
    "        return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70bd21fa-e3d5-4952-994b-44fd6a2e4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brevisModel = brevis.BranchModel(name=\"../models/alexNetv6_logits.hdf5\")\n",
    "# brevisModel.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2132af77-4d22-41d3-8d2c-fc29dd8f83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_map_graph_network\n",
      "True\n",
      "outputs [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_2')>]\n",
      "targets already present?  False\n",
      "added targets\n",
      "_map_graph_network\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  max_pooling2d\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'dense_2')>, [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_softmax_1')>]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 96), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'input_2'\") at layer \"branch_flatten_1\". The following previous layers were accessed without issue: ['conv2d_1', 'batch_normalization', 'max_pooling2d', 'conv2d_2', 'batch_normalization_1', 'max_pooling2d_1', 'conv2d_3', 'batch_normalization_2', 'conv2d_4', 'batch_normalization_3', 'conv2d_5', 'batch_normalization_4', 'max_pooling2d_2', 'flatten', 'dense']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19624/3526310864.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m                             \u001b[1;31m# \"max_pooling2d_1\",\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                             \u001b[1;31m# \"dense\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                            ],target_input=True)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19624/3174783131.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(model, customBranch, identifier, exact, target_input, compact)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# input_layer = layers.Input(batch_shape=new_model.layers[0].input_shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mnew_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrevis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBranchModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch_active\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch_active\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\core_v2.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, model, transfer, custom_objects)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBranchModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBranchModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBranchModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[1;32m--> 230\u001b[1;33m         self.inputs, self.outputs)\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1037\u001b[1;33m                 \u001b[1;34mf'Graph disconnected: cannot obtain value for tensor {x} '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1038\u001b[0m                 \u001b[1;34mf'at layer \"{layer.name}\". The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m                 f'were accessed without issue: {layers_with_complete_input}')\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 27, 27, 96), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'input_2'\") at layer \"branch_flatten_1\". The following previous layers were accessed without issue: ['conv2d_1', 'batch_normalization', 'max_pooling2d', 'conv2d_2', 'batch_normalization_1', 'max_pooling2d_1', 'conv2d_3', 'batch_normalization_2', 'conv2d_4', 'batch_normalization_3', 'conv2d_5', 'batch_normalization_4', 'max_pooling2d_2', 'flatten', 'dense']"
     ]
    }
   ],
   "source": [
    "# brevisModel = brevis.BranchModel(name=\"../models/alexNetv6_logits_flat.hdf5\")\n",
    "# brevisModel.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")\n",
    "# train_ds, test_ds, validation_ds = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)\n",
    "loss_fn = brevis.utils.evidence_crossentropy()\n",
    "# loss_fn = loss_function()\n",
    "brevisModel = brevis.BranchModel(name=\"../models/alexNetv6_logits.hdf5\")\n",
    "brevisModel.branch_active = True\n",
    "print(brevisModel.branch_active)\n",
    "model2 = add(brevisModel,[  \n",
    "                            EvidenceEndpoint_Model\n",
    "                            # brevis.branches.branch.newBranch_flatten\n",
    "                            ],\n",
    "                            # brevis.branches.branch.branch_conv2d_entropy,\n",
    "                            # brevis.branches.branch.newBranch_flatten],\n",
    "                         \n",
    "                           [\"max_pooling2d\",\n",
    "                            # \"max_pooling2d_1\",\n",
    "                            # \"dense\"\n",
    "                           ],target_input=True)\n",
    "print(model2)\n",
    "print(model2.summary())\n",
    "print(brevisModel.branch_active)\n",
    "brevisModel.compile(loss=[\"CategoricalCrossentropy\",loss_fn,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")\n",
    "print(\"done\")\n",
    "# brevisModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02504ffe-4cef-4aec-9e56-59efa934b43c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5028/3559581298.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbrevisModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "brevisModel.fit(train_ds, validation_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a523b59e-7c09-4c4f-abf5-d89f1f198251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 23s 75ms/step - loss: 3.4742 - dense_2_loss: 0.6684 - branch_softmax_loss: 1.1531 - branch_softmax_1_loss: 0.8553 - branch_softmax_2_loss: 0.7974 - dense_2_accuracy: 0.8117 - branch_softmax_accuracy: 0.6117 - branch_softmax_1_accuracy: 0.7096 - branch_softmax_2_accuracy: 0.8062 - branch_softmax_evidence: 0.0066 - branch_softmax_mean_ev_succ: 0.0813 - branch_softmax_mean_ev_fail: 0.0419 - branch_softmax_1_evidence: 0.0100 - branch_softmax_1_mean_ev_succ: 0.1280 - branch_softmax_1_mean_ev_fail: 0.0309 - branch_softmax_2_evidence: 0.2013 - branch_softmax_2_mean_ev_succ: 2.4431 - branch_softmax_2_mean_ev_fail: 0.2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4741899967193604,\n",
       " 0.6683692336082458,\n",
       " 1.153076410293579,\n",
       " 0.8553193211555481,\n",
       " 0.797425389289856,\n",
       " 0.8116987347602844,\n",
       " 0.6116786599159241,\n",
       " 0.7096354365348816,\n",
       " 0.8061898946762085,\n",
       " 0.006618714891374111,\n",
       " 0.0812828317284584,\n",
       " 0.04191126674413681,\n",
       " 0.0099885119125247,\n",
       " 0.12796013057231903,\n",
       " 0.03091173991560936,\n",
       " 0.2012537270784378,\n",
       " 2.443101644515991,\n",
       " 0.20794060826301575]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brevisModel.inputs\n",
    "brevisModel.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5d11d9-e0ce-4a22-8215-e739d4990779",
   "metadata": {},
   "outputs": [],
   "source": [
    "brevisModel.save(\"../models/brevis_alex_Bflat.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d35b54-7781-4a00-b068-3cf86719f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyEndpoint(branches.branch.BranchEndpoint):\n",
    "    def __init__(self, num_outputs, name=None, **kwargs):\n",
    "        super(CrossEntropyEndpoint, self).__init__(name=name)\n",
    "        self.num_outputs = num_outputs\n",
    "#             self.kl = tf.keras.losses.KLDivergence()\n",
    "        self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "#             self.loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "        self.evidence = brevis.utils.softplus_evidence\n",
    "#             self.evidence = tf.compat.v1.distributions.Dirichlet\n",
    "        self.temperature = 10\n",
    "        self.lmb = 0.005\n",
    "        self.branch_exit = True\n",
    "        self.evid = []\n",
    "    def build(self, input_shape):\n",
    "        tf.print(\"inputShape\",input_shape)\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_outputs': self.num_outputs,\n",
    "            'name': self.name\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, labels,learning_rate=1):\n",
    "        outputs = tf.matmul(inputs,self.kernel)\n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "\n",
    "        evidence = self.evidence (outputs)\n",
    "        self.evid.append( tf.reduce_sum(evidence))\n",
    "        alpha = evidence + 1\n",
    "        u = self.num_outputs / tf.reduce_sum(alpha, axis=1, keepdims=True) #uncertainty\n",
    "\n",
    "        # prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        \n",
    "        # total_evidence = tf.reduce_sum(evidence,1, keepdims=True)\n",
    "        mean_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
    "        mean_fail = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) )\n",
    "\n",
    "        self.add_metric(evidence, name=self.name+\"_evidence\")\n",
    "        self.add_metric(mean_succ, name=self.name+\"_mean_ev_succ\",aggregation='mean')\n",
    "        self.add_metric(mean_fail, name=self.name+\"_mean_ev_fail\",aggregation='mean')\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "75dcf31d-ac87-46ce-a703-ea372bef89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targetsis : True\n",
      "adding targets to inputs\n"
     ]
    }
   ],
   "source": [
    "test_set = brevis.dataset.prepare.test_set(tf.keras.datasets.cifar10.load_data(),32,(227,227),include_targets=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "063188b6-7e0e-452c-a4d9-3f1b941218eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 22s 71ms/step - loss: 3.4742 - dense_2_loss: 0.6684 - branch_softmax_loss: 1.1531 - branch_softmax_1_loss: 0.8553 - branch_softmax_2_loss: 0.7974 - dense_2_accuracy: 0.8117 - branch_softmax_accuracy: 0.6117 - branch_softmax_1_accuracy: 0.7096 - branch_softmax_2_accuracy: 0.8062 - branch_softmax_evidence: 0.0066 - branch_softmax_mean_ev_succ: 0.0813 - branch_softmax_mean_ev_fail: 0.0419 - branch_softmax_1_evidence: 0.0100 - branch_softmax_1_mean_ev_succ: 0.1280 - branch_softmax_1_mean_ev_fail: 0.0309 - branch_softmax_2_evidence: 0.2013 - branch_softmax_2_mean_ev_succ: 2.4431 - branch_softmax_2_mean_ev_fail: 0.2079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4741899967193604,\n",
       " 0.6683692336082458,\n",
       " 1.153076410293579,\n",
       " 0.8553193211555481,\n",
       " 0.797425389289856,\n",
       " 0.8116987347602844,\n",
       " 0.6116786599159241,\n",
       " 0.7096354365348816,\n",
       " 0.8061898946762085,\n",
       " 0.006618714891374111,\n",
       " 0.0812828317284584,\n",
       " 0.04191126674413681,\n",
       " 0.0099885119125247,\n",
       " 0.12796013057231903,\n",
       " 0.03091173991560936,\n",
       " 0.2012537270784378,\n",
       " 2.443101644515991,\n",
       " 0.20794060826301575]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brevisModel.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dd6705a2-8087-4538-a104-2db66bea215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_fn(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence\n",
    "# loss_fn = brevis.utils.evidence_crossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a04df65-c3a3-497f-87cd-fc0f2029105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_map_graph_network\n",
      "\n",
      "preset: Other\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "_map_graph_network\n",
      "\n",
      "preset: Other\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import brevis\n",
    "from brevis import branches\n",
    "from brevis import evaluate\n",
    "brevisModel = brevis.BranchModel(name=\"../models/brevis_alex_Bflat.hdf5\")\n",
    "brevisModel.compile(loss=[\"CategoricalCrossentropy\",loss_fn,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9), preset=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9c4454de-07be-4b2e-9c79-7383aa6c4e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[1.0044565200805664, 0.24729721248149872, 0.31445106863975525, 0.2363983392715454, 0.206309974193573, 1.0, 1.0, 1.0, 1.0, 0.002966057974845171, 0.029660580679774284, 0.0, 0.009362570010125637, 0.09362570196390152, 0.0, 0.04273209348320961, 0.4273209273815155, 0.0]\n",
      "10000ction: 9999 of 10000\n"
     ]
    }
   ],
   "source": [
    "stopping_point =None\n",
    "num_outputs = len(brevisModel.outputs)\n",
    "print(num_outputs)\n",
    "predictions = []\n",
    "labels = []\n",
    "pClass = []\n",
    "predictions=[]\n",
    "pEvidence = []\n",
    "pUncertainty=[]\n",
    "pOverlap=[]\n",
    "\n",
    "Outputs = pd.DataFrame()\n",
    "pAcc=[]\n",
    "for i in range(num_outputs):\n",
    "    pClass.append([])\n",
    "    predictions.append([])\n",
    "    pEvidence.append([])\n",
    "    pUncertainty.append([])\n",
    "    pAcc.append([])\n",
    "    pOverlap.append([])\n",
    "for i, (x,y) in enumerate(test_set):\n",
    "    if stopping_point and i > stopping_point:\n",
    "        break\n",
    "    print(\"prediction: {} of {}\".format(i,len(test_set)),end='\\r')\n",
    "    if True: \n",
    "        result = brevisModel.test_on_batch(x,y)\n",
    "        if i < 1:\n",
    "            print(result)\n",
    "#             print(result)\n",
    "        for j in range(num_outputs):\n",
    "            # print(\"output\",j)\n",
    "            pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "            pAcc[j].append(result[j+(num_outputs)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "            # if j ==0:\n",
    "                # pEvidence[j].append(0)\n",
    "            # else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "            pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "            pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "    else:\n",
    "        result = model.predict(x)[0]\n",
    "        if i < 2:\n",
    "            print(result)\n",
    "\n",
    "        for j in range(num_outputs):\n",
    "            pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "            # print(pClass[j])\n",
    "            # print(result)\n",
    "            prediction = np.argmax(result[j])\n",
    "            if prediction == pClass[j][i]:\n",
    "                pAcc[j].append(1)  \n",
    "            else:\n",
    "                pAcc[j].append(0)  \n",
    "            # print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "            pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "            pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "    '''\n",
    "    overlap\n",
    "    if zero, both match, if else they don't match\n",
    "    TT 1-1 =0\n",
    "    TF 1-0 =1\n",
    "\n",
    "    FT 0-1 = -1\n",
    "    FF 0-0 =0\n",
    "\n",
    "    '''\n",
    "Outputs=[]\n",
    "for j in range(num_outputs):\n",
    "    Predictions = pd.DataFrame({\"label\":pClass[j],\"evidence\":pEvidence[j],\"Acc\":pAcc[j], \"overlap\":pOverlap[j]})\n",
    "    Outputs.append(Predictions)\n",
    "print(len(Outputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2a78b460-4c73-4eef-b8a7-f661087ce786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# sklearn.set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6196ed28-8fd4-41ef-a233-2d61c31b5350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      label  evidence           Acc  overlap\n",
       " 0         3       1.0  2.063100e-01      0.0\n",
       " 1         8       1.0  2.910729e-01      0.0\n",
       " 2         8       0.0  1.433587e+00      0.0\n",
       " 3         0       1.0  1.881812e-03      0.0\n",
       " 4         6       0.0  4.224181e-01      0.0\n",
       " ...     ...       ...           ...      ...\n",
       " 9995      8       0.0  2.220496e-01      0.0\n",
       " 9996      3       0.0  1.469482e+00      0.0\n",
       " 9997      5       1.0  3.157306e-03      0.0\n",
       " 9998      1       0.0  3.743881e-01      0.0\n",
       " 9999      7       1.0  1.192093e-07      0.0\n",
       " \n",
       " [10000 rows x 4 columns],\n",
       "       label  evidence  Acc   overlap\n",
       " 0         3  0.002966  1.0 -0.793690\n",
       " 1         8  0.003421  1.0 -0.708927\n",
       " 2         8  0.012931  0.0  1.433587\n",
       " 3         0  0.004787  1.0 -0.998118\n",
       " 4         6  0.012468  1.0 -0.577582\n",
       " ...     ...       ...  ...       ...\n",
       " 9995      8  0.003613  1.0 -0.777950\n",
       " 9996      3  0.002980  0.0  1.469482\n",
       " 9997      5  0.000017  1.0 -0.996843\n",
       " 9998      1  0.001589  1.0 -0.625612\n",
       " 9999      7  0.004345  1.0 -1.000000\n",
       " \n",
       " [10000 rows x 4 columns],\n",
       "       label  evidence  Acc   overlap\n",
       " 0         3  0.009363  1.0 -0.793690\n",
       " 1         8  0.001202  1.0 -0.708927\n",
       " 2         8  0.000694  0.0  1.433587\n",
       " 3         0  0.000273  1.0 -0.998118\n",
       " 4         6  0.000140  0.0  0.422418\n",
       " ...     ...       ...  ...       ...\n",
       " 9995      8  0.002443  0.0  0.222050\n",
       " 9996      3  0.001373  0.0  1.469482\n",
       " 9997      5  0.001344  1.0 -0.996843\n",
       " 9998      1  0.000014  0.0  0.374388\n",
       " 9999      7  0.035630  1.0 -1.000000\n",
       " \n",
       " [10000 rows x 4 columns],\n",
       "       label  evidence  Acc   overlap\n",
       " 0         3  0.042732  1.0 -0.793690\n",
       " 1         8  0.014800  1.0 -0.708927\n",
       " 2         8  0.001199  0.0  1.433587\n",
       " 3         0  0.094376  1.0 -0.998118\n",
       " 4         6  0.003535  1.0 -0.577582\n",
       " ...     ...       ...  ...       ...\n",
       " 9995      8  0.000952  0.0  0.222050\n",
       " 9996      3  0.000890  0.0  1.469482\n",
       " 9997      5  0.207973  1.0 -0.996843\n",
       " 9998      1  0.002109  0.0  0.374388\n",
       " 9999      7  0.739164  1.0 -1.000000\n",
       " \n",
       " [10000 rows x 4 columns]]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Outputs\n",
    "# features = Outputs[0][['label', 'evidence']].values\n",
    "# print(features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0aba8329-5040-476b-8e94-e2c0564d3b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label  evidence  overlap\n",
      "Acc                          \n",
      "0.0   1883      1883     1883\n",
      "1.0   8117      8117     8117\n",
      "[5.         0.08074479]\n",
      "[8.00000000e+00 3.42087122e-03]\n"
     ]
    }
   ],
   "source": [
    "# features, true_labels = make_blobs(\n",
    "#     n_samples=200,\n",
    "#     centers=3,\n",
    "#     cluster_std=2.75,\n",
    "#     random_state=42\n",
    "# # )\n",
    "print(Outputs[1].groupby('Acc').count())\n",
    "# Trues = Outputs[1][['label', 'evidence']].loc[Outputs[1]['Acc']==1]\n",
    "# print(len(Trues))\n",
    "# # Trues['label'] = Trues['label']+.2\n",
    "# # Trues = Trues.values\n",
    "\n",
    "\n",
    "# Falses = Outputs[1][['label', 'evidence']].loc[Outputs[1]['Acc']==0].values\n",
    "# print(len(Falses))\n",
    "features = Outputs[1][['label', 'evidence']].values\n",
    "test_x = features[:2000]\n",
    "\n",
    "train_x = features[2000:]\n",
    "print(train_x[1])\n",
    "print(test_x[1])\n",
    "# true_labels = Outputs[1].Acc.replace([0,1],[\"red\",\"blue\"]).values\n",
    "true_labels = Outputs[1].Acc.values\n",
    "test_y = true_labels[:2000]\n",
    "\n",
    "train_y = true_labels[2000:]\n",
    "# print(train_y[1])\n",
    "# print(test_y[1])\n",
    "scaler = StandardScaler()\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "\n",
    "\n",
    "# print(true_labels)\n",
    "# Outputs[1][['label','evidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "61ddfc1e-3fb8-42c0-8dd8-eb1c9ac04783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanity\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: No contour levels were found within the data range.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# we create two clusters of random points\n",
    "n_samples_1 = 1000\n",
    "n_samples_2 = 100\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 0.5]\n",
    "X, y = make_blobs(\n",
    "    n_samples=[n_samples_1, n_samples_2],\n",
    "    centers=centers,\n",
    "    cluster_std=clusters_std,\n",
    "    random_state=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "# print(X)\n",
    "# print(y)\n",
    "X = test_x\n",
    "y = test_y\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel=\"linear\", C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel=\"linear\", class_weight=\"balanced\")\n",
    "wclf.fit(X, y)\n",
    "\n",
    "# plot the samples\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors=\"k\")\n",
    "\n",
    "# plot the decision functions for both classifiers\n",
    "ax = plt.gca()\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "# print(XX)\n",
    "# get the separating hyperplane\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "# plt.plot(Z)\n",
    "# plot decision boundary and margins\n",
    "a = ax.contour(XX, YY, Z, colors=\"k\", levels=[0], alpha=0.5, linestyles=[\"-\"])\n",
    "\n",
    "# get the separating hyperplane for weighted classes\n",
    "Z = wclf.decision_function(xy).reshape(XX.shape)\n",
    "# print(Z)\n",
    "# plot decision boundary and margins for weighted classes\n",
    "b = ax.contour(XX, YY, Z, colors=\"r\", levels=[0], alpha=0.5, linestyles=[\"-\"])\n",
    "\n",
    "plt.legend(\n",
    "    [a.collections[0], b.collections[0]],\n",
    "    [\"non weighted\", \"weighted\"],\n",
    "    loc=\"upper right\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "dd5bcd57-e7ef-4e36-83a0-2bbde18cdf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_random_dataset(size):\n",
    "    \"\"\" Generate a random dataset and that follows a quadratic  distribution\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    y = []\n",
    "    target = []\n",
    "    for i in range(size):\n",
    "        # class zero\n",
    "        x.append(np.round(random.uniform(0, 2.5), 1))\n",
    "        y.append(np.round(random.uniform(0, 20), 1))\n",
    "        target.append(0)\n",
    "        # class one\n",
    "        x.append(np.round(random.uniform(1, 5), 2))\n",
    "        y.append(np.round(random.uniform(20, 25), 2))\n",
    "        target.append(1)\n",
    "        x.append(np.round(random.uniform(3, 5), 2))\n",
    "        y.append(np.round(random.uniform(5, 25), 2))\n",
    "        target.append(1)\n",
    "    df_x = pd.DataFrame(data=x)\n",
    "    df_y = pd.DataFrame(data=y)\n",
    "    df_target = pd.DataFrame(data=target)\n",
    "    data_frame = pd.concat([df_x, df_y], ignore_index=True, axis=1)\n",
    "    data_frame = pd.concat([data_frame, df_target], ignore_index=True, axis=1)\n",
    "    data_frame.columns = ['x', 'y', 'target']\n",
    "    return data_frame\n",
    "\n",
    "# Generate dataset\n",
    "size = 100\n",
    "dataset = generate_random_dataset(size)\n",
    "features = dataset[['x', 'y']]\n",
    "label = dataset['target']\n",
    "# Hold out 20% of the dataset for training\n",
    "test_size = int(np.round(size * 0.2, 0))\n",
    "# Split dataset into training and testing sets\n",
    "x_train = features[:-test_size].values\n",
    "y_train = label[:-test_size].values\n",
    "x_test = features[-test_size:].values\n",
    "y_test = label[-test_size:].values\n",
    "# Plotting the training set\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "# removing to and right border\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# adding major gridlines\n",
    "ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "ax.scatter(features[:-test_size]['x'], features[:-test_size]['y'], color=\"#8C7298\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac19ef7-dee5-47c0-857a-856a46cd5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='poly', degree=2)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3dc7ea3b-e26e-444a-9b95-2a9b044d042a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23892/599299328.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Get the separating hyperplane\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m# Draw the decision boundary and margins\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[0mtransformation\u001b[0m \u001b[0mof\u001b[0m \u001b[0movo\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \"\"\"\n\u001b[1;32m--> 756\u001b[1;33m         \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function_shape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ovr\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_ovr_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mdec_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mdec_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;31m# In binary case, we need to flip the sign of coef, intercept and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         )\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAGXCAYAAABcJ/NsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA94klEQVR4nO3deZgddZ3v8U9VnXN6X9KdnZB0ErKRECEgiwiMQAwDorKGRBoHGK9y0RH1Ojg8XHDUB1DHuc+93Atuc525riDoTBxQBATCEiIkJKGTzp7OvvS+nD5rVd0/Oumk0+ecdMfk1Omq9+t5oqYqHb+p3zl1PudXv8VwXdcVAAAA4DOm1wUAAAAApwNBFwAAAL5E0AUAAIAvEXQBAADgSwRdAAAA+BJBFwAAAL5E0D1OU1OT1yUEHm1QGGgH79EGhYF28B5tUBhGYjsQdI8Ti8W8LiHwaIPCQDt4jzYoDLSD92iDwjAS24GgCwAAAF8i6AIAAMCXCLoAAADwJYIuAAAAfImgCwAAAF8i6AIAAMCXCLoAAADwJYIuAAAAfImgCwAAAF8i6AIAAMCXCLoAAADwpZDXBQAAgMLXsr9Ne3ccUGlFiabOmaxQyPK6JOCECLoAACAr13H1/C/+pK0NOyRJpmnKClla/F8/rtrxozyuDsiNoQsAACCr9e9u1rb1TUqnbKVTtpKJlGLRuP79Jy/IdV2vywNyIugCAICs1q3YoFQyPeh4T2dUbYc68l8QMAwEXQAAkFU6bWc8bhiGHNvJczXA8BB0AQBAVnMWnKVQePDEs3AkpNHjazyoCBg6gi4AAMjq3A/P0+jxNQpHwpIkK2QpHAnputuvkmEaHlcH5MaqCwAAIKtwOKQlX/iktq1v0q4te1VWVaZ5H5yl8qoyr0sDToigCwAAcjItUzPmT9OM+dO8LgUYFoYuAAAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJdyrrqQSqX0wAMPaO/evUomk7rnnns0YcIEffazn1VdXZ0kacmSJbr22mvzUSsAAAAwZDmD7rJly1RdXa3vfve76ujo0Cc/+Unde++9uvPOO3XXXXflq0YAAABg2HIG3WuuuUaLFi2SJLmuK8uy1NDQoB07dujll1/WlClT9MADD6i8vDwvxQIAAABDZbiu657oD/X09Oiee+7RrbfeqmQyqVmzZmnevHl68skn1dXVpfvvv3/QzzQ1NSkWi52Wok+neDyu4uJir8sINNqgMNAO3qMNCgPt4D3aoDAUajvMmTMn67kT7oy2f/9+3XvvvVq6dKmuv/56dXV1qbKyUpK0cOFCffOb38z4c0fG8I40jY2NOS8YTj/aoDDQDt6jDQoD7eA92qAwjMR2yLnqQktLi+666y599atf1c033yxJuvvuu7Vu3TpJ0ooVKzR37tzTXyUAAAAwTDl7dL///e+rq6tLTzzxhJ544glJ0te+9jU98sgjCofDGj16dNYeXQAAAMBLOYPugw8+qAcffHDQ8V/96lenrSAAAADgVGDDCAAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALxF0AQAA4EsEXQAAAPhSKNfJVCqlBx54QHv37lUymdQ999yjs846S1/72tdkGIZmzJihhx9+WKZJXgYAAEBhyRl0ly1bpurqan33u99VR0eHPvnJT2r27Nm67777dNFFF+mhhx7Syy+/rIULF+arXgAAAGBIcnbFXnPNNfriF78oSXJdV5Zlaf369brwwgslSZdffrneeuut018lAAAAMEw5e3TLysokST09Pfq7v/s73Xffffr2t78twzD6z3d3d2f82aamJsVisVNc7ukXj8fV2NjodRmBRhsUBtrBe7RBYaAdvEcbFIZCbYc5c+ZkPZcz6ErS/v37de+992rp0qW6/vrr9d3vfrf/XDQaVWVlZcafq6urG36lBaCxsTHnBcPpRxsUBtrBe7RBYaAdvEcbFIaR2A45hy60tLTorrvu0le/+lXdfPPNkqSzzz5bK1eulCQtX75cF1xwwemvEgAAABimnEH3+9//vrq6uvTEE0+ovr5e9fX1uu+++/T4449r8eLFSqVSWrRoUb5qBQAAAIYs59CFBx98UA8++OCg4z/72c9OW0EAAADAqcACuAAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8aUhBd+3ataqvr5ckbdiwQZdddpnq6+tVX1+v559//rQWCAAAAJyM0In+wI9+9CMtW7ZMJSUlkqT169frzjvv1F133XXaiwMAAABO1gl7dCdPnqzHH3+8//cNDQ169dVX9alPfUoPPPCAenp6TmuBAAAAwMkwXNd1T/SH9uzZoy9/+ct6+umn9eyzz2rWrFmaN2+ennzySXV1den+++8f9DNNTU2KxWKnpejTKR6Pq7i42OsyAo02KAy0g/dog8JAO3iPNigMhdoOc+bMyXruhEMXjrdw4UJVVlb2/+9vfvObGf9cXV3dcP/qgtDY2JjzguH0ow0KA+3gPdqgMNAO3qMNCsNIbIdhr7pw9913a926dZKkFStWaO7cuae8KAAAAOAvNewe3a9//ev65je/qXA4rNGjR2ft0QUAAAC8NKSgO2nSJD399NOSpLlz5+pXv/rVaS0KAAAA+EuxYQQAAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJcIugAAAPAlgi4AAAB8iaALAAAAXyLoAgAAwJdCXhcAAAAwkhzY3ax3X12rjtYunTl9gi644gMqqyz1uixkQNAFAAAYos3rtuv3v3hF6XRacqXmfa1q+PMm1X/5ZlWOKve6PByHoQsAAABD4DiOXn72DaVTfSFXkhzbUSKe1IoX3/W2OGRE0AUAABiC7vYeJROpQcddx1XTxj0eVIQTIegCAAAMQVFJkVzHyXiupKw4z9VgKAi6AAAAQ1BcWqS6WWfKsgbGp3AkpA/+1Qc8qgq5EHQBAACG6JqlH9HEqeMVCluKFEdkhSydd9k5mr3gLK9LQwasugAAADBExSVFuvWe69XR2qWezqhGj69RcWmR12UhC4IuAADAMFXXVqq6ttLrMnACDF0AAACALxF0AQAA4EsEXQAAAPgSQRcAAAC+RNAFAACALw0p6K5du1b19fWSpJ07d2rJkiVaunSpHn74YTlZdggBAAAAvHTCoPujH/1IDz74oBKJhCTp0Ucf1X333adf/OIXcl1XL7/88mkvEgAAABiuEwbdyZMn6/HHH+///fr163XhhRdKki6//HK99dZbp686AAAA4CSdMOguWrRIodDRfSVc15VhGJKksrIydXd3n77qAAAAgJM07J3RTPNoNo5Go6qszLwrSFNTk2Kx2MlX5pF4PK7Gxkavywg02qAw0A7eow0KA+3gPdqgMBRqO8yZMyfruWEH3bPPPlsrV67URRddpOXLl+viiy/O+Ofq6uqG+1cXhMbGxpwXDKcfbVAYaAfv0QaFgXbwHm1QGEZiOwx7ebH7779fjz/+uBYvXqxUKqVFixadjroAAACAv8iQenQnTZqkp59+WpI0depU/exnPzutRQEAAAB/KTaMAAAAgC8RdAEAAOBLBF0AAAD40rBXXQAAAAiybeub9PZL76m7o0dn1I3Xh665QLXjRnldFjIg6AIAAAzR2rfW69VlbyudSkuStry/Qzs27tan7ruBsFuAGLoAIPBcx5Xrul6XAaDA2bat5c/9uT/kSn07xqZTab31wrseVoZs6NEFEFgH97TopWdf14HdhxQKWZr7wVm64uOXKBzm1ghgsO6OqFzHGXTcdV3tazroQUU4Ee7mAAKpq61bT/2fZUolU5KkdMpWw583qautWzd+5lqPqwNQiErLiuU4mZ/+VFSX5bkaDAVDFwAE0uo3GmTb9oBjdtrW7m371N7c6VFVAApZpDiimfOnyTAGHjdMQxdfvcCbopATQRdAIDXva5FjD34EaVqm2ps78l8QgBHBCpk6PukahiHTJFIVIloFQCCNmzRGljX4FminHdUwcxpABsl4Uo2rt8o9bviCYzta8eIqj6pCLgRdAIF03mXnyApbA46Fwpamzj5T1bWVHlUFoJD19sRkmkbGc13tPXmuBkNB0AUQSBVVZVr6hRs0ecYZMi1TRSURnffhefpY/dVelwagQFVUl8s4foCuJBnS+Mlj8l8QTohVFwAEVu34Ubrlcx/zugwAI4QVsnTpX39Qrx+3lm44HNKliz7oYWXIhh5dAACAIVpw2TlacPk8hcIhyZDKKkt13e1Xa/SEGq9LQwYEXQAAgCF6f+VGrV7e0Nej60q93TE9//OX1cZqLQWJoAsAADAEtm3rtd+tGLQFcCqZ1oo/sAVwISLoAgAADEF3RzTj+tuu62rPjgMeVIQTIegCAAAMQUmOLYDLq9gCuBARdAEAAIagqDiimfOnygodvwZ3SBdddZ5HVSEXlhcDAAAYooW3XiHXlba8v0OmacowpA9fe6HOmlfndWnIgKALAAAwROFwSNfdfpXivQn1RmOqHFWh0HE9vCgcBF0AAIBhKi4tUnFpkddl4AQYowsAAABfIugCAADAlwi6AAAA8CWCLgAAAHyJoAsAAABfIugCCDTXdRXrjSt1zN71AAB/YHkxAIG1Z/t+/fGp19TZ3i1JOmtenT56y+UqKmHJIADwA3p0AQRSe3Onnv3R82pv6ZRjO3JsR9samvTbf/mD16UBAE4Rgi6AQFr9+vuy0/aAY7bt6OCeFrUeaPeoKgDAqUTQBRBIbYfa5TruoOOmZfQPZQAAjGwEXQCBNLFugqwM+9PbaUejx9d4UBEA4FQj6AIIpPMunatwJCTDOHosFA5p1rnTVTmq3LvCAACnDEEXQCCVVpSo/ks3adYHpqu4pEiVo8p16aILtGjxFV6XBgA4RVheDEBgVdZU6Lr6q70uAwBwmtCjCwAAAF8i6AIAAMCXCLoAAADwJYIuAAAAfImgCwAAAF9i1QUfSqdtNazcqI3vbVUoHNIHPnS2zppXJ+PYBUMBAMBJ2d64SytfXK2ujh6dMXW8PnTNBaoZU+11WciAoOszju3o6SeWqXlfm9KptCRpX9MBzbtwtq684VKPqwMAYGRb93ajXvn3t/o/Yzev3a7tjbt0+303qmZstbfFYRCGLvjM1oYmtew/GnIlKZVMa93bjepo7fKwMgAARjbbtrX8d28P+Ix1XVfpZFpvvvCOh5UhG4Kuz+zYuEupZHrQcdM0tGfbPg8qAgDAH7o7onIcZ9Bx13W1b8dBDyrCiRB0faa0olSmNbhZDcNQSVmxBxUBAOAPJWXFchw347mKqrI8V4OhIOj6zDkXzpJpDm5WK2SpbtaZHlQEAIA/FBVHNOsD02SFrAHHQ+GQLrr6PI+qQi4EXZ+pHl2laz91pSLFYUWKwwpHwqqoLtct93xs0BsTAAAMz8JbLtfMw2E3HAkpUhzRFddfrOlz67wuDRmw6oIPzThnqqbNmawDu5sVClsae8ZolhYDAOAUCIVDunbplbrqhkvVG42rsrqcjqQCRtD1KStk6Yyp470uAwAAXyoqKVJRSZHXZeAEGLoAAAAAXyLoAgAADJPjOErEk3LdzKswoDAwdAEAAGCIHNvRG79/R2vebJCdtlVaUaqPfPJDmjl/mtelIQN6dAEAAIbo1WUr9N4bDUol03IcVz2dUf3+F69o19a9XpeGDAi6AAAAQ5BKpPT+240DtgCWpHQqrRV/XOVRVciFoAsAADAE0e5eGWbm5To7WrryXA2GgqALAAAwBOXV5Vknn42ZWJvnajAUJz0Z7YYbblB5ebkkadKkSXr00UdPWVH4y8Wice3cvEehcEhTZk1SOMy8QwAA/hKhkKXKURVqO9Qx6NyEKePyXxBO6KTSTyKRkOu6+ulPf3qq68EpsObN9Xp12QqZlqkjD1huuPsaTZo+0dO6AAAYyWK9cXW2Zh6isGXddl2ycEGeK8KJnNTQhY0bNyoWi+muu+7SHXfcoTVr1pzisnCymve36rXfrZCdtpVKpJQ8/Ou3//IHpZIpr8sDAIxAju1oy/s79PJv3tDKl1erpzPqdUmeSMaSMszM0SkWjee5GgyF4Z7ESsebNm3S2rVrdcstt6ipqUmf+cxn9Ic//EGh0NEO4qamJsVisVNabD7E43EVFxd7XcZJa3x7m3as3ysd16pW2NL8y2dqwtQx3hQ2DCO9DfyCdvAebVAYgt4OdtrW28+tU097VHbakWkaMkxDF3x0nmonVuelhkJpA9d19fLP31YyflzHkSFNmjFO8y+f5U1heVIo7XC8OXPmZD13UkMXpk6dqilTpsgwDE2dOlXV1dVqbm7WhAkT+v9MXV3dyfzVnmtsbMx5wQrd7oZDg0KuJJmGoXFjxmnOnMJ/E470NvAL2sF7tEFhCHo7vPvqWnW3ReXYjiTJcVzJcfX+8i363MP1WVchOJUKqQ3Ct5Xo+Z//SXbaluu6sixTkeKIrl18tSqqy70u77QqpHYYqpMauvDMM8/osccekyQdPHhQPT09GjOm8HsKg2DGvKkKRwZ/f3EcV1NmTfKgIgDASLbu7cb+kHusWG9cLQfaPKjIWzPOmarbPv9xzTp3msZPHqvzr5ivT3/1Ft+H3JHqpHp0b775Zv3DP/yDlixZIsMw9MgjjwwYtgDv1M06U1NmTtLOzXuUSqZlGIaskKVLPrpA5ZVlXpcHABhhensyD0N0HVeJeDLP1RSGcZPG6Lrbr/a6DAzBSaXTSCSi733ve6e6FpwChmno45/+qLY37tTmtdsVjoQ098LZmjB5rNelAQBGICtkndQ5oBDQDetDhmlo+tw6TZ9b53UpAIARLtc67FU1PK5HYWNnNAAAkFV3jqXEWvYFb4wuRhaCLgAAyCrTRLQjmg+057ESYPgIugAAIKtMK/kcMXFKcOd/pG1X3bG0TmI7AuQRY3QBAEBWo8ZW69CeloznRo+vyXM13rMdVz/+0349/16rbFeqLLb02YUTdcWcaq9LQwb06AIAgKzaWzqynmve15q/QgrEky/u1fPvtSqRdpW2XbVF0/rn/9yt1Tu6vS4NGRB0AQBAVumEnfVcd1f2iWp+FEva+uO6diXSA4crJNKufvHmIY+qQi4EXQAAkFWuLX4tK1jr6HZE0zKNzNdjf0ciz9VgKAi6AAAgq1yT0apHV+axEu/VVoSVKecakmaML817PTgxJqMBAbNtw06993qD4rGEZs6fpnMvnatIUdjrsgAUqKLiIiViGbb6NSQ7lX1Ygx9FQqY+9eGx+unrB5VIHR2+EAkbuuOycR5WhmwIukCAvPn7d7Rq+TqlkmlJUuuBNq1/Z5Nu/9KNCkcIuwAGK6soUVd7holWrlQVsB5dSbr5orEaVRrSL99qVns0pRnjS3X3R8Zr2rgSr0tDBgRdICCi3b1659W1stNHe2DSKVtd7T3a8O5mfeBDcz2sDkChSsQz9OZKMk1TXe09Ki4pynNF3rvqnBpddU7wllYbiRijCwTEvqaDskKD3/LpVFrbG3d5UBGAkaCoOJLxuGEZCoWCNRkNIw9BFwiI0vISZdrAxzAMlVWW5b8gACPCBz50tkIZJqRVVpdr1JgqDyoCho6gCwTExCnjVFJWLOO4KcNWyNK5lzJsAUBmZ58/UzPmTVUobCkUDilSFFZJebE+ceeiQfcToNAwRheBsP1gTE3NcZ1RU6SZE0oCeXM2TEO3fO5j+u2Pf6/ujp7+a3D1TZdp7MRaj6sDUKgM09C1n7pSrQfO094d+1VaUaqps8+UFeBhC3u279ef/7RGnW1dOnP6RF145XmqHFXudVnIgKALX0ukHD386x1q3Nsr0zTkutKUMUV6ZPE0lRUH7yZdXVupv/n7W9V6sF3JeFJjJ41hjB2AIakZV63SihKFi8KBDrmNq7foj08vVzrVt3pN+6EObXxvq+q/dJOqaoO3CkWhI+jC1/71tQPasKdXSduV1DdAdfvBuJ54ca++ev1kb4vziGEYGj2e2cIAhm77hp166dnX1dsdkwxDZ58/Q1fecKlC4WDFCMdx9PJv3ugPuZLkulIiltRbL7yrv156pYfVIRPG6MLXXlzXdjjkHpWyXb3W2Ckn08wsAMAA+3cd0u/+30vq7ojKth3ZaVsbVm3R73/5itel5V1Xe4+S8VTGc6xeU5iC9VUsIFzH1bYNO7VpzTaFIyHNu2i2Jk4J5o4tx4fcI2zH7VuBIHhDdQFgWFa+9N6AHkxJstO2tjU0Kdrdq7KK4Gx92zcELvPnSjpgu8SNFARdn3EdV//+kxe0e+vevt2vDKlx9VZdvHCBLrrqPK/Ly7vzp1Zo5dYuOcfclwxJZ59RKssk5QLAiRzYfSjjcdt21N3RE6ig6ziuDNOQ6wwOu6FwcMctFzKGLvjMjk27tWvLnv4tXuX2bQjw1gvvqqcz6m1xHvjs1RNVXmypKNQXaiOWodIiU1+4ZpLHlQHAyJCIZd4ZLYgqq8tlmpmj07hJo/NcDYaCHl2f2bx2W8bHJ67jaufmPZr7wVkeVOWd8dUR/ctnZ+mFtW3avD+mqWOL9dfn1qq6jJc+AAzF8cMWjtV8oE3jzxybx2q8ZTuOHMfJeC7XdYJ3+LT3mWhXb8bjrusq3pvIczWFoaIkpJsvDs6NGABOJcNQxl0VJckygvVgONoZlWWZSjuDO5Q6Wrs8qAgnQtD1GSuUvUmtgI4fSqXS2rx2u5r3tqh2fI1mnTtdkaKw12UBwIgw9owxOrinOeO5aWcHa5nGsspSpdOZJ52F+VwpSMH6KhYA4ybVZtz1ywpZqg7gQtbRrl795LFf6eVn39Cq5e/rlX9/U//yyC/VyTdvABiSv176kYzH55w/Q8WlxXmuxlupRFpGluV67FTmIQ3wFkHXZ+pmnZlx6RPHdjRp2gQPKvLWq//xlnq6epVK9q17mEqmFYvG9eIzr3tcGQCMDLXjRunqmz8syzoaGSZOGaeFN1/mYVXeSKfTskKZo1MAd5YfEQi6PrO9cZfMDMtmhcKWdm/d50FF3tq6YeegZWBc19WuLXuzTigAABx1YHezXv2Pt2XbR++Zh/a16IWnXvOwKm9UVJertHzwcmqWZWrG/GkeVIQTYYyuz3R39MjJsL6f67rqyTJRzc/MLF+xDUNZHz8hONoOdeiV/3hLe7buU7gorPmXnK1LPrpAlhXM8exAJitfWj1oRYF0ytbWhib1dsdUWlHiUWX5ZxiGrv3UlXr2h8/JsR3ZtqNwJKSyilJdfPUCr8tDBgRdnxk3aYzWv7N50PF0ytbEuuDtjjbrvLO04Z1NA3oiTNPQtLlTZLBhRKD1dEb1i//5WyUSyb71ptO2Vr22Vu3NHbr+joVelwcUjOb9bRmPu46r7o6eQAVdSTpj6njdef9ivfd6g1oPdWjanMk6+4IZCkeYjFaICLo+0xuNZzxumoZ6OqOqHTcqzxV564qPXaQDuw6po6VLju3IDJkqqyjRwpsu97o0eOy9Nxr6eqmOeQCSTtnatn6nOlu7VBXAyZtAJtnWh3UcR5GSSJ6r8V4qldby/3xbW95vkmmZ2rNtn2zH1oIPn+N1aciAoOszXW3dGY+blqWu9p48V+O9opIi1X/pJu3aulctB9pUM6ZaU2ZNyrqzDYLjwO7mAT39R1iWqdaD7QRd4LBEPPvOaJ2tXRo1uiqP1Xjvxadf05b3m2SnbdmHlxp7/T//rMrqCp01r87b4jAIn/Y+M2naBIUjmb6/uBo/eUze6ykEhmloysxJOv/y+Zo6ZzIhV309EvFYMDcQOaK8cvCEEklKJlOqHhOsD25klkw7Wrm1S+v2OYrGM6+dGgROhi+E/bJsJOFXiXhSm9dt7w+4R6RTaa18+T2PqkIu9Oj6zOwFZ2nly6vV3RHtvzmFwpamzJykMRNqPa4OXovHEvrj069p2/qdkqTq2kotWnyFJtaN97iy/Mu16sbxH2IInrU7e/SPzzRJ6tv29eerN+jzi87QR+fXeFuYB1zXGZBnXUnG4V+mFayOg1g0LtM0ZWvw/aOnM+pBRTiRYL1CAyAcDmnpF2/Q9LlTFI6EVFQc0bkfmqvrP83kGki/+eHz2rZ+pxzbkWM7ajvUoWd+8Jw6swx58bPenszj2cORsLo7gv2BdfySfEETS9r6+q+b1Jt01Jt0lEhLybSr//3CXu1uzfy68TNXhpzD69QYOhocbBlZdwnzq4rqsqwL5k6YzFbzhYgeXZ9xXVcv/PJVbd+4q/+R0qrl76u4rFgXXXWet8V5JJqw9dL7bdqyP666scVaNH+UKkqC99I/tLdFzfvbBj2GtG1Ha95o0BUfv8SjyrwxafoE7d1xYFDvrWM7GjsxeE8/XNfV2rc2aMUfV6m3J6bKUeW6/GMXa9a5070uLe/e3tIlydUZsQOaFD8oU64ORGq1p3yiXm5o199cEazNd1JGWGENHKdrHP7PoAVd0zTlZnkaFNQNI1zH1Zb3d2j9u5tkyNDcC2fprHl1GXdp9ULwPu19bsu6HdreuGvAMdd19cbzf9a8D85SWZZxiX51qDOpv/vXrYqlbCVSropChn711iH9jzum68zaYG1d2dnWLdMypNTA447tqPVQhyc1eWn+xbO14o+rBh0/Y+p4lVeVeVCRt957vUGvP//n/hn2Xe09+sOvXpEVsgI3wSaecjSrfZNGxdsVOvyIempsr8Ym29QTG+1xdfmXNsMK24MnpLmSokZR/gvyUGdbl9KpzOF++4ZdGY/7meu6eu7nL2v7hp1KJfvuHbu27tWM+dP010sybx2dbwxd8Jlcg+FXv/5+HispDD94aZ+6YmklUn3d24m0q2jc1v/6/V6PK8u/MRNrZaczrDIQsgK5xvL2DbszPqLftXWvUolUhp/wL9d1teLFVRk3BXjj+T97VJV3ppamVHNMyJUkS65KnbjOMjs9rMwbLRXjZGeIC2kzpKqx1fkvyEO93bGs54LWuy1J+3cdGhByJSmVTGvz2u06uKfZw8qOIuj6TK7B8G3NHfkrpEC8u71bx2cZV1LDnqjsgI1DrK6tlDlm4AeWKynhmpp9/mzvCvPI2y8O7s2VJLnSjo2781uMx9LJdNYlpII4fjvR2qZMc6xCriOrK/PmCX7WVjVRnaFypWXKlWTLVFqm1lXMlNzCeDydL6Fw9gfhBfKkPq92btqjVIZ1lm3b1s7NhdGhRND1meLS7I+RgrbWoSSFrMx3HsswAndTautJ6SV7iraVTlLMjChlWDpQVKtVNfP1+vbgbQ8dzbEl9q6te/JYifdChyeuZjJqdPDWEy6rKFUkPHgbaCtkqXJUuQcVeauqLKJVVWdrbeUs7Sg5Q1vKJuuNmgWKlVTKynKP9auK6uztnysE+1VRSZFCGbZMtyxLRQWymYhvgm4qldamNdv03hsNat7f6nU5nqnJ8Rgp1zm/umreKIWPuxGHLEMfnl0pM2BJd+O+XoVCpjrDFeoIVagzVK72cJV6nJDe2Ra8XjsrQ5A5oqomWOHOMAxNnnFGxnPTAzY+V5Kmzjmzbz3y424Rpmlo7gdneVOUh645t0ZFYVNtkWptK5us3SUTlDLDGlUW0uTaYI3RTeYY1uQE7CmhJM0+d3rGrmzDkGZ+YJoHFQ3mi68fh/a16uknlimVTMtxHJmmqZnzp+napVfKMIMVZpKJ7DvYZBtA72d3/dUEbTsY07aDcR1Z/XHiqIju/WjmD3U/qy4NaVznbtVF98iSI0NSdapbZ8QOqrbsw16Xl3cl5SVKxjN/aGULfX7luu6gSaxHbHh3sy695oN5rshblmVp8b2f0LJ/+6M6Wjrluq5Kykp03e1XqbwyeBMVL59Wol8nOtRslsuRIdN1ZcjVbWdZBTOzPl9SyVxBN8fGGj5VWlGiT/zNR/W7n77Yv9KTYRr6+Kc/qpLSwpjwPeKDruu6eub7/6lE7GjAc2xHG9/bqrqZkzT3wmB9+25vyT5R4sDuQ5Lm5q+YAlAcMfVPt0/X5v0xNTXHNam2SGefURq4m7MkjS9zNTW6W9YxS7+H5KjMjqm6p0VSnWe1eSGaY63cLe83adyk4OwkmE6mlU4OHmcnKZBbh0vSqDFV+vR/u0Wdbd3avGmzLrh4QSDvG5K0evlazWvfIFuWTNlyZcqQo01/srTwI7MC9ci+uCR7D3aQrsOx6mafqXv+8dPau32/DMPQGVPHywplf2KWbyO+VQ7ubVUsmnkB79d//+fABd1Eb/Ye3Z6uYC6CbxiGaoy4erv3qbZmnAwjeD0ykrTinZ1yZKjbKlWpk5DpOuq1ilVkJ7Vn405JF3hdYl7ZObY17e4MVrjL1UsVVMl4UsufW6nGVVuUTtvav7lVH/nkpaoI4NJzjau3ypAU0pGngn3vHTtlq/VAu8adGZwvheGicNZzrhu8oQtHhEJ9O7AWohEfdHdtzj47OtdkE79yc2w8bpqF8w0rX9KptP7te79WR3NX/7GKqjLd8fe3qjjL5Bu/ak8Y6rVKVGH39vfqltu9sg1LHbZvhusPQ/b3SnFxsMYdYiDXdfXr7/+nmve39i/Jt/X9Ju3bcUB3/cMSRXKEHT/K1pkkSbFYsHaKa8kxByjbUxF4a8R/urUcCN5SL7nknGAVwG+bv/mXPwwIuZLU3RnV0/9nmUcVeae4rFjlx4Rcqe8GYLqOHCtYH9xS7rdDrrHufhSOBK/9c9m744BaDrQNWHfadV0l4kk1rt7iYWXeyLUldG9X9nVl/ai9OXjrKJ9IOpXWypff00++/ZR+8p2n9M4rawpqTeERH3SrA7j0TS62nf2G5AQw6O7eknkdv+Z9rcGbOBCNysnwlrfkqiwdvKcfufR2B+t6hMKDVxg4IoghuGV/W8bJu+mUrf27DnpQkbdyjU0eFbDVfMqrSjM+CwrYp0k/1+l7+vHWH95V26EOtR3s0Bu/f0fP/vC5ghnKMeKDbs2YUXI1+CFkYVze/Dt+Z6NjdQdwUkm214ErycmwS5ifja4qOrzc+0C2DFlFwXxUn+n14UqyAjapxHGdrD3cqRxjmf3KztEblUoE7/G042Z/DXS2dmU950cTp4zX9uKJcmT03z9cSWkjpJaiUV6W5ommzXu0f9ehAR1Hju1o744D2r11n4eVHTXig65cyZWRsTMiqeCNSc0lHkt4XULepY3MrwFHhlxz5L/8h2NClaWuUJns494trgyVVwQv6KZNK1snpkprgrW5SjLH0oPpHE+J/CrXRMVAjsM0Mt8rXUmVNRX5rcVjLW1RhV1bjo4+BDEkWa6t5lC1d4V5ZNOabRmHtriOq81rt3tQ0WAj/pN+645Dx3yvOsqQMvZeBZkZsGAnSY2ldQN6/I/8781lU2QawXp9tJtlWlcxUweLavt7I7qsMq2qOlvNJWO9Li/vUkb2XtvmaLBeG1YoNKCH6ghXkpMl5PhZvDf7BKtM2536Xa5hXrsPBmuzmY6epM5IHFJIrqJWsVrDVUoaIVlyNSHR7HV5eRfPMVGxN8e5fBrxz+c2b8v+wrICO2pmMFcK3OYZknSwZIwSZkRzeneoxE4oYUa0qXSKWopqsvZS+JVTVCLXsrS+YoY2lJ8lQ46cwz3ebnmpx9XlX1IhlWjwUw5HhlK9wRqjaziOTLmDergNSWE3eMGuanTV4e1lBnIllY8KVg+mlHX4tqTgTUZTT7eSRkjvV85Ud6hMpuvKMUydGTugKbFgbR0uSROnjtO2DTsznps0bXyeq8lsxAfdonRMAXubnbRUPFgzyaW+G3RvuFSHIjWqSkfVbZWqJ9y3V3nfQPnghP8Z40uUck3JkFzDkHtkaI/rakZNsEK/JCXMkFw70yvAUG1JcF4XkmSn0lnfCcG6En0O5ujR39sRvDWHc70GaitGfIwYlnDEVGP5dHWFyuUappzDF2d3yTiV2MFLI7kmqxbKRNYR/+k2rrbc6xIKSlrZJ2DF3RHf3MNWno7qQ+1rNCW2X7WpTp0ZP6BL2teoMt0jM2A93P0rUBw76+jw/97a0JT/gjyWMiNZ3iuOOq1gbQpQVFqUdWZ9KBKsICNJuzZlXp/dkNR1oCW/xRQQV1LCCMs+JjrkenTtR1s3H1RbpErucU8EHcPSnpLC6MHMp+0bdmad1LttfVOeq8lsxCcfO2hLRJ1AOscEvFQkeI+n53ZtleXa/WvHWnIVkqNzurfknFntRysbDmh0ok1n9exUxE4o5KQ0LtGiGT1N2hkN3sTN6mRnxhugKamrpSPP1XjLdVy5rts/hv3YX7lWcvGryrLsm8kUhUf8x+awuZLaQhXqssoUdtOyDVMHwzWyZSiaDNZncHt3POO8ICn3uH+/ShmWnAx9/rZM2QWySdWIb5WEO+L/CadUkbKHt5JU8JYXK3diGR+7lTgJ2Slb4QAtI9Xb1qFxyagaK6bLlSFXhlqKauQYpmoS7V6Xl3fFbjLjOExJSuzNvP6yXyWTKaVkKnTcR5YrKRnAJ0E1FWHtynDclVRkBmuioiR1W6WqSkf7571E3LRGpzrUFq7Uge5gfREqLzIVcm0lj1/Rx3U0Ohm8++jOdNmATYiOsOSoKV0YT8ZG/B0sFbDtB0/EUPbxVOkAjtHNKWCrUJhd7WqsmC7HsPoeuxmGbMNSW6Q6kBOOTGV/rzjpYF2PeMIeFHKlvusTCuCk3i1ZlkUyJHW1BG9nrLRhyTjudWDJUU2qS9HWYF0P03U1p3ubTNeWHFuG68pwHYVdW1NjwfqCLEnRA80Ze3QdGeraWxibq4z47qx0NFizo/8iweuIyCmRdlTsdRF51FE8SkbaHZTubMPSgaLR3hTlobQMhTKsNCBJ0XBh9ETkS3NH9vtosEay94n1Zl9zPHixXyp2khl7xRyZam8N1vJijuNoTKpDl7atVth1ZMpRyrBkuG4gvxQWx7oyLuVqylVJb0f+C8pgxHdp2Xawel5OJNMucUcE7y0o9ZqZo2zSCAVu7GE0meWVEbDVJ46wZcqQlDZMtYar1Bkq63/v9Ga7Vj7V1h6ssHIiiSw3y1z3Vz+Lm5GMnx+mHIVz7JrmR5NmT5UkFbtpHRmdGnHtQIZcSSpysn8pDDuF8RT5pHp0HcfR17/+dW3atEmRSETf+ta3NGXKlFNd25CkksFb6iUXV9m/vQRr6lWfraWTNa9n64A1ldMyta30TCUDtgVwON4rI8N8REuOapNt+S/IY2E52l00VpvL62QcDvsRN6nzOjcqYgfrvhIpjDkjBcPMElpyDQ3zs0PhKlWlozq2u8SWoS6rTCVl1Z7V5YVke+Z7paFgdibl/OZXIBfkpHp0X3rpJSWTST311FP6yle+oscee+xU1zVkqYDN+DyRXDfhQN6gi2rUUD5dvWaRXPX1TGwsq9Pe4nEqLYwl/vKm1yrW/O5Nslxb5jG/JsYPqioVvB69zlC5NpfXyTEs2WZItmkpZhZrddUcmSqMnoh8qSjOPogniD2YTpbVa1xp0BbaQTAx3qL0MWsN9H0tdBWxExpTGqzrsXNXcJeXy+RIAjv2PuEed85rJ9Wju2rVKl122WWSpHPPPVcNDQ2ntKjhSMhQUSBvxSeWNEIy5Crs9vXljvhxKiepNVKtqFWitBlSyE0rbhZJktJ2sF43pakelad7VZnqUnu4qm/XKyelscl2lRXII6Z82l08Ts7x7wrDUMoIqyNc7UlNXrEOL5l1/CCWYA5q6bt3HrlvHsuQBqwhGxS2aSlkJ/pfC0d6tiOGI/fQAQ8ry79DLZlXL+r7EhS814ahwU+SjxwrFCcVdHt6elRefnSjBsuylE6nFQod/euampoUi53+XUIyDYI+VmNj47D+vng8PuyfKTSdoTKtLz9LvVZfL011qlvzerYo4qRGxL/tVLZBcbpXiVCxoqFSyTCUcCMy5Kgk3avNW7ao+lBw1ha207beq5yjnlCpZPS9c5JWkd6rnK3z2tcPuuZ+eC/kkjCLpIybJLhKGJGC+Lfnqw3eX7tHrWa5qpyoQsfcUxMKKaZQQVyLfEq5meO9q75rErTrET5mLfJjGa6jA112Xq5HodyPurp7VaS+3sqYEVHSDKvMjiusvnG6hVDj6XR8O6TVFySP/VJ8bI9uvq7HnDlzsp47qaBbXl6uaDTa/3vHcQaEXEmqq6s7mb962H6r5TnP5/rHZ9LY2DjsnykkvzFWaFXVXNnHrPHXHq7Uu1VzdUn7mhHxbzuVbWDobbnHrnd4eOvbtBnShDHjVTf9jFPy/zMSdIW3KhoqGbSjjytDTWWTBl3zkf5eOJGI/ZJMt0zOcethuoYp07UL4t+erzbYtqVbKbUOWoWiSGnts2oK4lrkk2utzj6pwTACdz0M5+2Mxy25iplFebkeBXM/6n1LSZmyzZBKnaRK7b6nYR1Wucrt3sKo8TQ6vh2WHc5gx943jvTouhp+BjsdTqqffcGCBVq+vO8ft2bNGs2cOfOUFjUcHUZJxuN9jxGCZ0/x2MGPTwxDMbNYbeFKb4ryUCyU+fWRMiNqaNiT52q8FVHq8KSrgVzDHPDFKCjGJ1pVYsf71sOUJNeV6dqaFt2liBOsFTn2tPVqvNOZcR3dOvuQFyV5ysyymo8hqdgN3trtJUpmfXZakQ7WOrox2XKMkEqcZP8QDkNStd2jqJX588bPcg1tKpSBHCfVo7tw4UK9+eabuu222+S6rh555JFTXdeQlWQYRyX1XfxCucj51BIZleVxrNQaqspzNYVt685Wr0vIq2I7KccY/K4wHVsV6WiGn/C3UjepizoatLd4jA5FahV20zozdkCV6ag6A/aBtaNhu8ZkORfEMbpFyv5FZ8QvPn8Scq02EbTP2YQiqnYTGb8Ultunf7hmoXFzjMjNvEp5/p3Ue9Y0TX3jG9841bWclFyDvwvjEudXzn9zEC9IDt1ZlonxK9uwNC7RqkNFNUcf17uOQq4t0wne848jN+jJ8YOaHD+6g48tQxE7+9qQfmRn6TAIqlxzP7iNBltxjrUErIJZZyB/0kZIlpt5Oca0URhfC0f8l7GoEcl43JUUD+B37+pk5+ENAI7nqiLFLnLH+uQtH/S6hLyy7KRsGZoe3a2SdEwRO6kJ8WZN692lSJYblZ8V271yj1kySeoLuXEzonYzWDujfejis7wuoaDErMzLrbmSkgH8XMklaF+RKpT5XulKSmdZls7Peo3s63QWSgYb8UH3Gw9drzazbMCONUf++1DAlgiSpFHxdlmuPTDsuo5K7bjqxoz45h62mmTH4ODvuipP9eics2d5UpNXLr5qtordlPYUj9PYZJvOjB9QzCpWU8kZKk4G70vQoXCNXLmKG5H+pYESRljFTkIPP3Cd1+Xl1Y23fCTjrl+uCmctzHwKFWU/12oEaePwPo4yvzYk6WvfvjvP1Xjr77/3WSUGrE1yVNBCvyQVO73qMUsGraPbbZWqyC2MoRwjPvlUVJYrGYpoZ9G4vpmQktrNUu0oGq9v3L/Q6/Ly7tv/9CnN79yoynSPDNeV4Toak2zX7M4t+ruv3Oh1eXl3eZ2hilRPX9g9/KskHdMHijq8Li3vbrzmfFX2tmpabI/aw5XaXzRGVeluze9s1KOP3ep1eXn3z4/cqI5QhYrdvlnTphxF3KTaqs5QzajyE/y0/7iVo/r++5hfkjT5fO8mG3vl4W/ergNW1YBr4UpqsSr0z//0KW+L88Dnv/XpQddCkszamkErLgVBSSit5OGBCn09uYZSMnXrXVd6XVre/ffvfVbFTkwtoUp1WSXqskrVEqpUid2rB7/3Wa/LkyQZrpvxOfeI8/77TfrxL1YrZYY1viitBx/8hExz+Dm+YJYw+Qt944Gfy06mZBjS2Emj9V+/+DGvSxqyU90GnV3deviRP8g1Q5Jj67///Uc1uiZ4K1Ac8f9+s1Lr396msJtWV7hc/+uRzF+A/PJeOJFfL3tPb69skhUydd89f6WJ4wtn0ma+22Dfnmb93//xW0XkKi5L9z20WJVVFXn7/y80//ydZdrXGpcMqcy09Y+PLPG6JE/94MkX1L5tt5xwRP/lv92g0bX5e20U2v1o55Y9eub7z8lRX4/hFx69U5FI5qGUfpKtHf7nw/9XyZ6+YR0lVUX6/EN/k+fKsvNN0D1VCu3NFES0QWGgHbxHGxQG2sF7tEFhGIntMOKHLgAAAACZEHQBAADgSwRdAAAA+BJBFwAAAL5E0AUAAIAvEXQBAADgSwRdAAAA+BJBFwAAAL5E0AUAAIAvEXQBAADgSwRdAAAA+BJBFwAAAL5kuK7rno6/eNWqVafjrwUAAAAGOP/88zMeP21BFwAAAPASQxcAAADgSwRdAAAA+BJB97AXX3xRX/nKVzKe+9a3vqUbb7xR9fX1qq+vV3d3d56rC4ZcbfD000/rxhtv1K233qpXXnklz5UFQzwe1xe+8AUtXbpUn/nMZ9TW1jboz9xzzz267bbbVF9fr7/927/1oEp/chxHDz30kBYvXqz6+nrt3LlzwHle/6ffidqAz4H8Wrt2rerr6wcd/9Of/qSbbrpJixcv1tNPP+1BZcGRrQ3+9V//Vdddd13/e2H79u0eVDd0Ia8LKATf+ta39MYbb2jOnDkZz69fv14//vGPVVNTk+fKgiNXGzQ3N+unP/2pnn32WSUSCS1dulSXXnqpIpGIB5X61y9/+UvNnDlTX/jCF/Tcc8/piSee0IMPPjjgz+zcuVPPPfecDMPwqEp/eumll5RMJvXUU09pzZo1euyxx/Tkk09K4vWfL7naQOJzIJ9+9KMfadmyZSopKRlwPJVK6dFHH9UzzzyjkpISLVmyRFdeeaVGjx7tUaX+la0NJKmhoUHf/va3NW/ePA8qGz56dCUtWLBAX//61zOecxxHO3fu1EMPPaTbbrtNzzzzTH6LC4hcbbBu3Tqdd955ikQiqqio0OTJk7Vx48b8FhgAq1at0mWXXSZJuvzyy7VixYoB51taWtTV1aXPfe5zWrJkCT2Lp9Cx1/7cc89VQ0ND/zle//mRqw34HMivyZMn6/HHHx90fNu2bZo8ebKqqqoUiUR0/vnn65133vGgQv/L1gZS35e+H/7wh1qyZIl+8IMf5Lmy4QtUj+6vf/1r/du//duAY4888oiuvfZarVy5MuPP9Pb26vbbb9edd94p27Z1xx13aN68eZo9e3Y+Svadk2mDnp4eVVRU9P++rKxMPT09p7VOv8vUDrW1tf3XuaysbNCj2VQqpbvuukt33HGHOjs7tWTJEs2fP1+1tbV5q9uvenp6VF5e3v97y7KUTqcVCoV4/edJrjbgcyC/Fi1apD179gw6znshf7K1gSRdd911Wrp0qcrLy/X5z39er7zyij7ykY/kucKhC1TQveWWW3TLLbcM62dKSkp0xx139HffX3zxxdq4cSM3uJN0Mm1QXl6uaDTa//toNDrgZofhy9QOn//85/uvczQaVWVl5YDzo0eP1m233aZQKKTa2lrNmTNHO3bsIOieAse/xh3HUSgUyniO1//pkasN+BwoDLwXvOe6rj796U/3X/crrrhCGzZsKOigy9CFE2hqatKSJUtk27ZSqZRWr16tuXPnel1WoMyfP1+rVq1SIpFQd3e3tm3bppkzZ3pdlu8sWLBAr732miRp+fLlgxbffuutt/TFL35RUt8HzJYtWzRt2rS81+lHCxYs0PLlyyVJa9asGfD65vWfH7nagM+BwjB9+nTt3LlTHR0dSiaTevfdd3Xeeed5XVag9PT06GMf+5ii0ahc19XKlSsLfqxuoHp0h+MnP/mJJk+erKuuukqf+MQndOuttyocDusTn/iEZsyY4XV5gXBsG9TX12vp0qVyXVdf+tKXVFRU5HV5vrNkyRLdf//9WrJkicLhsL73ve9Jkr7zne/ommuu0RVXXKE33nhDt956q0zT1Je//GUm5pwiCxcu1JtvvqnbbrtNruvqkUce4fWfZydqAz4HvPO73/1Ovb29Wrx4sb72ta/p7rvvluu6uummmzRu3DivywuEY9vgS1/6ku644w5FIhFdcskluuKKK7wuLyd2RgMAAIAvMXQBAAAAvkTQBQAAgC8RdAEAAOBLBF0AAAD4EkEXAAAAvkTQBQAAgC8RdAEAAOBLBF0AAAD40v8H1sB93D0PGMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "# Removing to and right border\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "# Create grid to evaluate model\n",
    "xx = np.linspace(-1, max(features['x']) + 1, len(train_x))\n",
    "yy = np.linspace(0, max(features['y']) + 1, len(train_y))\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "train_size = len(features[:-test_size]['x'])\n",
    "# Assigning different colors to the classes\n",
    "colors = test_y\n",
    "colors = np.where(colors == 1, '#8C7298', '#4786D1')\n",
    "# Plot the dataset\n",
    "# print(test_x)\n",
    "ax.scatter(test_x[:, 0], test_x[:, 1], c=colors)\n",
    "# Get the separating hyperplane\n",
    "Z = model.decision_function(xy).reshape(XX.shape)\n",
    "# Draw the decision boundary and margins\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "# Highlight support vectors with a circle around them\n",
    "ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100, linewidth=1, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aeafda-c8b7-4824-8420-28cf846e5757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "834bfba0-466b-4a3c-b804-df682ea55451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.Input(shape=(2))\n",
    "# # targets = keras.Input(shape=(10,))\n",
    "# x = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "\n",
    "# x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "# classifier = tf.keras.Model(inputs=(inputs), outputs=[x], name=\"binaryClassifier\")\n",
    "# classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\n",
    "#         tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#         tf.keras.metrics.Precision(name='precision'),\n",
    "#         tf.keras.metrics.Recall(name='recall')\n",
    "# ])\n",
    "# # student_model.save(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "# classifier.summary()\n",
    "\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "classifier.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.03),\n",
    "    \n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "e05023da-b1cd-4a9f-a727-7518230eddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6209 - accuracy: 0.2096 - precision: 0.8218 - recall: 0.0348\n",
      "Epoch 2/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6037 - accuracy: 0.2165 - precision: 0.8816 - recall: 0.0412\n",
      "Epoch 3/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6035 - accuracy: 0.2111 - precision: 0.8857 - recall: 0.0334\n",
      "Epoch 4/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6061 - accuracy: 0.2128 - precision: 0.8885 - recall: 0.0355\n",
      "Epoch 5/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6078 - accuracy: 0.1988 - precision: 0.8516 - recall: 0.0168\n",
      "Epoch 6/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6036 - accuracy: 0.1992 - precision: 0.8983 - recall: 0.0163\n",
      "Epoch 7/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6054 - accuracy: 0.2039 - precision: 0.8659 - recall: 0.0238\n",
      "Epoch 8/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6033 - accuracy: 0.2026 - precision: 0.8758 - recall: 0.0217\n",
      "Epoch 9/9\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 1.6048 - accuracy: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24b835bdd48>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_x,train_y, epochs=9,class_weight={0:10,1:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c111fe3c-72f5-4791-bc7c-a82206c47dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.8085 - precision: 0.8085 - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46671178936958313, 0.8084999918937683, 0.8084999918937683, 1.0]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "810fd61e-e212-4c58-be3f-55280d26279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085\n"
     ]
    }
   ],
   "source": [
    "# print(features[:5])\n",
    "results =[]\n",
    "for i, x in enumerate(test_x):\n",
    "    # if i > 10:\n",
    "        # break\n",
    "    x = x.reshape(1,2)\n",
    "    # print(x)\n",
    "    # print(np.array(x).shape)\n",
    "    result = classifier.predict(x)\n",
    "    # print(result)\n",
    "    results.append(np.squeeze(result.tolist()))\n",
    "\n",
    "results = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(results)\n",
    "]\n",
    "accuracy = 0\n",
    "for i,x in enumerate(results):\n",
    "    # print(x, test_y[i])\n",
    "    if x == test_y[i]:\n",
    "        accuracy = accuracy + 1\n",
    "print(accuracy/len(results))\n",
    "# print(results[:10])\n",
    "# print(true_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2cd68a8f-c701-444f-8252-4e23390ea7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0  383]\n",
      " [   0 1617]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(test_y, results)\n",
    "print(cf_matrix)\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_title('Seaborn Confusion Matrix with labels\\n\\n');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87336688-888a-4dcf-98de-beedc2141ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "1001\n",
      "1001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x24bacee4108>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(features[:,1].size)\n",
    "print(features[:,0].size)\n",
    "print(true_labels.size)\n",
    "plt.scatter(Trues[:,0], Trues[:,1])\n",
    "plt.scatter(Falses[:,0], Falses[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43e99c1b-8ee9-4237-b6c8-3894e7093832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78823228, 0.87105382, 0.88275279, ..., 0.78529673, 0.92740711,\n",
       "       0.82061929])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(features,true_labels)\n",
    "reg.score(features,true_labels)\n",
    "\n",
    "# reg.coef_\n",
    "\n",
    "# reg.intercept_\n",
    "\n",
    "reg.predict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5be02af4-39c5-4f4d-a76c-88c9c32d4af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(features)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6fe277a-55de-471a-ad16-39523dcdfddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(scaled_features)\n",
    "plt.scatter(features[:,0], features[:,1],)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5d3e814-9a7a-4535-b1f7-7e3649fabfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 0 0 0 1 1 1 1]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.labels_[:15])\n",
    "print(true_labels[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20227693-976a-46c5-a24f-848d04bebdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5514842  -0.26481927]\n",
      " [ 1.16825314 -0.22331414]\n",
      " [ 1.16825314  0.64455279]\n",
      " [-1.5833266  -0.09866509]\n",
      " [ 0.4803582   0.60230442]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "print(scaled_features[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "022b05ca-556b-4328-bf9b-4eda465fe683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate seeds from kmeans++\n",
    "centers_init, indices = kmeans_plusplus(scaled_features, n_clusters=2, random_state=0)\n",
    "# Plot init seeds along side sample data\n",
    "\n",
    "kmeans = KMeans(\n",
    "    init=\"random\",\n",
    "    n_clusters=2,\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cec0af-ef3f-4e27-b90d-20f69a5052db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init='random', n_clusters=2, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90b1da9-e01d-4067-a59a-d392c5282813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1963.0247119877295\n",
      "[[7.07364341e+00 6.21600425e-03]\n",
      " [1.97525773e+00 5.49764369e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The lowest SSE value\n",
    "print(kmeans.inertia_)\n",
    "\n",
    "\n",
    "# Final locations of the centroid\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# The number of iterations required to converge\n",
    "kmeans.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3756859-e956-42cd-8dc3-ae2cf39cb7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f22731a3-b602-4a87-8162-426754fa6d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced_data = scaled_features\n",
    "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
    "h = 0.02  # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(\n",
    "    Z,\n",
    "    interpolation=\"nearest\",\n",
    "    extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "    cmap=plt.cm.Paired,\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], \"k.\", markersize=2)\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(\n",
    "    centroids[:, 0],\n",
    "    centroids[:, 1],\n",
    "    marker=\"x\",\n",
    "    s=169,\n",
    "    linewidths=3,\n",
    "    color=\"w\",\n",
    "    zorder=10,\n",
    ")\n",
    "plt.title(\n",
    "    \"K-means clustering on the digits dataset (PCA-reduced data)\\n\"\n",
    "    \"Centroids are marked with white cross\"\n",
    ")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dd4b1-7779-4ee5-a3d7-656bb33951a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
