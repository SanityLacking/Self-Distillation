{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook example for building a BrevisNet model using Inceptionv3 as a base.\n",
    "\n",
    "Things to keep in mind when running this example: \n",
    "1. That the dataset size matches the model input size\n",
    "2. That the names of the joining layer points matches what you expect\n",
    "3. That your computer has enough memory to build the model and train as well as shuffle and load the dataset. In testing I've found that if the kernel gets interupted and then continued, the ram and gpu memory allocation can get wonky when performing the fit command.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'branchingdnn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1728/3186071916.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"..\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Adds higher directory to python modules path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbranchingdnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbranching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'branchingdnn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, test_ds, validation_ds) = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227),include_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEntropy(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        if isinstance(y_hat, list):\n",
    "            y_hat = np.array(y_hat)\n",
    "        sum_entropy = 0\n",
    "        if y_hat.ndim >1:\n",
    "            return list(map(calcEntropy,y_hat))\n",
    "        for i in range(len(y_hat)):\n",
    "            if y_hat[i] != 0: # log of zero is undefined, see MacKay's book \"Information Theory, Inference, and Learning Algorithms\"  for more info on this workaround reasoning.\n",
    "                entropy =y_hat[i] * math.log(y_hat[i],2)\n",
    "                sum_entropy +=  entropy\n",
    "\n",
    "        return -sum_entropy\n",
    "    \n",
    "def calcEntropy_Tensors(y_hat):\n",
    "        #entropy is the sum of y * log(y) for all possible labels.\n",
    "        #doesn't deal with cases of log(0)\n",
    "        rank = tf.rank(y_hat)\n",
    "        def calc_E(y_hat):\n",
    "            results = tf.clip_by_value((tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))), -1e12, 1e12)\n",
    "#             results = tf.clip_by_value(results, -1e12, 1e12)\n",
    "#             print(\"res \", results)\n",
    "            return tf.reduce_sum(y_hat * results)\n",
    "\n",
    "        sumEntropies = (tf.map_fn(calc_E,tf.cast(y_hat,'float')))\n",
    "        \n",
    "        if rank == 1:\n",
    "            sumEntropies = tf.reduce_sum(sumEntropies)\n",
    "        return -sumEntropies\n",
    "    \n",
    "def calcEntropy_Tensors2(y_hat):\n",
    "    #entropy is the sum of y * log(y) for all possible labels.\n",
    "    #doesn't deal with cases of log(0)\n",
    "#     num = tf.math.log(y_hat)\n",
    "# #     print(\"num\",num)\n",
    "#     dem = tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "# #     print(\"dem\",dem)\n",
    "#     E = num / dem\n",
    "# #     print(\"E\",E)\n",
    "#     P = y_hat * E\n",
    "# #     print(\"p\",P)\n",
    "#     mean = tf.reduce_mean(tf.boolean_mask(P, tf.math.is_finite(P)))\n",
    "#     print(\"mean\",mean)\n",
    "#     sumEntropies = mean\n",
    "    val = y_hat * tf.math.log(y_hat)/tf.math.log(tf.constant(2, dtype=y_hat.dtype))\n",
    "    sumEntropies =  tf.reduce_mean(tf.boolean_mask(val,tf.math.is_finite(val)))\n",
    "    return -sumEntropies\n",
    "    \n",
    "# This function to generate evidence is used for the first example\n",
    "def relu_evidence(logits):\n",
    "    return tf.nn.relu(logits)\n",
    "\n",
    "# This one usually works better and used for the second and third examples\n",
    "# For general settings and different datasets, you may try this one first\n",
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits,-10,10))\n",
    "\n",
    "# This one is another alternative and \n",
    "# usually behaves better than the relu_evidence \n",
    "def softplus_evidence(logits):\n",
    "    return tf.nn.softplus(logits)\n",
    "\n",
    "def KL(alpha):\n",
    "    # print(\"K:\",K)\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    S_beta = tf.reduce_sum(beta,axis=1,keepdims=True)\n",
    "    lnB = tf.compat.v1.lgamma(S_alpha) - tf.reduce_sum(tf.compat.v1.lgamma(alpha),axis=1,keepdims=True)\n",
    "    lnB_uni = tf.reduce_sum(tf.compat.v1.lgamma(beta),axis=1,keepdims=True) - tf.compat.v1.lgamma(S_beta)\n",
    "\n",
    "    dg0 = tf.compat.v1.digamma(S_alpha)\n",
    "    dg1 = tf.compat.v1.digamma(alpha)\n",
    "\n",
    "    kl = tf.reduce_sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "    # print(\"kl\", kl)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyEndpoint(tf.keras.layers.Layer):\n",
    "        def __init__(self, num_outputs, name=None, **kwargs):\n",
    "            super(CrossEntropyEndpoint, self).__init__(name=name)\n",
    "            self.num_outputs = num_outputs\n",
    "#             self.kl = tf.keras.losses.KLDivergence()\n",
    "            self.loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "#             self.loss_fn = tf.keras.losses.categorical_crossentropy\n",
    "            self.evidence = softplus_evidence\n",
    "#             self.evidence = tf.compat.v1.distributions.Dirichlet\n",
    "            self.temperature = 10\n",
    "            self.lmb = 0.005\n",
    "        def build(self, input_shape):\n",
    "            self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "        def get_config(self):\n",
    "            config = super().get_config().copy()\n",
    "            config.update({\n",
    "                'num_outputs': self.num_outputs,\n",
    "                'name': self.name\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def call(self, inputs, labels,learning_rate=1):\n",
    "            outputs = tf.matmul(inputs,self.kernel)\n",
    "            softmax = tf.nn.softmax(outputs)\n",
    "            evidence = self.evidence (outputs)\n",
    "            alpha = evidence + 1\n",
    "            u = self.num_outputs / tf.reduce_sum(alpha, axis=1, keepdims=True) #uncertainty\n",
    "          \n",
    "            # prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
    "            pred = tf.argmax(outputs,1)\n",
    "            truth = tf.argmax(labels,1)\n",
    "            match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "            # total_evidence = tf.reduce_sum(evidence,1, keepdims=True)\n",
    "            mean_succ = tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*match) / tf.reduce_sum(match+1e-20)\n",
    "            mean_fail = tf.reduce_sum(tf.reduce_sum(tf.reduce_sum(evidence,1, keepdims=True)*(1-match)) / (tf.reduce_sum(tf.abs(1-match))+1e-20) )\n",
    "            \n",
    "            self.add_metric(evidence, name=self.name+\"_evidence\",aggregation='mean')\n",
    "            self.add_metric(mean_succ, name=self.name+\"_mean_ev_succ\",aggregation='mean')\n",
    "            self.add_metric(mean_fail, name=self.name+\"_mean_ev_fail\",aggregation='mean')\n",
    "            \n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "\n",
    "    return  cross_entropy_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence\n",
    "\n",
    "# outputs =[]\n",
    "# targets = tf.keras.Input(shape=(10,),name='targets')\n",
    "# inputs = tf.keras.Input(shape=(227,227,3))\n",
    "# x = tf.keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_1 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_1 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "# # branch_output_2 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "# branch_output_2 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = tf.keras.layers.BatchNormalization()(x)\n",
    "# x = tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),padding=\"same\")(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "\n",
    "\n",
    "\n",
    "# branchLayer = tf.keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "# branchLayer = tf.keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "# branchLayer = tf.keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "# # branchLayer = tf.keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# branch_output_3 = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer)\n",
    "# # branch_output_3 = (CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_endpoint\"))(branchLayer,targets))\n",
    "\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# output = tf.keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x)\n",
    "# # output = CrossEntropyEndpoint(10, name=tf.compat.v1.get_default_graph().unique_name(\"endpoint\"))(x, targets)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[inputs,targets], outputs=[output,branch_output_1,branch_output_2,branch_output_3], name=\"alexnet_branched_entropy\")\n",
    "# loss_fn = loss_function()\n",
    "# model.compile( loss=\"categorical_crossentropy\", optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# root_logdir = os.path.join(os.curdir, \"logs\\\\fit\\\\\")\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"alexNetv6_entropy_branched_scratch_40.hdf5\", monitor='val_loss',verbose=1,save_best_only=True, mode='auto')\n",
    "# def get_run_logdir():\n",
    "#     run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "#     return os.path.join(root_logdir, run_id)\n",
    "\n",
    "# run_logdir = get_run_logdir()\n",
    "# tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "# model.fit(train_ds,\n",
    "#         epochs=40,\n",
    "#         validation_data=validation_ds,\n",
    "#         validation_freq=1,\n",
    "#         # batch_size=1,\n",
    "#         verbose=1,\n",
    "#         callbacks=[tensorboard_cb,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(224,224), include_targets=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_ds, validation_ds, test_ds) = dataset\n",
    "\n",
    "# print(train_ds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets already present?  False\n",
      "added targets\n",
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  mixed0\n",
      "add Branch to branch point  mixed1\n",
      "add Branch to branch point  mixed6\n",
      "<branchingdnn.core.BranchingDnn.branched_model object at 0x000001AF2D3D1978>\n"
     ]
    }
   ],
   "source": [
    "# model  = tf.keras.models.load_model('alexNetv6_evidence_branched_contin_30.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})\n",
    "\n",
    "loss_fn = loss_function()\n",
    "brevis_model = (branching.core.branched_model(modelName=\"../models/inception_finetuned.hdf5\",saveName=\"inception_entropy_flat\",transfer=True,customOptions=\"\")\n",
    "            .add_branches(branching.branches.branch.newBranch_flatten_incept,[\"mixed0\",\"mixed1\",\"mixed6\"], target_input=True)                        \n",
    "            ).compile(customOptions=\"\")\n",
    "# brevis.evaluate(test_ds)\n",
    "brevis_model.fit(dataset, 12, loss=\"categorical_crossentropy\", optimizer=tf.optimizers.SGD(), transfer=False, customOptions=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# brevis.model.summary()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "\n",
      "customOption: Other\n",
      "https://app.neptune.ai/cailen01/branchingDNN/e/BRAN-374\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/12\n",
      "1406/1406 [==============================] - 468s 322ms/step - loss: 5.3854 - classification_loss: 0.0625 - branch_softmax_3_loss: 1.9018 - branch_softmax_4_loss: 1.9078 - branch_softmax_5_loss: 1.5133 - classification_accuracy: 0.9791 - branch_softmax_3_accuracy: 0.3014 - branch_softmax_4_accuracy: 0.2989 - branch_softmax_5_accuracy: 0.5482 - val_loss: 3.2439 - val_classification_loss: 0.0648 - val_branch_softmax_3_loss: 1.4355 - val_branch_softmax_4_loss: 1.3936 - val_branch_softmax_5_loss: 0.3500 - val_classification_accuracy: 0.9794 - val_branch_softmax_3_accuracy: 0.4688 - val_branch_softmax_4_accuracy: 0.4800 - val_branch_softmax_5_accuracy: 0.8912\n",
      "\n",
      "Epoch 00001: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 2/12\n",
      "1406/1406 [==============================] - 462s 318ms/step - loss: 3.1282 - classification_loss: 0.0609 - branch_softmax_3_loss: 1.4136 - branch_softmax_4_loss: 1.3117 - branch_softmax_5_loss: 0.3421 - classification_accuracy: 0.9797 - branch_softmax_3_accuracy: 0.4797 - branch_softmax_4_accuracy: 0.5150 - branch_softmax_5_accuracy: 0.8889 - val_loss: 3.3953 - val_classification_loss: 0.0900 - val_branch_softmax_3_loss: 1.6232 - val_branch_softmax_4_loss: 1.4313 - val_branch_softmax_5_loss: 0.2508 - val_classification_accuracy: 0.9720 - val_branch_softmax_3_accuracy: 0.4191 - val_branch_softmax_4_accuracy: 0.4850 - val_branch_softmax_5_accuracy: 0.9167\n",
      "\n",
      "Epoch 00002: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 3/12\n",
      "1406/1406 [==============================] - 463s 319ms/step - loss: 2.6004 - classification_loss: 0.0384 - branch_softmax_3_loss: 1.2556 - branch_softmax_4_loss: 1.1075 - branch_softmax_5_loss: 0.1988 - classification_accuracy: 0.9876 - branch_softmax_3_accuracy: 0.5455 - branch_softmax_4_accuracy: 0.5992 - branch_softmax_5_accuracy: 0.9353 - val_loss: 2.6592 - val_classification_loss: 0.0813 - val_branch_softmax_3_loss: 1.2840 - val_branch_softmax_4_loss: 1.0852 - val_branch_softmax_5_loss: 0.2087 - val_classification_accuracy: 0.9742 - val_branch_softmax_3_accuracy: 0.5258 - val_branch_softmax_4_accuracy: 0.6032 - val_branch_softmax_5_accuracy: 0.9289\n",
      "\n",
      "Epoch 00003: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 4/12\n",
      "1406/1406 [==============================] - 471s 324ms/step - loss: 2.2763 - classification_loss: 0.0234 - branch_softmax_3_loss: 1.1344 - branch_softmax_4_loss: 0.9797 - branch_softmax_5_loss: 0.1387 - classification_accuracy: 0.9925 - branch_softmax_3_accuracy: 0.5909 - branch_softmax_4_accuracy: 0.6477 - branch_softmax_5_accuracy: 0.9543 - val_loss: 3.0744 - val_classification_loss: 0.0887 - val_branch_softmax_3_loss: 1.5731 - val_branch_softmax_4_loss: 1.2072 - val_branch_softmax_5_loss: 0.2054 - val_classification_accuracy: 0.9732 - val_branch_softmax_3_accuracy: 0.4663 - val_branch_softmax_4_accuracy: 0.5709 - val_branch_softmax_5_accuracy: 0.9327\n",
      "\n",
      "Epoch 00004: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 5/12\n",
      "1406/1406 [==============================] - 509s 350ms/step - loss: 2.0319 - classification_loss: 0.0172 - branch_softmax_3_loss: 1.0360 - branch_softmax_4_loss: 0.8884 - branch_softmax_5_loss: 0.0903 - classification_accuracy: 0.9947 - branch_softmax_3_accuracy: 0.6249 - branch_softmax_4_accuracy: 0.6780 - branch_softmax_5_accuracy: 0.9711 - val_loss: 3.0720 - val_classification_loss: 0.1060 - val_branch_softmax_3_loss: 1.4816 - val_branch_softmax_4_loss: 1.2849 - val_branch_softmax_5_loss: 0.1996 - val_classification_accuracy: 0.9685 - val_branch_softmax_3_accuracy: 0.4844 - val_branch_softmax_4_accuracy: 0.5517 - val_branch_softmax_5_accuracy: 0.9341\n",
      "\n",
      "Epoch 00005: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 6/12\n",
      "1406/1406 [==============================] - 582s 402ms/step - loss: 1.8692 - classification_loss: 0.0135 - branch_softmax_3_loss: 0.9672 - branch_softmax_4_loss: 0.8240 - branch_softmax_5_loss: 0.0645 - classification_accuracy: 0.9961 - branch_softmax_3_accuracy: 0.6521 - branch_softmax_4_accuracy: 0.7064 - branch_softmax_5_accuracy: 0.9797 - val_loss: 2.9173 - val_classification_loss: 0.0998 - val_branch_softmax_3_loss: 1.5162 - val_branch_softmax_4_loss: 1.0985 - val_branch_softmax_5_loss: 0.2028 - val_classification_accuracy: 0.9752 - val_branch_softmax_3_accuracy: 0.5148 - val_branch_softmax_4_accuracy: 0.6230 - val_branch_softmax_5_accuracy: 0.9371\n",
      "\n",
      "Epoch 00006: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 7/12\n",
      "1406/1406 [==============================] - 592s 408ms/step - loss: 1.7598 - classification_loss: 0.0116 - branch_softmax_3_loss: 0.9175 - branch_softmax_4_loss: 0.7805 - branch_softmax_5_loss: 0.0502 - classification_accuracy: 0.9961 - branch_softmax_3_accuracy: 0.6694 - branch_softmax_4_accuracy: 0.7177 - branch_softmax_5_accuracy: 0.9841 - val_loss: 2.4579 - val_classification_loss: 0.1050 - val_branch_softmax_3_loss: 1.1947 - val_branch_softmax_4_loss: 0.9703 - val_branch_softmax_5_loss: 0.1879 - val_classification_accuracy: 0.9722 - val_branch_softmax_3_accuracy: 0.5982 - val_branch_softmax_4_accuracy: 0.6743 - val_branch_softmax_5_accuracy: 0.9409\n",
      "\n",
      "Epoch 00007: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 8/12\n",
      "1406/1406 [==============================] - 607s 419ms/step - loss: 1.6242 - classification_loss: 0.0088 - branch_softmax_3_loss: 0.8557 - branch_softmax_4_loss: 0.7233 - branch_softmax_5_loss: 0.0363 - classification_accuracy: 0.9974 - branch_softmax_3_accuracy: 0.6933 - branch_softmax_4_accuracy: 0.7409 - branch_softmax_5_accuracy: 0.9888 - val_loss: 2.1720 - val_classification_loss: 0.1177 - val_branch_softmax_3_loss: 0.9718 - val_branch_softmax_4_loss: 0.8803 - val_branch_softmax_5_loss: 0.2022 - val_classification_accuracy: 0.9700 - val_branch_softmax_3_accuracy: 0.6524 - val_branch_softmax_4_accuracy: 0.6877 - val_branch_softmax_5_accuracy: 0.9405\n",
      "\n",
      "Epoch 00008: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 9/12\n",
      " 675/1406 [=============>................] - ETA: 5:09 - loss: 1.5650 - classification_loss: 0.0097 - branch_softmax_3_loss: 0.8296 - branch_softmax_4_loss: 0.6917 - branch_softmax_5_loss: 0.0341 - classification_accuracy: 0.9964 - branch_softmax_3_accuracy: 0.7000 - branch_softmax_4_accuracy: 0.7484 - branch_softmax_5_accuracy: 0.9895"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-451067eabd42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrevis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainTransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustomOptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\branchingdnn\\core.py\u001b[0m in \u001b[0;36mtrainTransfer\u001b[1;34m(self, numEpocs, loss, optimizer, transfer, customOptions)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mtrainTransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumEpocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustomOptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbranchingdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainModelTransfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumEpocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveName\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransfer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustomOptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustomOptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\branchingdnn\\models\\train.py\u001b[0m in \u001b[0;36mtrainModelTransfer\u001b[1;34m(model, dataset, loss, optimizer, resetBranches, epocs, save, transfer, saveName, customOptions, tags)\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# batch_size=1,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m             callbacks=[tensorboard_cb,checkpoint,neptune_cbk])\n\u001b[0m\u001b[0;32m    137\u001b[0m                         \u001b[1;31m# callbacks=[tensorboard_cb,checkpoint])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    803\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1259\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3415\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3417\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric_obj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m         \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mweighted_metric_obj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweighted_metric_objs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mcontrol_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mag_update_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_update_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol_status\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdef_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    668\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    348\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Allowlisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    479\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m     return super(MeanMetricWrapper, self).update_state(\n\u001b[1;32m--> 620\u001b[1;33m         matches, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, values, sample_weight)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWEIGHTED_MEAN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[0mnum_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[0mnum_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m    964\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[1;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m-> 1823\u001b[1;33m         _ctx, \"Cast\", name, x, \"DstT\", DstT, \"Truncate\", Truncate)\n\u001b[0m\u001b[0;32m   1824\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "brevis_model.fit(dataset, 12, loss=\"categorical_crossentropy\", optimizer=tf.optimizers.SGD(), transfer=False, customOptions=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "Model: \"model_branched\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten (Flatten)        (None, 160000)       0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_1 (Flatten)      (None, 180000)       0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "branch_flatten_2 (Flatten)      (None, 110592)       0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "branch124 (Dense)               (None, 1024)         163841024   branch_flatten[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "branch124_1 (Dense)             (None, 1024)         184321024   branch_flatten_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "branch124_2 (Dense)             (None, 1024)         113247232   branch_flatten_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch64 (Dense)                (None, 512)          524800      branch124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "branch64_1 (Dense)              (None, 512)          524800      branch124_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "branch64_2 (Dense)              (None, 512)          524800      branch124_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "branch_output (Dense)           (None, 10)           5130        branch64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_1 (Dense)         (None, 10)           5130        branch64_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "branch_output_2 (Dense)         (None, 10)           5130        branch64_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "targets (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 10)           5130        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax (Softmax)        (None, 10)           0           branch_output[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_1 (Softmax)      (None, 10)           0           branch_output_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "branch_softmax_2 (Softmax)      (None, 10)           0           branch_output_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 487,429,960\n",
      "Trainable params: 487,395,528\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "customOption: Other\n",
      "https://app.neptune.ai/cailen01/branchingDNN/e/BRAN-338\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n",
      "Epoch 1/12\n",
      "1406/1406 [==============================] - 537s 368ms/step - loss: 11.0903 - classification_loss: 2.1802 - branch_softmax_loss: 3.1945 - branch_softmax_1_loss: 3.1898 - branch_softmax_2_loss: 2.5258 - classification_accuracy: 0.9890 - branch_softmax_accuracy: 0.0963 - branch_softmax_1_accuracy: 0.1010 - branch_softmax_2_accuracy: 0.6927 - val_loss: 10.8150 - val_classification_loss: 2.1664 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2722 - val_classification_accuracy: 0.9974 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9050\n",
      "\n",
      "Epoch 00001: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 2/12\n",
      "1406/1406 [==============================] - 538s 372ms/step - loss: 10.8050 - classification_loss: 2.1718 - branch_softmax_loss: 3.1933 - branch_softmax_1_loss: 3.1909 - branch_softmax_2_loss: 2.2490 - classification_accuracy: 0.9937 - branch_softmax_accuracy: 0.0980 - branch_softmax_1_accuracy: 0.1001 - branch_softmax_2_accuracy: 0.9292 - val_loss: 10.7806 - val_classification_loss: 2.1670 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2372 - val_classification_accuracy: 0.9968 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9373\n",
      "\n",
      "Epoch 00002: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 3/12\n",
      "1406/1406 [==============================] - 535s 371ms/step - loss: 10.7657 - classification_loss: 2.1687 - branch_softmax_loss: 3.1896 - branch_softmax_1_loss: 3.1933 - branch_softmax_2_loss: 2.2141 - classification_accuracy: 0.9950 - branch_softmax_accuracy: 0.1012 - branch_softmax_1_accuracy: 0.0980 - branch_softmax_2_accuracy: 0.9567 - val_loss: 10.7854 - val_classification_loss: 2.1672 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2418 - val_classification_accuracy: 0.9960 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9317\n",
      "\n",
      "Epoch 00003: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 4/12\n",
      "1406/1406 [==============================] - 533s 370ms/step - loss: 10.7432 - classification_loss: 2.1664 - branch_softmax_loss: 3.1909 - branch_softmax_1_loss: 3.1918 - branch_softmax_2_loss: 2.1941 - classification_accuracy: 0.9969 - branch_softmax_accuracy: 0.1001 - branch_softmax_1_accuracy: 0.0994 - branch_softmax_2_accuracy: 0.9740 - val_loss: 10.7771 - val_classification_loss: 2.1667 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2340 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9391\n",
      "\n",
      "Epoch 00004: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 5/12\n",
      "1406/1406 [==============================] - 533s 370ms/step - loss: 10.7349 - classification_loss: 2.1649 - branch_softmax_loss: 3.1917 - branch_softmax_1_loss: 3.1933 - branch_softmax_2_loss: 2.1850 - classification_accuracy: 0.9978 - branch_softmax_accuracy: 0.0994 - branch_softmax_1_accuracy: 0.0981 - branch_softmax_2_accuracy: 0.9822 - val_loss: 10.7725 - val_classification_loss: 2.1672 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2289 - val_classification_accuracy: 0.9958 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9431\n",
      "\n",
      "Epoch 00005: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 6/12\n",
      "1406/1406 [==============================] - 536s 371ms/step - loss: 10.7252 - classification_loss: 2.1642 - branch_softmax_loss: 3.1906 - branch_softmax_1_loss: 3.1912 - branch_softmax_2_loss: 2.1791 - classification_accuracy: 0.9982 - branch_softmax_accuracy: 0.1004 - branch_softmax_1_accuracy: 0.0998 - branch_softmax_2_accuracy: 0.9861 - val_loss: 10.7709 - val_classification_loss: 2.1658 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2286 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9437\n",
      "\n",
      "Epoch 00006: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 7/12\n",
      "1406/1406 [==============================] - 538s 373ms/step - loss: 10.7202 - classification_loss: 2.1635 - branch_softmax_loss: 3.1918 - branch_softmax_1_loss: 3.1910 - branch_softmax_2_loss: 2.1740 - classification_accuracy: 0.9988 - branch_softmax_accuracy: 0.0994 - branch_softmax_1_accuracy: 0.1000 - branch_softmax_2_accuracy: 0.9905 - val_loss: 10.7615 - val_classification_loss: 2.1657 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2194 - val_classification_accuracy: 0.9966 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9503\n",
      "\n",
      "Epoch 00007: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 8/12\n",
      "1406/1406 [==============================] - 540s 374ms/step - loss: 10.7181 - classification_loss: 2.1632 - branch_softmax_loss: 3.1916 - branch_softmax_1_loss: 3.1926 - branch_softmax_2_loss: 2.1708 - classification_accuracy: 0.9987 - branch_softmax_accuracy: 0.0995 - branch_softmax_1_accuracy: 0.0987 - branch_softmax_2_accuracy: 0.9929 - val_loss: 10.7632 - val_classification_loss: 2.1664 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2203 - val_classification_accuracy: 0.9964 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9501\n",
      "\n",
      "Epoch 00008: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 9/12\n",
      "1406/1406 [==============================] - 539s 374ms/step - loss: 10.7157 - classification_loss: 2.1630 - branch_softmax_loss: 3.1924 - branch_softmax_1_loss: 3.1906 - branch_softmax_2_loss: 2.1698 - classification_accuracy: 0.9989 - branch_softmax_accuracy: 0.0988 - branch_softmax_1_accuracy: 0.1004 - branch_softmax_2_accuracy: 0.9936 - val_loss: 10.7599 - val_classification_loss: 2.1661 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2174 - val_classification_accuracy: 0.9968 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9523\n",
      "\n",
      "Epoch 00009: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 10/12\n",
      "1406/1406 [==============================] - 542s 376ms/step - loss: 10.7142 - classification_loss: 2.1634 - branch_softmax_loss: 3.1894 - branch_softmax_1_loss: 3.1920 - branch_softmax_2_loss: 2.1694 - classification_accuracy: 0.9984 - branch_softmax_accuracy: 0.1014 - branch_softmax_1_accuracy: 0.0991 - branch_softmax_2_accuracy: 0.9936 - val_loss: 10.7615 - val_classification_loss: 2.1669 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2181 - val_classification_accuracy: 0.9954 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9507\n",
      "\n",
      "Epoch 00010: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 11/12\n",
      "1406/1406 [==============================] - 564s 391ms/step - loss: 10.7130 - classification_loss: 2.1625 - branch_softmax_loss: 3.1914 - branch_softmax_1_loss: 3.1909 - branch_softmax_2_loss: 2.1682 - classification_accuracy: 0.9994 - branch_softmax_accuracy: 0.0997 - branch_softmax_1_accuracy: 0.1001 - branch_softmax_2_accuracy: 0.9944 - val_loss: 10.7588 - val_classification_loss: 2.1670 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2154 - val_classification_accuracy: 0.9952 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9537\n",
      "\n",
      "Epoch 00011: saving model to models\\inception_entropy_flat.hdf5\n",
      "Epoch 12/12\n",
      "1406/1406 [==============================] - 574s 398ms/step - loss: 10.7121 - classification_loss: 2.1624 - branch_softmax_loss: 3.1915 - branch_softmax_1_loss: 3.1906 - branch_softmax_2_loss: 2.1677 - classification_accuracy: 0.9993 - branch_softmax_accuracy: 0.0996 - branch_softmax_1_accuracy: 0.1004 - branch_softmax_2_accuracy: 0.9949 - val_loss: 10.7578 - val_classification_loss: 2.1666 - val_branch_softmax_loss: 3.1897 - val_branch_softmax_1_loss: 3.1867 - val_branch_softmax_2_loss: 2.2149 - val_classification_accuracy: 0.9958 - val_branch_softmax_accuracy: 0.1012 - val_branch_softmax_1_accuracy: 0.1038 - val_branch_softmax_2_accuracy: 0.9543\n",
      "\n",
      "Epoch 00012: saving model to models\\inception_entropy_flat.hdf5\n",
      "<tensorflow.python.keras.callbacks.History object at 0x00000141A1DA2470>\n",
      "312/312 - 38s - loss: 10.8198 - classification_loss: 2.2003 - branch_softmax_loss: 3.1911 - branch_softmax_1_loss: 3.1908 - branch_softmax_2_loss: 2.2376 - classification_accuracy: 0.9666 - branch_softmax_accuracy: 0.1000 - branch_softmax_1_accuracy: 0.1002 - branch_softmax_2_accuracy: 0.9333\n",
      "overall loss: 10.819804191589355\n"
     ]
    }
   ],
   "source": [
    "model = brevis.trainTransfer(12, loss=loss_fn, optimizer=tf.optimizers.SGD(), transfer=False, customOptions=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = tf.keras.models.load_model('models/inception_finetuned.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n",
      "10000/10000 [==============================] - 173s 17ms/step - loss: 0.1502 - accuracy: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15015941858291626, 0.9585000276565552]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),1,5000,22500,(224,224), include_targets=False)\n",
    "\n",
    "(train_ds, test_ds,validation_set) = dataset\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n",
      "10000/10000 [==============================] - 215s 21ms/step - loss: 9.4830 - classification_loss: 2.2052 - branch_softmax_3_loss: 2.4957 - branch_softmax_4_loss: 2.5354 - branch_softmax_5_loss: 2.2465 - classification_classification_accuracy: 0.9614 - branch_softmax_3_branch_softmax_3_accuracy: 0.7051 - branch_softmax_4_branch_softmax_4_accuracy: 0.6688 - branch_softmax_5_branch_softmax_5_accuracy: 0.9256: 3:19 - loss: 9.4896 - classification_loss: 2.2159 - branch_softmax_3_loss: 2.4834 - branch_softmax_4_loss: 2.5210 - branch_softmax_5_loss: 2.2693 - classification_classification_accuracy: 0.9518 - branch_softmax_3_branch_softmax_3_acc - ETA: 3:13 - loss: 9.4554 - classification_loss: 2.1993 - branch_softmax_3_loss: 2.5005 - branch_softmax_4_loss: 2.5129 - branch_softmax_5_loss: 2.2427 - classification_classification_accuracy: 0.9675 - branch_softmax_3_branch_softmax_3_accuracy: 0.7003 - branch_softmax_4_branch_softmax_4_accuracy: 0.6901 - branch_softmax_5_branch_softmax_5_accu - ETA: 3:12 - loss: 9.4402 - classification_loss: 2.1972 - branch_softmax_3_loss: 2.4953 - branch_softmax_4_loss: 2.5054 - branch_softmax_5_loss: 2.2423 - classification_ - ETA: 3:02 - loss: 9.4482 - classification_loss: 2.1980 - branch_softmax_3_loss: 2.4880 - branch_softmax_4_loss: 2.5181 - branch_softmax_5_loss: 2.2440 - classification_classification_accuracy: 0.9671 - branch_softmax_3_branch_softmax_3_accuracy: 0.7131 - branch_softmax_4_branch_softmax_4_accuracy: 0.6852 - branch_softma - ETA: 2:59 - loss: 9.4444 - classification_loss: 2.1981 - branch_softmax_3_loss: 2.4905 - branch_softmax_4_loss: 2.5110 - branch_softmax_5_loss: 2.2448 - classification_classification_accuracy: 0.9668 - branch_softmax_3_branch_softmax_3_accuracy: 0.7104 - branch_softmax_4_branch_softm - ETA: 2:55 - loss: 9.4529 - classification_loss: 2.2014 - branch_softmax_3_loss: 2 - ETA: 2:38 - loss: 9.4761 - classification_loss: 2.2037 - branch_softmax_3_loss: 2.4970 - branch_softmax_4_loss: 2.5218 - branch_softmax_5_loss: 2.2537 - classification_classification_accuracy: 0.9628  - ETA: 2s - loss: 9.4833 - classification_loss: 2.2053 - branch_softmax_3_loss: 2.4958 - branch_softmax_4_loss: 2.5354 - branch_softmax_5_loss: 2.2466 - classification_classification_accuracy: 0.9612 - branch_softmax_3_branch_softmax_3_accuracy: 0.7050 - branch_softmax_4_branch_softmax_4_accuracy: 0.6688 - branch_softmax_5_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.482992172241211,\n",
       " 2.2051708698272705,\n",
       " 2.4957211017608643,\n",
       " 2.5354161262512207,\n",
       " 2.246487855911255,\n",
       " 0.9613999724388123,\n",
       " 0.7050999999046326,\n",
       " 0.6687999963760376,\n",
       " 0.925599992275238]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = tf.keras.models.load_model('models/inception_entropy_conv2d.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})\n",
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),1,5000,22500,(224,224), include_targets=True)\n",
    "\n",
    "(train_ds, test_ds,validation_set) = dataset\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : True\n",
      "adding targets to inputs\n",
      "trainSize 45000\n",
      "testSize 10000\n",
      "156/156 [==============================] - 15s 77ms/step - loss: 9.4108 - classification_loss: 2.1765 - branch_softmax_3_loss: 2.4808 - branch_softmax_4_loss: 2.5275 - branch_softmax_5_loss: 2.2260 - classification_classification_accuracy: 0.9866 - branch_softmax_3_branch_softmax_3_accuracy: 0.7185 - branch_softmax_4_branch_softmax_4_accuracy: 0.6773 - branch_softmax_5_branch_softmax_5_accuracy: 0.9445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.410823822021484,\n",
       " 2.1765189170837402,\n",
       " 2.4808175563812256,\n",
       " 2.527522325515747,\n",
       " 2.2259633541107178,\n",
       " 0.9865785241127014,\n",
       " 0.7185496687889099,\n",
       " 0.6772836446762085,\n",
       " 0.9445112347602844]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = tf.keras.models.load_model('models/inception_entropy_conv2d.hdf5', custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"cross_entropy_evidence\":loss_function()})\n",
    "dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(224,224), include_targets=True)\n",
    "\n",
    "(train_ds, validation_ds, test_ds) = dataset\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0 of 10000\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-b5b8c402bc14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#                 print(\"overlap\",pOverlap[j][i])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;31m#             print(result)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "evidence=False\n",
    "num_outputs=4\n",
    "predictions = []\n",
    "labels = []\n",
    "pClass = []\n",
    "predictions=[]\n",
    "pEvidence = []\n",
    "pUncertainty=[]\n",
    "pOverlap=[]\n",
    "\n",
    "Outputs = pd.DataFrame()\n",
    "pAcc=[]\n",
    "for i in range(num_outputs):\n",
    "    pClass.append([])\n",
    "    predictions.append([])\n",
    "    pEvidence.append([])\n",
    "    pUncertainty.append([])\n",
    "    pAcc.append([])\n",
    "    pOverlap.append([])\n",
    "    # pOutputs.append([])\n",
    "for i, (x,y) in enumerate(test_ds):\n",
    "        if i > 10:\n",
    "            break\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        if evidence: \n",
    "            result = model.model.test_on_batch(x,y)\n",
    "#             print(result)\n",
    "            for j in range(num_outputs):\n",
    "#                 print(\"output\",j)\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "                pAcc[j].append(result[j+(num_outputs+1)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "                if j ==0:\n",
    "                    pEvidence[j].append(0)\n",
    "                else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "                    pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "        else:\n",
    "            result = model.model.predict(x)[0]\n",
    "#             print(result)\n",
    "\n",
    "            for j in range(num_outputs):\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "                # print(pClass[j])\n",
    "                # print(result)\n",
    "                prediction = np.argmax(result[j])\n",
    "                if prediction == pClass[j][i]:\n",
    "                    pAcc[j].append(1)  \n",
    "                else:\n",
    "                    pAcc[j].append(0)  \n",
    "                print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "                pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEvidence_branches(model,test_ds, evidence=True):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "    print(\"outputs\",num_outputs)\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    pOverlap=[]\n",
    "\n",
    "    Outputs = pd.DataFrame()\n",
    "    pAcc=[]\n",
    "    for i in range(num_outputs):\n",
    "        pClass.append([])\n",
    "        predictions.append([])\n",
    "        pEvidence.append([])\n",
    "        pUncertainty.append([])\n",
    "        pAcc.append([])\n",
    "        pOverlap.append([])\n",
    "        # pOutputs.append([])\n",
    "\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "        # if i > 10:\n",
    "            # break\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        if evidence: \n",
    "            result = model.test_on_batch(x,y)\n",
    "            if i < 2:\n",
    "                print(result)\n",
    "#             print(result)\n",
    "            for j in range(num_outputs):\n",
    "#                 print(\"output\",j)\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "#                 print(\"class\",pClass[j][i])\n",
    "                pAcc[j].append(result[j+(num_outputs+1)])  \n",
    "#                 print(\"acc\",pAcc[j][i])\n",
    "                if j ==0:\n",
    "                    pEvidence[j].append(0)\n",
    "                else:\n",
    "#                     print(\"evid Number\",((num_outputs * 2)+1), \" \", ((j-1)*3))\n",
    "                    pEvidence[j].append(result[((num_outputs * 2) + 1)+((j-1)*3)])\n",
    "#                 print(\"evid\",pEvidence[j][i])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "#                 print(\"overlap\",pOverlap[j][i])\n",
    "        else:\n",
    "            result = model.predict(x)[0]\n",
    "            if i < 2:\n",
    "                print(result)\n",
    "    \n",
    "            for j in range(num_outputs):\n",
    "                pClass[j].append(tf.argmax(y[0]).numpy())\n",
    "                # print(pClass[j])\n",
    "                # print(result)\n",
    "                prediction = np.argmax(result[j])\n",
    "                if prediction == pClass[j][i]:\n",
    "                    pAcc[j].append(1)  \n",
    "                else:\n",
    "                    pAcc[j].append(0)  \n",
    "                # print(branching.utils.calcEntropy_Tensors(result[j]).numpy())\n",
    "                pEvidence[j].append(branching.utils.calcEntropy_Tensors(result[j]).numpy()[0])\n",
    "\n",
    "                pOverlap[j].append(pAcc[0][i] - pAcc[j][i])\n",
    "        '''\n",
    "        overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "    Outputs=[]\n",
    "    for j in range(num_outputs):\n",
    "        Predictions = pd.DataFrame({\"label\":pClass[j],\"evidence\":pEvidence[j],\"Acc\":pAcc[j], \"overlap\":pOverlap[j]})\n",
    "        Outputs.append(Predictions)\n",
    "    \n",
    "    print(\"Done\")\n",
    "    \n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool') ##sometime the predictions can come back with 0.5 acc, this should be rounded to 1.\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            E_threshold = mean + std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "\n",
    "def evidenceHistogram(branch_predictions, output_names=[\"main_exit\",\"branch_1\",\"branch_2\",\"branch_3\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    for i, Predictions in enumerate(branch_predictions):\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "        std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        if Evidence:\n",
    "            # E_threshold = mean + std + einsumfunc\n",
    "\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                    \"T_F\":Accepted.loc[Accepted['overlap']==1],\n",
    "                    \"F_T\":Accepted.loc[Accepted['overlap']==-1],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        else:\n",
    "            print(\"mean\",mean , \" std\",std)\n",
    "            E_threshold = mean - std\n",
    "            Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "            # if i ==1 or i == 0 :\n",
    "                # print(Predictions)\n",
    "                # print(Predictions.loc[ (Predictions['Acc'] == True)  & (Predictions[\"overlap\"] == 0) ])\n",
    "            # print(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold) ].count())\n",
    "           \n",
    "            Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                    \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                    \"E_Threshold\":E_threshold,\n",
    "                    # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                    \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                    \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                    \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                    \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                    },index=[i]))\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(\"evidence\")\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "\n",
    "def displayEvidence_cascade(branch_predictions, thresholds=None, output_names=[\"branch_1\",\"branch_2\",\"branch_3\",\"Main_Exit\"], Evidence = True):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure()\n",
    "    series=[]\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.tight_layout()\n",
    "    Outputs=pd.DataFrame()\n",
    "    #lets reorder the predictions so that the final layer is at the end\n",
    "    # _branch_predictions.copy()\n",
    "    _branch_predictions = branch_predictions.copy()\n",
    "    # print(_branch_predictions)\n",
    "    _branch_predictions.append(_branch_predictions.pop(0))\n",
    "    # print(_branch_predictions)\n",
    "    rollOver_indices = pd.Index([])\n",
    "    for i, Predictions in enumerate(_branch_predictions):\n",
    "        #check if rollover is active, if so, select only the predictions whose indexes match the rollover list\n",
    "        # print(rollOver_indices)\n",
    "        test_acc = Predictions[\"Acc\"].astype('bool').value_counts()\n",
    "        test_accuracy = (test_acc.loc[True] /  (test_acc.loc[True] + test_acc.loc[False]))\n",
    "        if len(rollOver_indices)>0:\n",
    "            print(\"rollover enabled, {} predictions provided\".format(len(rollOver_indices)))\n",
    "            Predictions = Predictions.iloc[rollOver_indices]\n",
    "        # print(Predictions.shape)\n",
    "        Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "        # Predictions[\"evidence\"]=Predictions[\"evidence\"].()[0]\n",
    "        acc = Predictions[\"Acc\"].value_counts()\n",
    "        # print(acc)\n",
    "        # print((acc.loc[True] , acc.loc[False]))\n",
    "        _Incorrects_missed = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"overlap\"] == 1)] #all the predictions that the main exit got true and the branch got wrong\n",
    "        if len(_Incorrects_missed) > 0 :\n",
    "            mean = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = _Incorrects_missed.groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "        else:\n",
    "            mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "            std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "\n",
    "        print(\"mean\",mean , \" std\",std)\n",
    "        \n",
    "        correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "        incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "        \n",
    "        E_threshold = -1 #-1 is null for threshold\n",
    "        if thresholds is not None:\n",
    "            try:\n",
    "                E_threshold = thresholds[i]\n",
    "            except:\n",
    "                print(\"threshold not supplied for branch {}, using test data\".format(i))\n",
    "                \n",
    "        if Evidence:\n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean + std\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] >= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] < E_threshold)]\n",
    "        else: \n",
    "            if E_threshold ==-1:\n",
    "                E_threshold = mean - (std/2)\n",
    "            Accepted = Predictions.loc[(Predictions[\"evidence\"] <= E_threshold)]\n",
    "            Rejected = Predictions.loc[(Predictions[\"evidence\"] > E_threshold)]\n",
    "        \n",
    "        rollOver_indices = Rejected.index\n",
    "        Incorrects_overlap = Accepted.loc[(Accepted['Acc'] == False) & (Accepted[\"overlap\"] == 0)].count().iloc[0]\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Predictions\": len(Predictions.index),\n",
    "                \"test_accuracy\": test_accuracy,\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Accepted.shape[0]/(Predictions.shape[0]),\n",
    "                \"accepted_correct\":Accepted.loc[(Predictions['Acc'] == True)].shape[0],\n",
    "                \"accepted_incorrect\":Accepted.loc[(Predictions['Acc'] == False)].shape[0],\n",
    "                \"accepted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].shape[0])/ Accepted.shape[0],\n",
    "                \"overlap_adjusted_accuracy\":(Accepted.loc[(Accepted['Acc'] == True)].count()[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] >E_threshold)].count()[0],\n",
    "                \"M(T) B(F)\":Accepted.loc[(Accepted[\"overlap\"] == 1)].count().iloc[0],\n",
    "                \"M(F) B(T)\":Accepted.loc[(Accepted[\"overlap\"] ==-1)].count().iloc[0],\n",
    "                \"M(F) B(F) overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "#         print(\"TT\",Accepted.loc[(Accepted[\"Acc\"] ==True) & (Accepted[\"overlap\"] == 0)])\n",
    "#         print(\"TF\",Accepted.loc[(Accepted[\"overlap\"] == 1)])\n",
    "#         print(\"FT\",Accepted.loc[(Accepted[\"overlap\"] == -1)])\n",
    "#         print(\"FF\",Accepted.loc[(Accepted[\"Acc\"] ==False) & (Accepted[\"overlap\"] == 0)])\n",
    "        axs[round(int(i/2)), round(i%2)]\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[round(int(i/2)), round(i%2)].suptitle('Horizontally stacked subplots')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "        axs[round(int(i/2)), round(i%2)].scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "        axs[round(int(i/2)), round(i%2)].plot(np.repeat(E_threshold,11),'b--')\n",
    "        axs[round(int(i/2)), round(i%2)].title.set_text(output_names[i])\n",
    "    \n",
    "    for ax in fig.axes:\n",
    "            # ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "            axLine, axLabel = ax.get_legend_handles_labels()\n",
    "            lines=(axLine)\n",
    "            labels=(axLabel)\n",
    "    fig.text(0.5, 0.01, 'Items Exit at Branch', ha='center', va='center')\n",
    "    fig.text(0.01, 0.5, 'Accuracy %', ha='center', va='center', rotation='vertical')\n",
    "    # fig.legend(lines, labels,bbox_to_anchor=(1., 1), loc=2,borderaxespad=0.,frameon=True)\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=64\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "def augment_images(image, label,input_size=(224,224), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "# test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=batch_size, drop_remainder=True))\n",
    "\n",
    "validation_size = 5000\n",
    "validation_images, validation_labels = train_images[:validation_size], train_labels[:validation_size] #get the first 5k training samples as validation set\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "validation_ds_size = len(list(validation_ds))\n",
    "validation_ds = (validation_ds.map(augment_images))\n",
    "v_target = tf.data.Dataset.from_tensor_slices((validation_labels))\n",
    "validation_ds = tf.data.Dataset.zip((validation_ds,v_target))\n",
    "validation_ds = (validation_ds.batch(batch_size=1, drop_remainder=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 23s 135ms/step - loss: 0.1504 - accuracy: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15039660036563873, 0.9584335088729858]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 4\n",
      "[4.338977813720703, 2.2023322582244873, 1.0179318189620972, 0.7743613123893738, 0.34435170888900757, 0.9714285731315613, 0.7469387650489807, 0.8285714387893677, 0.922448992729187, 0.08814287185668945, 0.8796835541725159, 0.0017450168961659074, 0.0903993621468544, 0.8979098200798035, 0.006083896849304438, 0.4067836105823517, 4.039254188537598, 0.0285817738622427]\n",
      "[2.1640779972076416, 2.161137580871582, 1.1920872111659264e-07, 0.002938241232186556, 2.1457672119140625e-06, 1.0, 1.0, 1.0, 1.0, 0.05678410083055496, 0.5678409934043884, 0.0, 0.001008541090413928, 0.010085411369800568, 0.0, 0.45002251863479614, 4.500225067138672, 0.0]\n",
      "Doneiction: 4999 of 5000\n"
     ]
    }
   ],
   "source": [
    "validation_Outputs = collectEvidence_branches(model,validation_ds, evidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 4\n",
      "[2.1773431301116943, 2.161133289337158, 0.016127871349453926, 8.141670696204528e-05, 7.152555099310121e-07, 1.0, 1.0, 1.0, 1.0, 0.0011353364679962397, 0.01135336421430111, 0.0, 3.826653482974507e-05, 0.0003826653410214931, 0.0, 0.5278791785240173, 5.278791904449463, 0.0]\n",
      "[2.1611897945404053, 2.161137580871582, 3.325892976135947e-05, 3.3378573789377697e-06, 1.5854737284826115e-05, 1.0, 1.0, 1.0, 1.0, 0.1368730068206787, 1.368730068206787, 0.0, 0.31425192952156067, 3.142519235610962, 0.0, 0.477458655834198, 4.7745866775512695, 0.0]\n",
      "Doneiction: 9999 of 10000\n"
     ]
    }
   ],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# # print(y_train)\n",
    "# K= 10 # number of classes\n",
    "# test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "# shuffle_size = 22500\n",
    "# batch_size=1\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "# def augment_images(image, label,input_size=(224,224), channel_first = False):\n",
    "#             image = tf.image.resize(image,input_size)\n",
    "#             if channel_first:\n",
    "#                 image = tf.transpose(image, [2, 0, 1])\n",
    "#             return image, label\n",
    "# test_ds_size = len(list(test_ds))\n",
    "# test_ds = (test_ds.map(augment_images))\n",
    "# t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "# test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "# test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))\n",
    "# # Predictions = collectEvidence_branches(model,test_ds)\n",
    "# Outputs = collectEvidence_branches(model,test_ds, evidence=False)\n",
    "# # print(Outputs)\n",
    "test_Outputs = collectEvidence_branches(model,test_ds, evidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      label  evidence  Acc  overlap\n",
      "0         6  0.000277    1        0\n",
      "1         9  0.000014    1        0\n",
      "2         9  0.000002    1        0\n",
      "3         4  0.000176    1        0\n",
      "4         1  0.000949    1        0\n",
      "5         1  0.000053    1        0\n",
      "6         2  0.001873    1        0\n",
      "7         7  0.000016    1        0\n",
      "8         8  0.000054    1        0\n",
      "9         3  0.000024    1        0\n",
      "10        4  0.000021    1        0\n",
      "11        7  0.000215    1        0\n",
      "12        7  0.000030    1        0\n",
      "13        2  0.000037    1        0\n",
      "14        9  0.000158    1        0\n",
      "15        9  0.000414    1        0\n",
      "16        9  0.000016    1        0\n",
      "17        3  0.006838    1        0\n",
      "18        2  0.001318    1        0\n",
      "19        6  0.030568    1        0\n",
      "20        4  0.000002    1        0\n",
      "21        3  0.002419    1        0\n",
      "22        6  0.000023    1        0\n",
      "23        6  0.000011    1        0\n",
      "24        2  0.005362    1        0\n",
      "25        6  0.000102    1        0\n",
      "26        3  0.000514    1        0\n",
      "27        5  0.001435    1        0\n",
      "28        4  0.000020    1        0\n",
      "29        0  0.000048    1        0\n",
      "...     ...       ...  ...      ...\n",
      "4970      9  0.000096    1        0\n",
      "4971      2  0.000072    1        0\n",
      "4972      8  1.137955    0        0\n",
      "4973      4  1.034469    1        0\n",
      "4974      8  0.000497    1        0\n",
      "4975      8  0.000015    1        0\n",
      "4976      2  0.000081    1        0\n",
      "4977      1  0.001289    1        0\n",
      "4978      4  0.000145    1        0\n",
      "4979      8  0.000017    1        0\n",
      "4980      6  0.000023    1        0\n",
      "4981      7  0.022958    1        0\n",
      "4982      3  0.000337    1        0\n",
      "4983      1  0.000272    1        0\n",
      "4984      3  0.000032    1        0\n",
      "4985      4  0.000053    1        0\n",
      "4986      9  0.000095    1        0\n",
      "4987      4  0.022059    1        0\n",
      "4988      8  0.000223    1        0\n",
      "4989      4  0.000218    1        0\n",
      "4990      5  0.000110    1        0\n",
      "4991      0  0.000721    1        0\n",
      "4992      9  0.000130    1        0\n",
      "4993      1  0.000057    1        0\n",
      "4994      3  0.000214    1        0\n",
      "4995      8  0.000028    1        0\n",
      "4996      7  0.000717    1        0\n",
      "4997      5  0.905167    1        0\n",
      "4998      4  0.000029    1        0\n",
      "4999      6  0.000175    1        0\n",
      "\n",
      "[5000 rows x 4 columns],       label      evidence    Acc  overlap\n",
      "0         6  2.131075e-11   True        0\n",
      "1         9  1.609779e-23   True        0\n",
      "2         9  5.026363e-26   True        0\n",
      "3         4  6.685136e-25   True        0\n",
      "4         1  1.688640e-11   True        0\n",
      "5         1  5.528278e-04   True        0\n",
      "6         2  8.427449e-09   True        0\n",
      "7         7 -0.000000e+00   True        0\n",
      "8         8  6.597417e-22   True        0\n",
      "9         3  2.701237e-06   True        0\n",
      "10        4  2.283635e-21   True        0\n",
      "11        7  1.555853e-25   True        0\n",
      "12        7  2.950255e-20   True        0\n",
      "13        2  3.015398e-06   True        0\n",
      "14        9  1.318188e-13   True        0\n",
      "15        9  6.254992e-15   True        0\n",
      "16        9  2.530385e-16   True        0\n",
      "17        3  2.307578e-03   True        0\n",
      "18        2  1.661954e-05  False        1\n",
      "19        6  1.928747e-08   True        0\n",
      "20        4  4.698035e-08   True        0\n",
      "21        3  7.535545e-01   True        0\n",
      "22        6  3.086847e-14   True        0\n",
      "23        6  1.137336e-14   True        0\n",
      "24        2  2.359815e-02   True        0\n",
      "25        6  7.410923e-01   True        0\n",
      "26        3  1.047013e-10   True        0\n",
      "27        5  1.937166e-01  False        1\n",
      "28        4  1.413030e-04   True        0\n",
      "29        0  1.104543e-03  False        1\n",
      "...     ...           ...    ...      ...\n",
      "4970      9  4.328774e-03   True        0\n",
      "4971      2  2.413989e-13  False        1\n",
      "4972      8  1.003231e-01  False        0\n",
      "4973      4  3.908656e-02  False        1\n",
      "4974      8  5.545224e-19   True        0\n",
      "4975      8  6.099510e-23   True        0\n",
      "4976      2  5.721551e-02  False        1\n",
      "4977      1  5.622793e-03  False        1\n",
      "4978      4  1.150708e-10   True        0\n",
      "4979      8  1.502713e-26   True        0\n",
      "4980      6 -0.000000e+00   True        0\n",
      "4981      7  6.154853e-05  False        1\n",
      "4982      3  4.254979e-24   True        0\n",
      "4983      1  2.360114e-18   True        0\n",
      "4984      3  4.614501e-05  False        1\n",
      "4985      4  1.554703e-20   True        0\n",
      "4986      9  8.741271e-07   True        0\n",
      "4987      4  4.210882e-12  False        1\n",
      "4988      8  1.409217e-29   True        0\n",
      "4989      4  2.901096e-01  False        1\n",
      "4990      5  9.629391e-01  False        1\n",
      "4991      0  2.285036e-13  False        1\n",
      "4992      9  1.087657e-16   True        0\n",
      "4993      1  5.075947e-27   True        0\n",
      "4994      3  4.024445e-07  False        1\n",
      "4995      8  3.052058e-02  False        1\n",
      "4996      7  9.930781e-01  False        1\n",
      "4997      5  2.368657e-12  False        1\n",
      "4998      4  1.580822e-04   True        0\n",
      "4999      6  2.287027e-18   True        0\n",
      "\n",
      "[5000 rows x 4 columns],       label      evidence  Acc  overlap\n",
      "0         6  2.022537e-04    1        0\n",
      "1         9  9.866394e-21    1        0\n",
      "2         9  3.854149e-08    1        0\n",
      "3         4  5.147473e-14    1        0\n",
      "4         1  4.503473e-11    1        0\n",
      "5         1  2.022868e-01    1        0\n",
      "6         2  6.633025e-05    1        0\n",
      "7         7  1.553560e-09    0        1\n",
      "8         8  3.465974e-10    1        0\n",
      "9         3  2.442510e-10    1        0\n",
      "10        4  1.723245e-09    1        0\n",
      "11        7  1.490826e-02    0        1\n",
      "12        7  4.270623e-09    0        1\n",
      "13        2  4.209984e-05    1        0\n",
      "14        9  2.557243e-10    1        0\n",
      "15        9  2.124712e-16    1        0\n",
      "16        9  1.842110e-17    1        0\n",
      "17        3  9.795852e-03    1        0\n",
      "18        2  4.292966e-02    0        1\n",
      "19        6  1.144920e-02    0        1\n",
      "20        4  3.591862e-02    1        0\n",
      "21        3  1.246740e-05    1        0\n",
      "22        6  1.911732e-10    1        0\n",
      "23        6  3.737684e-11    1        0\n",
      "24        2  1.402946e-01    0        1\n",
      "25        6  1.892532e-05    0        1\n",
      "26        3  3.283404e-06    1        0\n",
      "27        5  1.356563e+00    1        0\n",
      "28        4  2.886953e-13    1        0\n",
      "29        0  9.168934e-01    1        0\n",
      "...     ...           ...  ...      ...\n",
      "4970      9  2.432923e-05    1        0\n",
      "4971      2  1.207018e+00    0        1\n",
      "4972      8  9.765444e-01    0        0\n",
      "4973      4  1.598655e-05    0        1\n",
      "4974      8  5.488323e-05    1        0\n",
      "4975      8  1.805727e-09    1        0\n",
      "4976      2  6.571510e-03    1        0\n",
      "4977      1  1.310767e+00    0        1\n",
      "4978      4  3.921660e-12    1        0\n",
      "4979      8  1.258456e-09    1        0\n",
      "4980      6  2.270489e-10    1        0\n",
      "4981      7  5.685111e-05    0        1\n",
      "4982      3  4.116664e-18    1        0\n",
      "4983      1  1.512657e-12    1        0\n",
      "4984      3  1.978940e-10    1        0\n",
      "4985      4  2.292529e-14    1        0\n",
      "4986      9  1.557253e-12    1        0\n",
      "4987      4  3.221575e-01    0        1\n",
      "4988      8  2.210334e-17    1        0\n",
      "4989      4  4.135559e-01    1        0\n",
      "4990      5  1.882231e-09    1        0\n",
      "4991      0  3.353433e-07    0        1\n",
      "4992      9  1.380497e-25    1        0\n",
      "4993      1  4.621464e-20    1        0\n",
      "4994      3  4.409548e-03    0        1\n",
      "4995      8  5.940216e-08    0        1\n",
      "4996      7  4.817659e-02    0        1\n",
      "4997      5  2.337333e-05    0        1\n",
      "4998      4  2.888289e-07    1        0\n",
      "4999      6  1.115984e-08    1        0\n",
      "\n",
      "[5000 rows x 4 columns],       label      evidence  Acc  overlap\n",
      "0         6  1.480305e-04    1        0\n",
      "1         9  4.045282e-13    1        0\n",
      "2         9  1.533427e-12    1        0\n",
      "3         4  4.285401e-10    1        0\n",
      "4         1  9.710948e-10    1        0\n",
      "5         1  4.620927e-08    1        0\n",
      "6         2  1.258044e-06    1        0\n",
      "7         7  1.292840e-10    1        0\n",
      "8         8  4.031556e-10    1        0\n",
      "9         3  4.755521e-08    1        0\n",
      "10        4  2.260050e-10    1        0\n",
      "11        7  1.167807e-09    1        0\n",
      "12        7  6.646525e-10    1        0\n",
      "13        2  1.119600e-03    1        0\n",
      "14        9  9.073574e-09    1        0\n",
      "15        9  1.103587e-09    1        0\n",
      "16        9  4.064506e-09    1        0\n",
      "17        3  7.172037e-02    0        1\n",
      "18        2  2.296417e-10    1        0\n",
      "19        6  5.063486e-05    1        0\n",
      "20        4  5.834403e-14    1        0\n",
      "21        3  6.140271e-02    0        1\n",
      "22        6  3.726919e-11    1        0\n",
      "23        6  2.347801e-08    1        0\n",
      "24        2  6.501600e-16    1        0\n",
      "25        6  6.272205e-01    0        1\n",
      "26        3  4.723152e-09    1        0\n",
      "27        5  6.604376e-07    1        0\n",
      "28        4  3.875638e-10    1        0\n",
      "29        0  3.321381e-05    1        0\n",
      "...     ...           ...  ...      ...\n",
      "4970      9  6.437675e-08    1        0\n",
      "4971      2  1.242008e-02    1        0\n",
      "4972      8  2.038309e-01    0        0\n",
      "4973      4  9.620020e-01    0        1\n",
      "4974      8  6.432179e-05    1        0\n",
      "4975      8  2.960676e-14    1        0\n",
      "4976      2  3.953586e-07    1        0\n",
      "4977      1  1.331842e-08    1        0\n",
      "4978      4  4.588809e-05    1        0\n",
      "4979      8  3.640427e-17    1        0\n",
      "4980      6  1.909745e-05    1        0\n",
      "4981      7  2.063422e-03    1        0\n",
      "4982      3  2.324741e-04    1        0\n",
      "4983      1  9.456980e-07    1        0\n",
      "4984      3  2.474643e-01    1        0\n",
      "4985      4  2.809829e-07    1        0\n",
      "4986      9  3.467140e-07    1        0\n",
      "4987      4  4.021651e-01    0        1\n",
      "4988      8  3.515917e-21    1        0\n",
      "4989      4  7.327926e-16    1        0\n",
      "4990      5  2.848125e-12    1        0\n",
      "4991      0  2.985673e-07    1        0\n",
      "4992      9  1.352494e-12    1        0\n",
      "4993      1  9.867649e-13    1        0\n",
      "4994      3  7.509147e-08    1        0\n",
      "4995      8  6.286257e-08    1        0\n",
      "4996      7  2.376782e-09    1        0\n",
      "4997      5  1.224351e-01    1        0\n",
      "4998      4  2.242271e-06    1        0\n",
      "4999      6  1.422943e-12    1        0\n",
      "\n",
      "[5000 rows x 4 columns]]\n"
     ]
    }
   ],
   "source": [
    "print(validation_Outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.007409457870596763  std 0.038176381962990176\n",
      "rollover enabled, 3952 predictions provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.004870160663709058  std 0.035349414170499194\n",
      "rollover enabled, 3279 predictions provided\n",
      "mean 0.016847474446909944  std 0.04632826841796389\n",
      "rollover enabled, 1084 predictions provided\n",
      "mean 0  std 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:311: RuntimeWarning: divide by zero encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch Name</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>E_Threshold</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>accepted_correct</th>\n",
       "      <th>accepted_incorrect</th>\n",
       "      <th>accepted_accuracy</th>\n",
       "      <th>overlap_adjusted_accuracy</th>\n",
       "      <th>M(T) B(F)</th>\n",
       "      <th>M(F) B(T)</th>\n",
       "      <th>M(F) B(F) overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>branch_1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.762600</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>1008</td>\n",
       "      <td>40</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>0.961832</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>branch_2</td>\n",
       "      <td>3952</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.778593</td>\n",
       "      <td>0.040220</td>\n",
       "      <td>0.170294</td>\n",
       "      <td>650</td>\n",
       "      <td>23</td>\n",
       "      <td>0.965825</td>\n",
       "      <td>0.967311</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>branch_3</td>\n",
       "      <td>3279</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>0.936566</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.669411</td>\n",
       "      <td>2181</td>\n",
       "      <td>14</td>\n",
       "      <td>0.993622</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Main_Exit</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>0.962177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1043</td>\n",
       "      <td>41</td>\n",
       "      <td>0.962177</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Branch Name  Predictions  test_accuracy  Accuracy  E_Threshold  \\\n",
       "0    branch_1         5000         0.7626  0.762600     0.045586   \n",
       "1    branch_2         3952         0.8154  0.778593     0.040220   \n",
       "2    branch_3         3279         0.9558  0.936566     0.063176   \n",
       "3   Main_Exit         1084         0.9910  0.962177     0.000000   \n",
       "\n",
       "   acceptance_rate  accepted_correct  accepted_incorrect  accepted_accuracy  \\\n",
       "0         0.209600              1008                  40           0.961832   \n",
       "1         0.170294               650                  23           0.965825   \n",
       "2         0.669411              2181                  14           0.993622   \n",
       "3         1.000000              1043                  41           0.962177   \n",
       "\n",
       "   overlap_adjusted_accuracy  M(T) B(F)  M(F) B(T)  M(F) B(F) overlap  \n",
       "0                   0.961832         40          0                  0  \n",
       "1                   0.967311         22          0                  1  \n",
       "2                   0.994989         11          0                  3  \n",
       "3                        inf          0          0                 41  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayEvidence_cascade(validation_Outputs, Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.0071180407012081896  std 0.0417395117312799\n",
      "rollover enabled, 7843 predictions provided\n",
      "mean 0.003780258221507589  std 0.02761419295949236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:263: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollover enabled, 6577 predictions provided\n",
      "mean 0.022312147958141224  std 0.06906060695298791\n",
      "rollover enabled, 2323 predictions provided\n",
      "mean 0  std 0.0\n",
      "threshold not supplied for branch 3, using test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:311: RuntimeWarning: divide by zero encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Branch Name</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>E_Threshold</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>accepted_correct</th>\n",
       "      <th>accepted_incorrect</th>\n",
       "      <th>accepted_accuracy</th>\n",
       "      <th>overlap_adjusted_accuracy</th>\n",
       "      <th>M(T) B(F)</th>\n",
       "      <th>M(F) B(T)</th>\n",
       "      <th>M(F) B(F) overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>branch_1</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.7556</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>0.045586</td>\n",
       "      <td>0.215700</td>\n",
       "      <td>2076</td>\n",
       "      <td>81</td>\n",
       "      <td>0.962448</td>\n",
       "      <td>0.968011</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>branch_2</td>\n",
       "      <td>7843</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>0.771388</td>\n",
       "      <td>0.040220</td>\n",
       "      <td>0.161418</td>\n",
       "      <td>1224</td>\n",
       "      <td>42</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.973934</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>branch_3</td>\n",
       "      <td>6577</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.922001</td>\n",
       "      <td>0.063176</td>\n",
       "      <td>0.646799</td>\n",
       "      <td>4199</td>\n",
       "      <td>55</td>\n",
       "      <td>0.987071</td>\n",
       "      <td>0.993888</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Main_Exit</td>\n",
       "      <td>2323</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.879036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2042</td>\n",
       "      <td>281</td>\n",
       "      <td>0.879036</td>\n",
       "      <td>inf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Branch Name  Predictions  test_accuracy  Accuracy  E_Threshold  \\\n",
       "0    branch_1        10000         0.7556  0.755600     0.045586   \n",
       "1    branch_2         7843         0.8119  0.771388     0.040220   \n",
       "2    branch_3         6577         0.9432  0.922001     0.063176   \n",
       "3   Main_Exit         2323         0.9643  0.879036     0.000000   \n",
       "\n",
       "   acceptance_rate  accepted_correct  accepted_incorrect  accepted_accuracy  \\\n",
       "0         0.215700              2076                  81           0.962448   \n",
       "1         0.161418              1224                  42           0.966825   \n",
       "2         0.646799              4199                  55           0.987071   \n",
       "3         1.000000              2042                 281           0.879036   \n",
       "\n",
       "   overlap_adjusted_accuracy  M(T) B(F)  M(F) B(T)  M(F) B(F) overlap  \n",
       "0                   0.968011         69          9                 12  \n",
       "1                   0.973934         33          6                  9  \n",
       "2                   0.993888         26         11                 29  \n",
       "3                        inf          0          0                281  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayEvidence_cascade(test_Outputs, thresholds=[0.045586,0.040220,0.063176],  Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     overlap\n",
    "        if zero, both match, if else they don't match\n",
    "        TT 1-1 =0\n",
    "        TF 1-0 =1\n",
    "\n",
    "        FT 0-1 = -1\n",
    "        FF 0-0 =0\n",
    "        \n",
    "        '''\n",
    "# print(Outputs[1])\n",
    "displayEvidence(Outputs, Evidence = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10 v2\n",
    "# print(Outputs[0])\n",
    "\n",
    "displayEvidence(Outputs, Evidence = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid evidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 227,227 sigmoid cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 32,32 crossEvidence cifar10\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "displayEvidence(Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.load_model('alexNetv6_evidence_test.hdf5',\n",
    "    custom_objects={\"CrossEntropyEndpoint\":CrossEntropyEndpoint,\"crossEntropy_loss\":loss_function()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_2 = collectEvidence(model_2,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectEntropy(model,test_ds):\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "#     train_ds, test_ds, validation_ds = (dataset)\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    iterator = iter(test_ds)\n",
    "    print(len(test_ds))\n",
    "    item = iterator.get_next()\n",
    "#     print(item)\n",
    "\n",
    "    pClass = []\n",
    "    predictions=[]\n",
    "    pEvidence = []\n",
    "    pUncertainty=[]\n",
    "    Outputs = pd.DataFrame()\n",
    "    output_names=[\"mainExit\"]\n",
    "    pAcc=[]\n",
    "    for i, (x,y) in enumerate(test_ds):\n",
    "#     for i in range(100):\n",
    "        print(\"prediction: {} of {}\".format(i,len(test_ds)),end='\\r')\n",
    "        result = model.predict(x)\n",
    "        pClass.append(tf.argmax(y,1).numpy()[0])\n",
    "        pred= (tf.nn.softmax(result)[0])\n",
    "\n",
    "        pEvidence.append(calcEntropy_Tensors(pred).numpy())\n",
    "        if np.argmax(pred) == np.argmax(y):\n",
    "            pAcc.append(1)       \n",
    "        else:\n",
    "            pAcc.append(0)\n",
    "    Predictions = pd.DataFrame({\"label\":pClass,\"evidence\":pEvidence,\"Acc\":pAcc,\"overlap\":0})\n",
    "    return Predictions\n",
    "\n",
    "def displayEntropy(Predictions):\n",
    "    output_names=[\"mainExit\"]\n",
    "    Outputs=pd.DataFrame()\n",
    "    Predictions[\"Acc\"]=Predictions[\"Acc\"].astype('bool')\n",
    "    acc = Predictions[\"Acc\"].value_counts()\n",
    "    print(acc)\n",
    "    print((acc.loc[True] , acc.loc[False]))\n",
    "    mean = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].mean().iloc[0]\n",
    "    std = Predictions.loc[(Predictions['Acc'] == False)].groupby(\"Acc\")[\"evidence\"].std().iloc[0]\n",
    "    E_threshold = mean - std\n",
    "    correct_rows = Predictions.loc[Predictions['Acc'] == True]\n",
    "    incorrect_rows = Predictions.loc[Predictions['Acc'] == False]\n",
    "    # Incorrects_overlap = Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold) & (Predictions[\"overlap\"] == 0)].count().iloc[0]\n",
    "    print(acc)\n",
    "    for i,name in enumerate(output_names):\n",
    "        Outputs = Outputs.append(pd.DataFrame({\"Branch Name\":output_names[i],\n",
    "                \"Accuracy\":(acc.loc[True] /  (acc.loc[True] + acc.loc[False])),\n",
    "                \"E_Threshold\":E_threshold,\n",
    "                # \"Overlap_Threshold\":non_overlapping_incorrects_threshold,\n",
    "                \"acceptance_rate\":Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0]/(Predictions.count().iloc[0]),\n",
    "                \"accepted_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"accepted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] < E_threshold)].sort_values(\"evidence\").shape[0])/ Predictions.loc[(Predictions[\"evidence\"] < E_threshold)].count()[0],\n",
    "                # \"overlap_adjusted_accuracy\":(Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0] + Incorrects_overlap) / Predictions.loc[(Predictions[\"evidence\"] > E_threshold)].count()[0],\n",
    "                \"rejected_correct\":Predictions.loc[(Predictions['Acc'] == True)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                \"rejected_incorrect\":Predictions.loc[(Predictions['Acc'] == False)  & (Predictions[\"evidence\"] > E_threshold)].sort_values(\"evidence\").shape[0],\n",
    "                # \"Incorrects_overlap\":Incorrects_overlap,\n",
    "                },index=[i]))\n",
    "\n",
    "    # fig, axs = plt.subplots(1, 2)\n",
    "    plt.suptitle('Horizontally stacked subplots')\n",
    "    plt.scatter(correct_rows['label'],correct_rows['evidence'],c ='r',marker='+')\n",
    "    plt.scatter(incorrect_rows['label']+.3,incorrect_rows['evidence'],c ='k',marker='x')\n",
    "    plt.plot(np.repeat(E_threshold,11),'b--')\n",
    "    plt.title(\"evidence\")\n",
    "\n",
    "\n",
    "    # fig.set_size_inches(10, 10)\n",
    "    plt.show()\n",
    "    return Outputs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy_predictions = collectEntropy(model_2,test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEntropy(Entropy_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "test_images = test_images.reshape(10000, 32,32,3).astype(\"float32\") / 255\n",
    "\n",
    "# print(y_train)\n",
    "K= 10 # number of classes\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "shuffle_size = 22500\n",
    "batch_size=1\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "\n",
    "def augment_images(image, label,input_size=(227,227), channel_first = False):\n",
    "            image = tf.image.resize(image,input_size)\n",
    "            if channel_first:\n",
    "                image = tf.transpose(image, [2, 0, 1])\n",
    "            return image, label\n",
    "test_ds_size = len(list(test_ds))\n",
    "# test_ds = (test_ds.map(augment_images))\n",
    "t_target = tf.data.Dataset.from_tensor_slices((test_labels))\n",
    "test_ds = tf.data.Dataset.zip((test_ds,t_target))\n",
    "test_ds = (test_ds.batch(batch_size=1, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_mse = collectEvidence(model,test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayEvidence(Predictions_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sum entropy \n",
    "import pandas as pd\n",
    "def entropy(x):\n",
    "    return -(x * math.log(x))\n",
    "# Data for plotting\n",
    "t = np.arange(0.00001, 1, 0.01)\n",
    "print(t.shape)\n",
    "t_ = np.full((100,), .1)\n",
    "df = pd.DataFrame([t,t,t_,t,t])\n",
    "# print(df.transpose())\n",
    "p = df.apply(calcEntropy,axis=0)\n",
    "# print(p)\n",
    "# print(p)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, p)\n",
    "ax.set(xlabel='Probability of Outcome',ylabel='Entropy of event')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0,1,0,0,0,0]\n",
    "y_pred = [.99,.01, .01, .0, .01, .01]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.CategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0]\n",
    "y_pred = [.0,.01, .9, .0, .0, .0]\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = ent *1\n",
    "print(\"Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "y_pred = [[.9,.0,.0,.0,.0,.0,],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "# y_pred = [.1,.1, .1, .1, .1, .1]\n",
    "# Using 'auto'/'sum_over_batch_size' reduction type.  \n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossE: \",crossE)\n",
    "\n",
    "''' When the answer is correct, CrossE goes down\n",
    "    When \n",
    "    When its wrong, Entropy High\n",
    "    When its right, Entropy Low\n",
    "    \n",
    "    so penalize being right with low entropy and reward being right with high entropy\n",
    "    \n",
    "    \n",
    "    OORRRR train a second model for a branch to determine if you are going to get it right or not?\n",
    "    Isn't that what ResNet Did? you calculate if the blocks will contribute, was it block drop?\n",
    "    Binary classification,\n",
    "    could be done at the branch end as a separate evaulator, using the entropy score and the input to the branch as inputs?\n",
    "'''\n",
    "\n",
    "\n",
    "ent = calcEntropy(y_pred)\n",
    "print(\"Entropy: \",ent)\n",
    "loss = crossE + ent\n",
    "print(\"combined Loss: \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5]]\n",
    "x = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "print(list(map(np.argmax,np.array(x))))\n",
    "def foo(y_pred):\n",
    "    y_pred = y_pred.numpy()\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    return pred_label\n",
    "%timeit foo(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.constant([[2],[2],[0]])\n",
    "A = tf.constant([.1,.1, .675, .1091, .4311, .1875,.121,.143,.2,.5])\n",
    "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "\n",
    "y_pred = tf.constant([[.9,.5, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]])\n",
    "\n",
    "# new_list = new_list = [list(range(10)) for _ in range(10)]\n",
    "\n",
    "print(tf.math.argmax(y_pred,1))\n",
    "pred_labels = tf.math.argmax(y_pred,1)\n",
    "print(tf.reshape(y_true,pred_labels.shape))\n",
    "indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "indexes = tf.reshape(indexes,[-1])\n",
    "# print(tf.gather(B,indexes))\n",
    "CorrectE = tf.gather(y_pred,indexes)\n",
    "print(CorrectE)\n",
    "# print(calcEntropy(CorrectE[0]))\n",
    "\n",
    "\n",
    "results = tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "print(\"results: \",results)\n",
    "\n",
    "\n",
    "\n",
    "%timeit tf.map_fn(calcEntropy,tf.cast(CorrectE,'float'))\n",
    "\n",
    "\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE(y_true,y_pred)\n",
    "%timeit crossE(y_true,y_pred)\n",
    "# [\n",
    "#     [\n",
    "#         [ 2 20 30  3  6]\n",
    "#     ]\n",
    "#     [\n",
    "#         [ 3 11 16  1  8]\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "def entropyAddition_noCross(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[0,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyAddition(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 0\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = scce + (correctEntropies * scce)\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true ,y_pred))\n",
    "\n",
    "print(\"normal Entropy\",entropyAddition_noCross(y_true2,y_pred2))\n",
    "\n",
    "print(entropyAddition(y_true2, y_pred2))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([1])\n",
    "y_pred = tf.constant([0,1, 0, 0, 0, 0])\n",
    "# print(crossE(y_true,y_pred))\n",
    "\n",
    "print(tf.cast(1e-8,'float')+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[0]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "def entropyMultiplication(y_true, y_pred):\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    #Entropy is added to the CrossE divided by the len of inputs\n",
    "    pred_labels = tf.math.argmax(y_pred,1)\n",
    "    indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "    indexes = tf.reshape(indexes,[-1])\n",
    "    entropies = tf.gather(y_pred,indexes)\n",
    "    if tf.equal(tf.size(entropies), 0):\n",
    "        correctEntropies = 1\n",
    "    else:\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy_Tensors,tf.cast(entropies,'float')))\n",
    "    scce = crossE(y_true, y_pred)\n",
    "    loss = correctEntropies * scce\n",
    "    return loss\n",
    "\n",
    "\n",
    "print(\"normal CrossE: \",crossE(y_true,y_pred))\n",
    "print(entropyAddition(y_true, y_pred))\n",
    "# %timeit entropyAddition(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = tf.constant([[1],[2],[1]])\n",
    "y_pred = tf.constant([[.9,.1, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.9,.3, .3, .2, .1, .32]])\n",
    "\n",
    "def confidenceScore(y_true, y_pred):\n",
    "        # print(y_pred)\n",
    "        # print(tf.keras.backend.get_value(y_pred))\n",
    "        \n",
    "        # y_true =y_true.numpy()\n",
    "        # y_pred = y_pred.numpy()\n",
    "        # AvgConfidence = -1\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        # countCorrect=0\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        if tf.equal(tf.size(entropies), 0):\n",
    "            correctEntropies = 0\n",
    "        else:\n",
    "            correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))    \n",
    "        \n",
    "        return correctEntropies\n",
    "    \n",
    "print(confidenceScore(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.9,0, .6, .5, .5, .5],[.8,.5, .6, .5, .5, .5],[.7,.5, .6, .5, .5, .5]]\n",
    "\n",
    "def foo(x, y):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    crossE = scce(x, y).numpy()\n",
    "    return crossE\n",
    "\n",
    "print(foo(y_true,y_pred))\n",
    "%timeit foo(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python program explaining \n",
    "# where() function \n",
    "  \n",
    "import numpy as np\n",
    "  \n",
    "# a is an array of integers.\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "  \n",
    "print(a)\n",
    "  \n",
    "print ('Indices of elements <4')\n",
    "  \n",
    "b = np.where(a<5)\n",
    "print(b)\n",
    "  \n",
    "print(\"Elements which are <4\")\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[0],[0],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .1],[.5,.5, .6, .5, .5, .2],[.5,.5, .6, .5, .5, .3]]\n",
    "# y_pred = [[1],[1],[1]]\n",
    "# print(np.array(y_pred))\n",
    "\n",
    "####\n",
    "# Numpy confidence metric version\n",
    "y_true =np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "def argmax(x):\n",
    "    return [np.argmax(x)]\n",
    "pred_labels = list(map(argmax,np.array(y_pred)))\n",
    "x = np.where(np.equal(y_true,pred_labels) ==True)\n",
    "y = y_pred[x[0]]\n",
    "results = calcEntropy(y)\n",
    "print(results)\n",
    "if not (results):\n",
    "    print(\"A\")\n",
    "print(np.median(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[2],[2],[0]]\n",
    "y_pred = [[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5],[.5,.5, .6, .5, .5, .5]]\n",
    "\n",
    "y_true = [[2]]\n",
    "y_pred = [[.1,.1, .15, .1, .1, .1]]\n",
    "def entropyAddition_loss():\n",
    "    #create a wrapper function that returns a function\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    def entropyAddition(y_true, y_pred):\n",
    "        #Entropy is added to the CrossE divided by the len of inputs\n",
    "        pred_labels = tf.math.argmax(y_pred,1)\n",
    "        indexes = tf.where(tf.math.equal(pred_labels, tf.cast(tf.reshape(y_true,pred_labels.shape),'int64')))\n",
    "        indexes = tf.reshape(indexes,[-1])\n",
    "        entropies = tf.gather(y_pred,indexes)\n",
    "        correctEntropies = tf.reduce_mean(tf.map_fn(calcEntropy,tf.cast(entropies,'float')))\n",
    "#         print(pred_label)\n",
    "        scce = crossE(y_true, y_pred)\n",
    "        sumEntropy = 0\n",
    "        loss = correctEntropies + scce\n",
    "        return loss\n",
    "    \n",
    "    return entropyAddition\n",
    "\n",
    "def custom_loss_multi(y_true, y_pred):\n",
    "    #CrossE is multiplied by the Entropy\n",
    "    pred_label = list(map(np.argmax,np.array(y_pred)))\n",
    "    crossE = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    sumLoss = 0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        loss = crossE(y_true[i], y_pred[i])\n",
    "#         print('crossE: ',loss)\n",
    "        if pred_label[i] == y_true[i]:\n",
    "#             print('calcEntropy ',calcEntropy(y_pred[i]))\n",
    "            loss = loss * calcEntropy(y_pred[i])\n",
    "        sumLoss += loss\n",
    "    sumLoss = sumLoss / len(y_pred)         \n",
    "    \n",
    "#     loss = crossE(y_true, y_pred)\n",
    "#     print(\"CrossE : \",loss.numpy())\n",
    "#     print(\"Loss : \",sumLoss)\n",
    "    return sumLoss\n",
    "    ### I want to reduce the entropy of correct answers\n",
    "    ### if label - pred = 0 (aka correct) then add entropy to crossE\n",
    "    \n",
    "    \n",
    "#     squared_difference = tf.square(np.array(y_true) - np.array(y_pred))\n",
    "#     return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "crossE = scce(y_true, y_pred).numpy()\n",
    "print(\"crossEntropyLoss: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_addition(y_true, y_pred).numpy()\n",
    "print(\"customLoss_addition: \",crossE)\n",
    "\n",
    "\n",
    "crossE = custom_loss_multi(y_true, y_pred).numpy()\n",
    "print(\"customLoss_multi: \",crossE)\n",
    "\n",
    "  \n",
    "# model.compile(loss=custom_loss, optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x - y == 0:\n",
    "        return 1\n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sub(x,y):\n",
    "    if x == y:\n",
    "        return 0\n",
    "    \n",
    "%timeit sub(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7483e188a462fd4248cd8d23b24bc727a5fe7a35e4044aa57ebcc92f8fe9e445"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
