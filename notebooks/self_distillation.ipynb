{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Distillation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "import branching\n",
    "\n",
    "from branching import branches\n",
    "from branching import evaluate\n",
    "\n",
    "# branching.enable_neptune(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, validation_ds = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,shuffle_size=15000,input_size=(32,32),include_targets=False,num_outputs = 10,reshuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Branch Model. this is a subclass of the standard Keras model and can do all the normal things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchModel(tf.keras.Model):\n",
    "    '''\n",
    "    Branched model sub-class. \n",
    "    Acts as a drop in replacement keras model class, with the additional functionality of adding branches to the model.\n",
    "            \n",
    "    '''\n",
    "    def __init__(self, inputs=None, outputs=None, name=\"\", model=None, transfer=True,custom_objects={}):\n",
    "        ## add default custom objects to the custom objects dictionary, this saves having to define them everytime.\n",
    "        custom_objects = {**branching.default_custom_objects,**custom_objects} \n",
    "        if inputs  is None and model is None and name is not \"\":\n",
    "            model = tf.keras.models.load_model(name,custom_objects=custom_objects)\n",
    "            self.saveLocation = name\n",
    "            super(BranchModel, self).__init__(inputs = model.inputs, outputs=model.outputs,name=model.name)            \n",
    "        elif model is None:\n",
    "            super(BranchModel, self).__init__(inputs = inputs, outputs=outputs,name=name)\n",
    "        elif model is not None:\n",
    "            super(BranchModel, self).__init__(inputs = model.inputs, outputs=model.outputs,name=name)\n",
    "        self.transfer = transfer\n",
    "        self.custom_objects = custom_objects\n",
    "        ##remap the depths of the layers to match the desired layout for branching\n",
    "        # self._map_graph_network(self.inputs,self.outputs, True)\n",
    "        self.branch_active = False\n",
    "   \n",
    "    def _run_internal_graph(self, inputs, training=None, mask=None):\n",
    "        \"\"\"custom version of _run_internal_graph\n",
    "            used to allow for interuption of the graph by an internal layer if conditions are met.\n",
    "        Computes output tensors for new inputs.\n",
    "        Args:\n",
    "            inputs: Tensor or nested structure of Tensors.\n",
    "            training: Boolean learning phase.\n",
    "            mask: (Optional) Tensor or nested structure of Tensors.\n",
    "\n",
    "        Returns:\n",
    "            output_tensors\n",
    "        \"\"\"\n",
    "        inputs = self._flatten_to_reference_inputs(inputs)\n",
    "        if mask is None:\n",
    "            masks = [None] * len(inputs)\n",
    "        else:\n",
    "            masks = self._flatten_to_reference_inputs(mask)\n",
    "        for input_t, mask in zip(inputs, masks):\n",
    "            input_t._keras_mask = mask\n",
    "\n",
    "        # Dictionary mapping reference tensors to computed tensors.\n",
    "        tensor_dict = {}\n",
    "        tensor_usage_count = self._tensor_usage_count\n",
    "        for x, y in zip(self.inputs, inputs):\n",
    "            y = self._conform_to_reference_input(y, ref_input=x)\n",
    "            x_id = str(id(x))\n",
    "            tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n",
    "\n",
    "        nodes_by_depth = self._nodes_by_depth\n",
    "        depth_keys = list(nodes_by_depth.keys())\n",
    "        depth_keys.sort(reverse=True)\n",
    "    \n",
    "        for depth in depth_keys:\n",
    "            nodes = nodes_by_depth[depth]\n",
    "            for node in nodes:\n",
    "                # print(node.layer.name)\n",
    "                if node.is_input:\n",
    "                    continue  # Input tensors already exist.\n",
    "\n",
    "                if any(t_id not in tensor_dict for t_id in node.flat_input_ids):\n",
    "                    continue  # Node is not computable, try skipping.\n",
    "\n",
    "                args, kwargs = node.map_arguments(tensor_dict)\n",
    "                outputs = node.layer(*args, **kwargs)\n",
    "                # Update tensor_dict.\n",
    "                for x_id, y in zip(node.flat_output_ids, nest.flatten(outputs)):\n",
    "                    tensor_dict[x_id] = [y] * tensor_usage_count[x_id]\n",
    "                \n",
    "                ## check if branch exiting is turned on and if current layer is a potential exit.\n",
    "                # print(node.layer.name, hasattr(node.layer, 'branch_exit'))\n",
    "                if not training:\n",
    "                    if self.branch_active == True and hasattr(node.layer, 'branch_exit'):  \n",
    "                        ## check if the confidence of output of the layer is equal to or above the threshold hyperparameter\n",
    "                        # print(\"threshold: \", node.layer.threshold, \"evidence: \", tf.reduce_sum(node.layer.evidence(outputs)))\n",
    "                        if node.layer.branch_exit and (tf.reduce_sum(node.layer.evidence(outputs)) >= node.layer.confidence_threshold): ##check if current layer's exit is active\n",
    "                            # print(\"branch exit activated\")\n",
    "                            output_tensors = []\n",
    "                            for x_id, y in zip(node.flat_output_ids, nest.flatten(outputs)):\n",
    "                                for x in self.outputs:\n",
    "                                    output_id = str(id(x))  \n",
    "                                    if output_id == x_id:\n",
    "                                        output_tensors.append(tensor_dict[x_id])\n",
    "                                    else:\n",
    "                                        # print(tensor_dict[x_id][0].shape)\n",
    "                                        output_tensors.append(tf.zeros(tensor_dict[x_id][0].shape))\n",
    "                                    # x_id_output = str(id(x))\n",
    "                                    # assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n",
    "                                    # output_tensors.append(tensor_dict[x_id])\n",
    "\n",
    "                            return nest.pack_sequence_as(self._nested_outputs, output_tensors)\n",
    "        output_tensors = []\n",
    "        for x in self.outputs:\n",
    "            x_id = str(id(x))\n",
    "            assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n",
    "            output_tensors.append(tensor_dict[x_id].pop())\n",
    "\n",
    "        return nest.pack_sequence_as(self._nested_outputs, output_tensors)\n",
    "\n",
    "    def add_branches(self,branchName, branchPoints=[], exact = True, target_input = False, compact = False, loop=True,num_outputs=10):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        # [\"max_pooling2d\",\"max_pooling2d_1\",\"dense\"]\n",
    "        # branch.newBranch_flatten\n",
    "        if loop:\n",
    "            newModel = branch.add_loop(self,branchName, branchPoints,exact=exact, target_input = target_input, compact = compact,num_outputs=num_outputs)\n",
    "        else:\n",
    "            newModel = branch.add(self,branchName,branchPoints, exact=exact, target_input = target_input, compact = compact,num_outputs=num_outputs)\n",
    "        print(\"branch added\", newModel)\n",
    "        self.__dict__.update(newModel.__dict__)\n",
    "\n",
    "        return self\n",
    "\n",
    "#     def compile(self, loss, optimizer, metrics=['accuracy'], run_eagerly=True, preset=\"\",**kwargs):\n",
    "#         ''' compile the model with custom options, either ones provided here or ones already set'''\n",
    "\n",
    "#         # if preset == \"\":\n",
    "#             # preset = self.customOptions\n",
    "#         print(preset)\n",
    "#         if preset == \"customLoss\": \n",
    "#             print(\"preset: customLoss\")\n",
    "#             loss_fn = evidence_crossentropy()\n",
    "#             super().compile(loss=loss_fn, optimizer=tf.optimizers.SGD(learning_rate=0.001,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "#         elif preset == \"customLoss_onehot\": \n",
    "#             print(\"preset: CrossE_onehot\")\n",
    "#             super().compile( loss={\"dense_2\":keras.losses.CategoricalCrossentropy(from_logits=True)}, optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "\n",
    "#         elif preset == \"CrossE\": \n",
    "#             print(\"preset: CrossE\")\n",
    "#             super().compile( loss =tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9), metrics=['accuracy'],run_eagerly=True,**kwargs)\n",
    "\n",
    "#         elif preset == \"CrossE_Eadd\":\n",
    "#             print(\"preset: CrossE_Eadd\")\n",
    "#             entropyAdd = entropyAddition_loss()\n",
    "#             super().compile( optimizer=tf.optimizers.SGD(learning_rate=0.01,momentum=0.9,clipvalue=0.5), loss=[keras.losses.SparseCategoricalCrossentropy(),entropyAdd,entropyAdd,entropyAdd], metrics=['accuracy',confidenceScore, unconfidence],run_eagerly=True,**kwargs)\n",
    "#             # model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.001), loss=[crossE_test, entropyAdd, entropyAdd, entropyAdd], metrics=['accuracy',confidenceScore, unconfidence],run_eagerly=True)\n",
    "#         else:\n",
    "#             print(\"preset: Other\")\n",
    "#         # model.compile(loss=entropyAddition, optimizer=tf.optimizers.SGD(learning_rate=0.001), metrics=['accuracy'],run_eagerly=True)\n",
    "#             super().compile(loss=loss, optimizer=optimizer, metrics=['accuracy'], **kwargs)\n",
    "\n",
    "    def setTrainable(self,trainable):\n",
    "        \"\"\" sets the trainable status of all main path layers in the model\"\"\"\n",
    "        if trainable == True: \n",
    "            print(\"Freezing Main Layers and setting branch layers training to true\")\n",
    "            for i in range(len(self.layers)):\n",
    "                # print(model.layers[i].name)\n",
    "                if \"branch\" in self.layers[i].name:\n",
    "                    # print(\"setting \",self.layers[i].name,\" training to true\")\n",
    "                    self.layers[i].trainable = True\n",
    "                else: \n",
    "                    # print(\"setting \",self.layers[i].name,\" training to false\")\n",
    "                    self.layers[i].trainable = False               \n",
    "        else:\n",
    "            print(\"Setting Main Layers  and branch layers training to true\")\n",
    "            for i in range(len(self.layers)):\n",
    "                # print(model.layers[i].name)\n",
    "                self.layers[i].trainable = True\n",
    "                # print(\"setting \",self.layers[i].name,\" training to true\")\n",
    "\n",
    "\n",
    "    def fit(self, train_ds, validation_data=None, epochs=1, callbacks=[], saveName = \"\", transfer = False, customOptions=\"\"):\n",
    "        \"\"\"Train the model that is passed using transfer learning. This function expects a model with trained main branches and untrained (or randomized) side branches.\n",
    "    \"\"\"\n",
    "        logs = []\n",
    "        num_outputs = len(self.outputs) # the number of output layers for the purpose of providing labels\n",
    "        #Freeze main branch layers\n",
    "        #how to iterate through layers and find main branch ones?\n",
    "        #simple fix for now: all branch nodes get branch in name.\n",
    "        self.setTrainable(transfer)\n",
    "        run_logdir = get_run_logdir(self.name)\n",
    "        tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "        if saveName ==\"\":\n",
    "            newModelName = \"{}_branched\".format(self.name )\n",
    "        else:\n",
    "            newModelName = saveName\n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\"models/{}\".format(newModelName), monitor='val_loss', verbose=1, mode='max')\n",
    "\n",
    "        history =super().fit(train_ds,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_data,\n",
    "                validation_freq=1,\n",
    "                callbacks=[tensorboard_cb]+callbacks)\n",
    "        return self\n",
    "\n",
    "### the distill version of the branch model\n",
    "    \n",
    "class distilled_branch_model(BranchModel):\n",
    "    def __init__(self, modelName=\"\",saveName=\"\",transfer=True,customOptions=\"\") -> None:\n",
    "        self.modelName=modelName\n",
    "        self.saveName=saveName\n",
    "        self.transfer=transfer\n",
    "        self.customOptions=customOptions\n",
    "        self.model = tf.keras.models.load_model(\"{}\".format(modelName))\n",
    "        self.branchName = \"\"\n",
    "        self.dataset =\"\"\n",
    "        return None\n",
    "\n",
    "    def add_branches(self,branchName, branchPoints=[], exact = True, target_input = False):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        self.model = branch.add(self.model,branchPoints,branchName, exact=exact, target_input = target_input)\n",
    "        print(self)\n",
    "        return self\n",
    "\n",
    "    def add_distill(self,branchName, branchPoints, teacher_softmax, teaching_features, exact = True, target_input = False):\n",
    "        if len(branchPoints) == 0:\n",
    "            return\n",
    "        self.model = branch.add_distil(self.model, teacher_softmax, teaching_features, branchPoints,branchName, exact=exact, target_input = target_input)\n",
    "        print(self)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define some functions for report the results after the training is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getPredictions_Energy(model, input_set, stopping_point=None,num_classes=10, values =['energy', 'entropy', 'calibration']):\n",
    "    '''\n",
    "        Function for collecting the model's predictions on a test set. \n",
    "        Returns a list of DataFrames for each exit of the model.    \n",
    "    '''\n",
    "    num_outputs = len(model.outputs) # the number of output layers for the purpose of providing labels\n",
    "    print(\"outputs\",num_outputs)\n",
    "    print(values)\n",
    "    Results=[]\n",
    "    Pred=[]\n",
    "    Labels =[]\n",
    "    Outputs = pd.DataFrame()\n",
    "    Energy = []\n",
    "    Entropy = []\n",
    "    pAcc=[]\n",
    "    calibration=[]\n",
    "    conf=[]\n",
    "    if 'energy' in values:\n",
    "        print(True)\n",
    "    for i in range(num_outputs):\n",
    "        Results.append([])\n",
    "        Pred.append([])\n",
    "        Labels.append([])\n",
    "        Energy.append([])\n",
    "        Entropy.append([])\n",
    "        pAcc.append([])\n",
    "        calibration.append([])\n",
    "    for i, (x,y) in enumerate(input_set):\n",
    "        if stopping_point and i > stopping_point:\n",
    "            break\n",
    "        try:\n",
    "            print(\"prediction: {} of {}\".format(i,len(input_set)),end='\\r')\n",
    "        except:\n",
    "            print(\"prediction: {}\".format(i),end='\\r')\n",
    "            pass\n",
    "        predictions = model.predict(x)\n",
    "        if num_outputs > 1:\n",
    "            _predictions = predictions[0]\n",
    "        else:\n",
    "            _predictions = [predictions]\n",
    "        # print(_predictions)\n",
    "        for k, outputs in enumerate(_predictions):\n",
    "            \n",
    "            # print(\"outputs \", k, outputs)\n",
    "            for j, prediction in enumerate(outputs):\n",
    "                Results[k].append(np.argmax(prediction))\n",
    "                Labels[k].append(np.argmax(y[j]))\n",
    "                if 'energy' in values:\n",
    "                    Energy[k].append( -(logsumexp(np.array(prediction))))\n",
    "                if 'entropy' in values:\n",
    "                    Entropy[k].append(brevis.utils.calcEntropy_Tensors2(tf.nn.softmax(prediction)).numpy())\n",
    "                if 'calibration' in values:\n",
    "                    calibration[k].append(np.amax(tf.nn.softmax(prediction).numpy()))\n",
    "    Outputs=[]\n",
    "    for j in range(num_outputs):\n",
    "        results = {\"x\":Results[j],\"y\":Labels[j]}\n",
    "        if 'energy' in values:\n",
    "            results[\"energy\"]=Energy[j]\n",
    "        if 'entropy' in values:\n",
    "            results['entropy']=Entropy[j]\n",
    "        if 'calibration' in values:\n",
    "            results['calibration']=calibration[j]\n",
    "        df = pd.DataFrame(results)\n",
    "        conditions = [df['x'] == df['y'],df['x'] != df['y']]\n",
    "        choices = [1, 0]\n",
    "        #create new column in DataFrame that displays results of comparisons\n",
    "        df['correct'] = np.int32(np.select(conditions, choices, default=None))\n",
    "        Outputs.append(df)\n",
    "    return Outputs\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, plot_precision_recall_curve\n",
    "from numpy import sqrt, argmax\n",
    "def calc_AUC(output_df,metrics=['energy'],plot=False, pos_label = 0):\n",
    "    '''\n",
    "    AUC calculation function for list of output dataframes\n",
    "    returns a list of threshold for the gmean of each set of outputs.    \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    _thresholds = []\n",
    "    y_test = np.int32(output_df['correct'])\n",
    "    plots = []\n",
    "        \n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for metric in metrics:    \n",
    "        # print(\"metric\", metric)\n",
    "        lr_auc = roc_auc_score(y_test, output_df[metric])\n",
    "        if metric in lessThanMetrics:\n",
    "            pos_label = 0\n",
    "        else:\n",
    "            pos_label = 1\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, output_df[metric],pos_label=pos_label)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        # print(gmeans)\n",
    "        # locate the index of the largest g-mean\n",
    "        ix = argmax(gmeans)\n",
    "        threshold = thresholds[ix]\n",
    "        if plot:\n",
    "            print(metric,\" lr_auc\",lr_auc, 'Best Threshold={}, G-Mean={}, TPR={}, FPR={}'.format(threshold, gmeans[ix],tpr[ix],fpr[ix]))\n",
    "        _thresholds.append(threshold)\n",
    "        # plot the roc curve for the model\n",
    "        plots.append({\"fpr\":fpr,\"tpr\":tpr,\"label\":metric, \"ix\":ix})\n",
    "    if plot:\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        for plot in plots:\n",
    "            ix = plot['ix']\n",
    "            plt.plot(plot[\"fpr\"], plot[\"tpr\"],  label=plot['label'])\n",
    "\n",
    "            plt.scatter(plot[\"fpr\"][ix], plot[\"tpr\"][ix], marker='o', color='black')\n",
    "        # axis labels\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(metric)\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "    return _thresholds, plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateOOD(ID,OOD,metrics=[\"energy\"], threshold=None, exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1']):\n",
    "    '''\n",
    "    Build an evaluation plot of the branched model's performance on ID and OOD datasets.\n",
    "\n",
    "    ::Variables::\n",
    "    ID: in-distribution dataset\n",
    "    OOD: out of distribution dataset\n",
    "    metrics: list of strings of metrics to evaluate branch results with. can be any of the following: [\"gmean\", \"mean\", \"PR_AUC\"]\n",
    "    exit: #if a specific exit number is specified, only output the results of that exit. counts from 0 - N, with 0 being the main exit. -1 returns all exits\n",
    "    legend: specify a legend to use for the plot\n",
    "    main_exit_included: specify if the last exit must answer all inputs recieved, if False, it will use the threshold to accept and reject inputs\n",
    "    plot: choose to produce a plot or just the table of branch results\n",
    "    exit_labels: what labels to use for the exits, defaults to \"exit_N\" \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for j, metric in enumerate(metrics):\n",
    "        print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "        rollOver_ID_indices = pd.Index([])\n",
    "        rollOver_OOD_indices = pd.Index([])\n",
    "        Exit_Name=[]\n",
    "        _ID = ID.copy()\n",
    "        _OOD = OOD.copy()\n",
    "        _ID.append(_ID.pop(0))\n",
    "        _OOD.append(_OOD.pop(0))\n",
    "        Accepted_df = pd.DataFrame()\n",
    "        Input_ID=[]\n",
    "        Input_OOD=[]\n",
    "        Accepted_list =[]\n",
    "        Accepted_ID_list = []\n",
    "        Accepted_OOD_list = []\n",
    "        Acceptance_correct =[]\n",
    "        Input_predictions =[]\n",
    "        Accepted_Ratio_list=[]\n",
    "        Accepted_Accuracy_list=[]\n",
    "        Branch_flops = []\n",
    "        Thresholds=[]\n",
    "        Test_accuracy =[]\n",
    "        Rollover_accuracy=[]\n",
    "        Results=[]\n",
    "        \n",
    "        if exit > 0: #if a specific exit number is specified, only output the results of that exit.\n",
    "            _ID = [_ID[max(exit-1,0)]]\n",
    "            _OOD = [_OOD[max(exit-1,0)]]\n",
    "            exit_labels=['exit_{}'.format(exit)]\n",
    "        for i, (output_ID, output_OOD) in enumerate(zip(_ID, _OOD)): \n",
    "            Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "            if threshold:\n",
    "                if type(threshold) is list:\n",
    "                    if i >= len(threshold): #no threshold in the array so treat as None.\n",
    "                        continue\n",
    "                    _threshold = threshold[i]\n",
    "                    print(\"threshold\",_threshold)\n",
    "                else:\n",
    "                    _threshold = threshold\n",
    "                if _threshold == \"mean\":\n",
    "                    Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                    _threshold = np.array(Correct[metric]).mean()\n",
    "                if _threshold == \"gmean\":\n",
    "                    AUC_thresholds = evaluate.calc_AUC(output_ID, metrics=metric, plot = False)\n",
    "                    _threshold = AUC_thresholds[j]\n",
    "                if _threshold == \"PR_AUC\":\n",
    "                    precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                    _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                else:\n",
    "                    _threshold = np.float32(_threshold)\n",
    "\n",
    "            if len(rollOver_ID_indices)>0:\n",
    "                # print(\"rollover enabled, {} ID predictions provided\".format(len(rollOver_ID_indices)))\n",
    "                output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "            if len(rollOver_OOD_indices)>0:\n",
    "                # if plot:\n",
    "                # print(\"rollover enabled, {} OOD predictions provided\".format(len(rollOver_OOD_indices)))\n",
    "                output_OOD = output_OOD.iloc[rollOver_OOD_indices]\n",
    "            \n",
    "            legend = [\"Branch Threshold\",\"Correct ID Predictions\",\"Incorrect ID Predictions\", \"OOD Inputs\"]\n",
    "            Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "            Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "            if plot:\n",
    "                \n",
    "                _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(output_OOD[metric].tolist(), bins=100,color=\"grey\",alpha=0.5)  # arguments are passed to np.histogram\n",
    "\n",
    "            if plot:\n",
    "                plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                plt.title(metric.capitalize() + \" Outliers\", weight=\"bold\")\n",
    "                # plt.legend(legend)\n",
    "                plt.xlabel(metric.capitalize() + \" Score\", weight=\"bold\")\n",
    "                plt.ylabel(\"Frequency\", weight=\"bold\")\n",
    "                plt.legend(legend,frameon=True)\n",
    "                \n",
    "                ## arrow annotation\n",
    "                if lessThanMetrics:\n",
    "                    ymax = plt.gca().get_ylim()\n",
    "                    xmax = plt.gca().get_xlim()\n",
    "                    ywidth = abs(ymax[0] - ymax[1])\n",
    "                    xwidth = abs(xmax[0] - xmax[1])\n",
    "                    print(ymax, ywidth)\n",
    "                    print(xmax, _threshold- xmax[1]/10 )\n",
    "                    \n",
    "                    plt.text(max(_threshold- xwidth/4,xmax[0]) , (ywidth/1.5) + ywidth/60 ,\"Accepted Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold - xwidth/4, ywidth/1.5), xytext=(_threshold, ywidth/1.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                    plt.text(min(_threshold + xwidth/80,xmax[1]), (ywidth/2)+ ywidth/60,\"Rejected Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold + xwidth/4, ywidth/2), xytext=(_threshold, ywidth/2),  arrowprops=dict(arrowstyle=\"->\"))\n",
    "                else:\n",
    "                    plt.annotate(\"\", xy=(_threshold, 100), xytext=(_threshold, 0), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                plt.show()\n",
    "            if main_exit_included and i == len(_ID)-1 :\n",
    "                Exit_Name.append(\"Main_exit\")\n",
    "                _threshold\n",
    "                if plot:\n",
    "                    print(\"main_exit\")\n",
    "                OOD_accepted = output_OOD\n",
    "                OOD_rejected = None\n",
    "                ID_accepted = output_ID\n",
    "                ID_rejected = None\n",
    "                accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                rejected_correct = None\n",
    "                accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                rejected_incorrect = None\n",
    "                accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                _threshold = \"NA\"\n",
    "            else:\n",
    "                if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() <= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() > _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                else: ### metrics that require greater than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() >= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() < _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                rollOver_ID_indices = ID_rejected.index\n",
    "                rollOver_OOD_indices = OOD_rejected.index\n",
    "                if i >= len(exit_labels):\n",
    "                    exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                print(exit_labels)\n",
    "                Exit_Name.append(exit_labels[i])\n",
    "            Thresholds.append(_threshold)\n",
    "            \n",
    "            Results.append(accepted_correct + accepted_incorrect)\n",
    "            Input_ID.append(len(output_ID))\n",
    "            Input_OOD.append(len(output_OOD))\n",
    "            Accepted_ID_list.append(len(ID_accepted))\n",
    "            Accepted_OOD_list.append(len(OOD_accepted))\n",
    "            Accepted_Ratio_list.append(len(ID_accepted)/(len(ID_accepted) + len(OOD_accepted)))\n",
    "            Acceptance_correct.append(len(accepted_correct))\n",
    "            Accepted_Accuracy_list.append(overall_accepted_acc)\n",
    "        df = pd.DataFrame({\n",
    "        \"Exit_Name\":Exit_Name,\n",
    "        \"ID_Inputs\":Input_ID,\n",
    "        \"OOD_Inputs\":Input_OOD,\n",
    "        \"Test_Accuracy\":Test_accuracy,\n",
    "        # \"RollOver_Accuracy\":Rollover_accuracy,\n",
    "        \"Threshold\":Thresholds,\n",
    "        \"Accepted ID\":Accepted_ID_list,\n",
    "        \"Accepted OOD\":Accepted_OOD_list,\n",
    "            \n",
    "        \"Accepted_Correct\":Acceptance_correct,\n",
    "        \"Accepted_ID_Ratio\":Accepted_Ratio_list,\n",
    "        \"Acceptance_Accuracy\":Accepted_Accuracy_list,\n",
    "\n",
    "        # \"Flops\":Branch_flops,\n",
    "        # \"Cost Ratio\":,                                  \n",
    "                        })\n",
    "        with pd.option_context('expand_frame_repr', False):\n",
    "            print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Datasets\n",
    "<hr>\n",
    "validation set is for eval during training, testing set is for eval after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds batch count 1406\n",
      "validation_ds batch count 156\n",
      "test_ds batch count 312\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# import csv\n",
    "# with open('results/altTrain_labels.csv', newline='') as f:\n",
    "    # reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    # alt_trainLabels = list(reader)\n",
    "# with open('results/altTest_labels.csv', newline='') as f:\n",
    "    # reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    # alt_testLabels = list(reader)\n",
    "\n",
    "# altTraining = tf.data.Dataset.from_tensor_slices((train_images,alt_trainLabels))\n",
    "\n",
    "# validation_images, validation_labels = train_images[:5000], alt_trainLabels[:5000]\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_images, alt_trainLabels))\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_images, alt_testLabels))\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels,10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "\n",
    "###normal method\n",
    "validation_images, validation_labels = train_images[:5000], train_labels[:5000] #get the first 5k training samples as validation set\n",
    "train_images, train_labels = train_images[5000:], train_labels[5000:] # now remove the validation set from the training set.\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "\n",
    "def augment_images(image, label):\n",
    "    image = tf.image.resize(image, (32,32))\n",
    "    return image, label\n",
    "\n",
    "train_ds_size = len(list(train_ds))\n",
    "test_ds_size = len(list(test_ds))\n",
    "validation_ds_size = len(list(validation_ds))\n",
    "\n",
    "train_ds = (train_ds\n",
    "                  .map(augment_images)\n",
    "                  .shuffle(buffer_size=train_ds_size,seed=42,reshuffle_each_iteration=False)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "test_ds = (test_ds\n",
    "                  .map(augment_images)\n",
    "                #   .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "validation_ds = (validation_ds\n",
    "                  .map(augment_images)\n",
    "                #   .shuffle(buffer_size=validation_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "print(\"train_ds batch count\", len(train_ds))\n",
    "print(\"validation_ds batch count\", len(validation_ds))\n",
    "print(\"test_ds batch count\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 6s 12ms/step - loss: 0.8087 - accuracy: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8087037205696106, 0.7813501358032227]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./models/resnet_CE_entropy_finetuned.hdf5\")\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "def loss_function(annealing_rate=1, momentum=1, decay=1, global_loss=False):\n",
    "    #create a wrapper function that returns a function\n",
    "    temperature = 1\n",
    "    Classes = 10\n",
    "    keras_kl = tf.keras.losses.KLDivergence()\n",
    "    annealing_rate = annealing_rate\n",
    "    momentum_rate = momentum\n",
    "    decay_rate = decay\n",
    "    def cross_entropy_evidence(labels, outputs): \n",
    "        softmax = tf.nn.softmax(outputs)\n",
    "        # activated_outputs =tf.keras.activations.sigmoid(softmax)\n",
    "        evidence = softplus_evidence(outputs)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha, axis=1, keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((labels-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "\n",
    "        annealing_coef = tf.minimum(1.0,tf.cast(annealing_rate,tf.float32))\n",
    "#         annealing_coef = 1\n",
    "        alp = E*(1-labels) + 1 \n",
    "        # print(\"alp\", alp)\n",
    "        C =  annealing_coef * KL(alp)\n",
    "        # C = keras_kl(labels,evidence)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(labels, softmax)\n",
    "        pred = tf.argmax(outputs,1)\n",
    "        truth = tf.argmax(labels,1)\n",
    "        match = tf.reshape(tf.cast(tf.equal(pred, truth), tf.float32),(-1,1))\n",
    "        return loss + C\n",
    "        # return (A + B) + C\n",
    "    return  cross_entropy_evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the branch structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _branch_conv1(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" \n",
    "        Standard Branch, no distillation\n",
    "        Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, activation='softmax', name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "# class SelfDistilDense(branches.branch.BranchEndpoint):\n",
    "#     \"\"\" distillation feature endpoint, an attempt at looking at the distillation betwen internal layers rather then exit layers\n",
    "#     \"\"\"\n",
    "#         def __init__(self, num_outputs, loss_coef=.3, temperature=10, name=None, **kwargs):\n",
    "#             super(SelfDistilDense, self).__init__(num_outputs=num_outputs, name=name)\n",
    "#             self.num_outputs = num_outputs\n",
    "#             self.loss_coef = loss_coef\n",
    "#             self.temperature = temperature \n",
    "#             self.distillation_loss_fn=keras.losses.KLDivergence()\n",
    "\n",
    "#         def build(self, input_shape):\n",
    "#             tf.print(\"inputShape\",input_shape)\n",
    "#             # self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "\n",
    "#         def get_config(self):\n",
    "#             config = super().get_config().copy()\n",
    "#             config.update({\n",
    "#                 'name': self.name\n",
    "#             })\n",
    "#             return config\n",
    "\n",
    "#         def call(self, inputs, teaching_distill=None):\n",
    "#             ''' do the normal kernel operations, then compare the difference between the teacher and this.\n",
    "#             '''\n",
    "#             # outputs = tf.matmul(inputs,self.kernel)\n",
    "#             # outputs = tf.nn.relu(outputs)\n",
    "#             # tf.print(\"outputs\",outputs)\n",
    "#             # tf.print(\"teaching\",teaching_distill)\n",
    "#             if teaching_distill is not None:\n",
    "#                 distil_loss = self.distillation_loss_fn(inputs/self.temperature, teaching_distill/self.temperature)\n",
    "#                 distil_loss = distil_loss * self.loss_coef\n",
    "#                 # print(\"KL_LOSS\", kl_loss)\n",
    "#                 # self.add_loss(kl_loss)\n",
    "#                 self.add_loss(distil_loss)\n",
    "#                 self.add_metric(distil_loss, aggregation='mean',name=self.name+\"_distil\") # metric so this loss value can be monitored.\n",
    "#             return inputs\n",
    "        \n",
    "class SelfDistilEndpoint_2(branches.branch.BranchEndpoint):\n",
    "        \"\"\" distillation endpoint, performs the KL divergence between the teacher's and student's logits\n",
    "    \"\"\"\n",
    "        def __init__(self, num_outputs, loss_coef=1.9, temperature=10, name=None, **kwargs):\n",
    "            super(SelfDistilEndpoint_2, self).__init__(num_outputs=num_outputs, name=name)\n",
    "            self.num_outputs = num_outputs\n",
    "            self.loss_coef = loss_coef\n",
    "            self.temperature = temperature \n",
    "            self.distillation_loss_fn=keras.losses.KLDivergence()\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            tf.print(\"inputShape\",input_shape)\n",
    "            self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]), self.num_outputs])\n",
    "        \n",
    "        def get_config(self):\n",
    "            config = super().get_config().copy()\n",
    "            config.update({\n",
    "                'name': self.name\n",
    "            })\n",
    "            return config\n",
    "\n",
    "        def call(self, inputs, teaching_distill=None):\n",
    "            ''' do the normal kernel operations, then compare the difference between the teacher and this.\n",
    "            '''\n",
    "            outputs = tf.matmul(inputs,self.kernel)\n",
    "            outputs_sm = tf.nn.softmax(outputs)\n",
    "            # tf.print(\"outputs\",outputs)\n",
    "            # tf.print(\"teaching\",teaching_distill)\n",
    "            if teaching_distill is not None:\n",
    "                distil_loss = self.distillation_loss_fn(outputs_sm/self.temperature, teaching_distill/self.temperature)\n",
    "                distil_loss = distil_loss * self.loss_coef\n",
    "                # print(\"KL_LOSS\", kl_loss)\n",
    "                # self.add_loss(kl_loss)\n",
    "                self.add_loss(distil_loss)\n",
    "                self.add_metric(distil_loss, aggregation='mean',name=self.name+\"_distil\") # metric so this loss value can be monitored.\n",
    "            return outputs\n",
    "\n",
    "class distillBranch():\n",
    "    def __init__(self, _teacher, _features, loss_coef=1.0, temperature = 10,**kwargs):\n",
    "        self.loss_coef = loss_coef\n",
    "        self.temperature = temperature\n",
    "        self.teacher = _teacher\n",
    "        self.features = _features\n",
    "    def _branch_feature_distill(self,prevLayer, teacher = None, teaching_features=None):\n",
    "        \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "            NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "        \"\"\" \n",
    "        branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "        branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "        branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "        branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "        branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "        branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "        branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "        branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "        branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "        branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "        branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "        branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "        branchLayer = SelfDistilDense(512, loss_coef=self.loss_coef, temperature = self.temperature, name=tf.compat.v1.get_default_graph().unique_name(\"branch_feature_student\"))(branchLayer,self.features)\n",
    "        output = SelfDistilEndpoint_2(num_outputs=10, loss_coef=1.9, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer,self.teacher)\n",
    "        # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "        # output = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "        return output\n",
    "\n",
    "    \n",
    "def _branch_Distill(prevLayer, teacher = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    # branchLayer = SelfDistilDense(512, loss_coef=1.9, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_feature_student\"))(branchLayer,teacher)\n",
    "    # branchLayer = layers.ReLU()(branchLayer)\n",
    "    # print(teacher)\n",
    "    output = SelfDistilEndpoint_2(num_outputs=10, loss_coef=1.3, temperature = 10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer,teacher)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    # output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### branch the model\n",
    "<hr>\n",
    "The already existing model is loaded from the file, \"*.hdf5\", \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by name\n",
      "add Branch to branch point  conv2_block1_out\n",
      "inputShape TensorShape([None, 512])\n",
      "add Branch to branch point  conv2_block3_out\n",
      "inputShape TensorShape([None, 512])\n",
      "branches added, new outputs [<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# branch_loss = IAD_loss(growth_callback)\n",
    "branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "# model = branching.Distill_BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\", custom_objects={})\n",
    "model = branching.Distill_BranchModel(name=\"./models/resnet_CE_entropy_finetuned.hdf5\")\n",
    "\n",
    "### branch the model, no distillation\n",
    "# model.add_branches([_branch_conv1,_branch_conv1],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           )\n",
    "\n",
    "\n",
    "\n",
    "### branch and distill the model\n",
    "model.add_distill(teacher = \"classification\",\n",
    "                  branch_layers = [_branch_Distill,_branch_Distill],\n",
    "                  branch_points = [\"conv2_block1_out\",\n",
    "                                   \"conv2_block3_out\",],\n",
    "                  )\n",
    "\n",
    "# model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss, branch_loss, branch_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "                  # optimizer=\"adam\",\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>,\n",
       " <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 89s 59ms/step - loss: 2.8396 - classification_loss: 0.3344 - branch_exit_loss: 1.2431 - branch_exit_1_loss: 1.0413 - classification_accuracy: 0.9150 - branch_exit_accuracy: 0.5607 - branch_exit_1_accuracy: 0.6411 - branch_exit_distil: 0.1238 - branch_exit_1_distil: 0.0970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2154c5f9488>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs =1, validation_data = validation_ds, callbacks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./models/resnet_CE_entropy_finetuned.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 15ms/step - loss: 0.8078 - accuracy: 0.7815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8078323006629944, 0.781499981880188]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brevis.model.summary()\n",
    "# print(branching.NepLogging)\n",
    "\n",
    "# model.fit(train_ds, epochs =1)\n",
    "model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the branches on the test dataset, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if EDL\n",
    "output_ID= evaluate.getPredictions_Energy(model, test_ds,  values =['entropy'], stopping_point=None)\n",
    "\n",
    "#if CE\n",
    "# output_ID= evaluate.getPredictions_Energy(model, test_ds,  values =['entropy'], stopping_point=None)\n",
    "for i in output_ID:\n",
    "    i['outlier']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if EDL\n",
    "output_OOD= evaluate.getPredictions_Energy(model, test_ds100,  values =['entropy'], stopping_point=None)\n",
    "\n",
    "#if CE\n",
    "# output_OOD= evaluate.getPredictions_Energy(model, test_ds100,  values =['entropy'], stopping_point=None)\n",
    "\n",
    "for i in output_OOD:\n",
    "    i['correct']=0\n",
    "    i['outlier']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, plot_precision_recall_curve\n",
    "from numpy import sqrt, argmax\n",
    "def calc_AUC(output_df,metrics=['energy'],plot=False, pos_label = 0):\n",
    "    '''\n",
    "    AUC calculation function for list of output dataframes\n",
    "    returns a list of threshold for the gmean of each set of outputs.    \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    _thresholds = []\n",
    "    y_test = np.int32(output_df['correct'])\n",
    "    plots = []\n",
    "        \n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for metric in metrics:    \n",
    "        # print(\"metric\", metric)\n",
    "        lr_auc = roc_auc_score(y_test, output_df[metric])\n",
    "        if metric in lessThanMetrics:\n",
    "            pos_label = 0\n",
    "        else:\n",
    "            pos_label = 1\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, output_df[metric],pos_label=pos_label)\n",
    "        gmeans = sqrt(tpr * (1-fpr))\n",
    "        # print(gmeans)\n",
    "        # locate the index of the largest g-mean\n",
    "        ix = argmax(gmeans)\n",
    "        threshold = thresholds[ix]\n",
    "        if plot:\n",
    "            print(metric,\" lr_auc\",lr_auc, 'Best Threshold={}, G-Mean={}, TPR={}, FPR={}'.format(threshold, gmeans[ix],tpr[ix],fpr[ix]))\n",
    "        _thresholds.append(threshold)\n",
    "        # plot the roc curve for the model\n",
    "        plots.append({\"fpr\":fpr,\"tpr\":tpr,\"label\":metric, \"ix\":ix})\n",
    "    if plot:\n",
    "        plt.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        for plot in plots:\n",
    "            ix = plot['ix']\n",
    "            plt.plot(plot[\"fpr\"], plot[\"tpr\"],  label=plot['label'])\n",
    "\n",
    "            plt.scatter(plot[\"fpr\"][ix], plot[\"tpr\"][ix], marker='o', color='black')\n",
    "        # axis labels\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(metric)\n",
    "        plt.legend()\n",
    "        # show the plot\n",
    "        plt.show()\n",
    "    return _thresholds, plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateOOD(ID,OOD,metrics=[\"energy\"], threshold=None, exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1']):\n",
    "    '''\n",
    "    Build an evaluation plot of the branched model's performance on ID and OOD datasets.\n",
    "\n",
    "    ::Variables::\n",
    "    ID: in-distribution dataset\n",
    "    OOD: out of distribution dataset\n",
    "    metrics: list of strings of metrics to evaluate branch results with. can be any of the following: [\"gmean\", \"mean\", \"PR_AUC\"]\n",
    "    exit: #if a specific exit number is specified, only output the results of that exit. counts from 0 - N, with 0 being the main exit. -1 returns all exits\n",
    "    legend: specify a legend to use for the plot\n",
    "    main_exit_included: specify if the last exit must answer all inputs recieved, if False, it will use the threshold to accept and reject inputs\n",
    "    plot: choose to produce a plot or just the table of branch results\n",
    "    exit_labels: what labels to use for the exits, defaults to \"exit_N\" \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for j, metric in enumerate(metrics):\n",
    "        print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "        rollOver_ID_indices = pd.Index([])\n",
    "        rollOver_OOD_indices = pd.Index([])\n",
    "        Exit_Name=[]\n",
    "        _ID = ID.copy()\n",
    "        _OOD = OOD.copy()\n",
    "        _ID.append(_ID.pop(0))\n",
    "        _OOD.append(_OOD.pop(0))\n",
    "        Accepted_df = pd.DataFrame()\n",
    "        Input_ID=[]\n",
    "        Input_OOD=[]\n",
    "        Accepted_list =[]\n",
    "        Accepted_ID_list = []\n",
    "        Accepted_OOD_list = []\n",
    "        Acceptance_correct =[]\n",
    "        Input_predictions =[]\n",
    "        Accepted_Ratio_list=[]\n",
    "        Accepted_Accuracy_list=[]\n",
    "        Branch_flops = []\n",
    "        Thresholds=[]\n",
    "        Test_accuracy =[]\n",
    "        Rollover_accuracy=[]\n",
    "        Results=[]\n",
    "        \n",
    "        if exit > 0: #if a specific exit number is specified, only output the results of that exit.\n",
    "            _ID = [_ID[max(exit-1,0)]]\n",
    "            _OOD = [_OOD[max(exit-1,0)]]\n",
    "            exit_labels=['exit_{}'.format(exit)]\n",
    "        for i, (output_ID, output_OOD) in enumerate(zip(_ID, _OOD)): \n",
    "            Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "            if threshold:\n",
    "                if type(threshold) is list:\n",
    "                    if i >= len(threshold): #no threshold in the array so treat as None.\n",
    "                        continue\n",
    "                    _threshold = threshold[i]\n",
    "                    print(\"threshold\",_threshold)\n",
    "                else:\n",
    "                    _threshold = threshold\n",
    "                if _threshold == \"mean\":\n",
    "                    Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                    _threshold = np.array(Correct[metric]).mean()\n",
    "                if _threshold == \"gmean\":\n",
    "                    AUC_thresholds = evaluate.calc_AUC(output_ID, metrics=metric, plot = False)\n",
    "                    _threshold = AUC_thresholds[j]\n",
    "                if _threshold == \"PR_AUC\":\n",
    "                    precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                    _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                else:\n",
    "                    _threshold = np.float32(_threshold)\n",
    "\n",
    "            if len(rollOver_ID_indices)>0:\n",
    "                # print(\"rollover enabled, {} ID predictions provided\".format(len(rollOver_ID_indices)))\n",
    "                output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "            if len(rollOver_OOD_indices)>0:\n",
    "                # if plot:\n",
    "                # print(\"rollover enabled, {} OOD predictions provided\".format(len(rollOver_OOD_indices)))\n",
    "                output_OOD = output_OOD.iloc[rollOver_OOD_indices]\n",
    "            \n",
    "            legend = [\"Branch Threshold\",\"Correct ID Predictions\",\"Incorrect ID Predictions\", \"OOD Inputs\"]\n",
    "            Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "            Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "            if plot:\n",
    "                \n",
    "                _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(output_OOD[metric].tolist(), bins=100,color=\"grey\",alpha=0.5)  # arguments are passed to np.histogram\n",
    "\n",
    "            if plot:\n",
    "                plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                plt.title(metric.capitalize() + \" Outliers\", weight=\"bold\")\n",
    "                # plt.legend(legend)\n",
    "                plt.xlabel(metric.capitalize() + \" Score\", weight=\"bold\")\n",
    "                plt.ylabel(\"Frequency\", weight=\"bold\")\n",
    "                plt.legend(legend,frameon=True)\n",
    "                \n",
    "                ## arrow annotation\n",
    "                if lessThanMetrics:\n",
    "                    ymax = plt.gca().get_ylim()\n",
    "                    xmax = plt.gca().get_xlim()\n",
    "                    ywidth = abs(ymax[0] - ymax[1])\n",
    "                    xwidth = abs(xmax[0] - xmax[1])\n",
    "                    print(ymax, ywidth)\n",
    "                    print(xmax, _threshold- xmax[1]/10 )\n",
    "                    \n",
    "                    plt.text(max(_threshold- xwidth/4,xmax[0]) , (ywidth/1.5) + ywidth/60 ,\"Accepted Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold - xwidth/4, ywidth/1.5), xytext=(_threshold, ywidth/1.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                    plt.text(min(_threshold + xwidth/80,xmax[1]), (ywidth/2)+ ywidth/60,\"Rejected Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold + xwidth/4, ywidth/2), xytext=(_threshold, ywidth/2),  arrowprops=dict(arrowstyle=\"->\"))\n",
    "                else:\n",
    "                    plt.annotate(\"\", xy=(_threshold, 100), xytext=(_threshold, 0), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                plt.show()\n",
    "            if main_exit_included and i == len(_ID)-1 :\n",
    "                Exit_Name.append(\"Main_exit\")\n",
    "                _threshold\n",
    "                if plot:\n",
    "                    print(\"main_exit\")\n",
    "                OOD_accepted = output_OOD\n",
    "                OOD_rejected = None\n",
    "                ID_accepted = output_ID\n",
    "                ID_rejected = None\n",
    "                accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                rejected_correct = None\n",
    "                accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                rejected_incorrect = None\n",
    "                accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                _threshold = \"NA\"\n",
    "            else:\n",
    "                if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() <= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() > _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                else: ### metrics that require greater than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() >= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() < _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                rollOver_ID_indices = ID_rejected.index\n",
    "                rollOver_OOD_indices = OOD_rejected.index\n",
    "                if i >= len(exit_labels):\n",
    "                    exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                print(exit_labels)\n",
    "                Exit_Name.append(exit_labels[i])\n",
    "            Thresholds.append(_threshold)\n",
    "            \n",
    "            Results.append(accepted_correct + accepted_incorrect)\n",
    "            Input_ID.append(len(output_ID))\n",
    "            Input_OOD.append(len(output_OOD))\n",
    "            Accepted_ID_list.append(len(ID_accepted))\n",
    "            Accepted_OOD_list.append(len(OOD_accepted))\n",
    "            Accepted_Ratio_list.append(len(ID_accepted)/(len(ID_accepted) + len(OOD_accepted)))\n",
    "            Acceptance_correct.append(len(accepted_correct))\n",
    "            Accepted_Accuracy_list.append(overall_accepted_acc)\n",
    "        df = pd.DataFrame({\n",
    "        \"Exit_Name\":Exit_Name,\n",
    "        \"ID_Inputs\":Input_ID,\n",
    "        \"OOD_Inputs\":Input_OOD,\n",
    "        \"Test_Accuracy\":Test_accuracy,\n",
    "        # \"RollOver_Accuracy\":Rollover_accuracy,\n",
    "        \"Threshold\":Thresholds,\n",
    "        \"Accepted ID\":Accepted_ID_list,\n",
    "        \"Accepted OOD\":Accepted_OOD_list,\n",
    "            \n",
    "        \"Accepted_Correct\":Acceptance_correct,\n",
    "        \"Accepted_ID_Ratio\":Accepted_Ratio_list,\n",
    "        \"Acceptance_Accuracy\":Accepted_Accuracy_list,\n",
    "\n",
    "        # \"Flops\":Branch_flops,\n",
    "        # \"Cost Ratio\":,                                  \n",
    "                        })\n",
    "        with pd.option_context('expand_frame_repr', False):\n",
    "            print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateOOD(output_ID,output_OOD,metrics=[\"entropy\"], threshold=\"gmean\", exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "632aef774cc0760417fa29704a5cf9562c90ea600d77237eb2969e3f571ea566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
