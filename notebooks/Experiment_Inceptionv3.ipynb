{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ee15a3-73b2-488d-b909-6949cf64c745",
   "metadata": {},
   "source": [
    "# Training and evaluation notebook for InceptionV3 based Brevis Model.\n",
    "<HR>\n",
    "Models are trained on the CIFAR10 dataset, and uses CIFAR100 as an OOD dataset. <br>\n",
    "    2 models are trained, one with branches using BrevisEnergy Loss and one using Cross entropy for all exits. <br>\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146f7bc4-1494-408c-8e50-436ce46c7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from skimage.filters import gaussian as gblur\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import brevis\n",
    "from brevis import branches\n",
    "from brevis import evaluate\n",
    "import tensorflow_probability as tfp\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c256da-228a-46e2-b6ec-f1b0363b8b59",
   "metadata": {},
   "source": [
    "### load datasets\n",
    "Inception is initially trained using 224x224x3 image sizes, and because of its convolution process it can't accept CIFAR10 images at their default resolution, so we have scaled the images up to the default size for inception.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa29a9a-2c5a-4a7f-a767-7b4b406e00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, validation_ds = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,shuffle_size=15000,input_size=(224,224),include_targets=False,num_outputs = 10,reshuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada7c6b5-4bbf-437f-bb76-1a5dcab41011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augment Dataset\n",
      "targetsis : False\n",
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow_datasets as tfds\n",
    "# ds = tfds.load('svhn_cropped', split='train', shuffle_files=True)\n",
    "# assert isinstance(ds, tf.data.Dataset)\n",
    "train_ds100, test_ds100, validation_ds100 = brevis.dataset.prepare.dataset(tf.keras.datasets.cifar100.load_data(label_mode=\"fine\"),32,5000,shuffle_size=15000,input_size=(224,224),include_targets=False,num_outputs = 100,reshuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27862ed3-0328-4282-98d5-5abf95e4e70e",
   "metadata": {},
   "source": [
    "## Initialize functions for building the loss functions \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706c314f-13ba-492c-b15d-18d67e2c7cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lambda_update(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, annealing_max,  lambda_t=0, max_t=1):\n",
    "        self.start_val = tf.Variable(initial_value=lambda_t, dtype=tf.float32) \n",
    "        \n",
    "        self.lambda_t = tf.Variable(initial_value=lambda_t, dtype=tf.float32) #updates each epoch\n",
    "        self.max_t = tf.Variable(initial_value=max_t, dtype=tf.float32)\n",
    "        self.annealing_max = tf.Variable(initial_value=annealing_max, dtype=tf.float32)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}): #needs to be on begin, otherwise the epoch update won't increase the value from 0 to 0.1 till the 3rd epoch...\n",
    "        val = tf.reduce_min([self.max_t, tf.cast(epoch+self.start_val, tf.dtypes.float32) / tf.cast(self.annealing_max, tf.dtypes.float32)])\n",
    "        tf.print(\"annealing coef updated to:\", val)\n",
    "        self.lambda_t.assign(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f338aa19-d7ed-4f2d-b7df-049c6c6cf534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits/10,-10,10))\n",
    "\n",
    "def KL(alpha,K):\n",
    "    # print(\"K:\",K)\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    S_beta = tf.reduce_sum(beta,axis=1,keepdims=True)\n",
    "    lnB = tf.compat.v1.lgamma(S_alpha) - tf.reduce_sum(tf.compat.v1.lgamma(alpha),axis=1,keepdims=True)\n",
    "    lnB_uni = tf.reduce_sum(tf.compat.v1.lgamma(beta),axis=1,keepdims=True) - tf.compat.v1.lgamma(S_beta)\n",
    "    dg0 = tf.compat.v1.digamma(S_alpha)\n",
    "    dg1 = tf.compat.v1.digamma(alpha)\n",
    "    kl = tf.reduce_sum((alpha - beta)*(dg1-dg0),axis=1,keepdims=True) + lnB + lnB_uni\n",
    "    return kl\n",
    "\n",
    "def _KL(alphas, target_alphas,  precision=None, target_precision=None, epsilon=1e-8):\n",
    "    '''\n",
    "    New KL divergence function. \n",
    "    '''\n",
    "    target_alphas = tf.cast(target_alphas,tf.float32)\n",
    "    alphas = tf.cast(alphas,tf.float32)\n",
    "    if not precision:\n",
    "        precision = tf.reduce_sum(alphas, axis=1, keepdims=True)\n",
    "    if not target_precision:\n",
    "        target_precision = tf.reduce_sum(target_alphas, axis=1, keepdims=True)\n",
    "    precision = tf.cast(precision,tf.float32)\n",
    "    target_precision = tf.cast(target_precision,tf.float32)\n",
    "    \n",
    "    precision_term = tf.compat.v1.lgamma(target_precision) - tf.compat.v1.lgamma(precision)\n",
    "    alphas_term = tf.reduce_sum(\n",
    "        tf.compat.v1.lgamma(alphas + epsilon)\n",
    "        - tf.compat.v1.lgamma(target_alphas + epsilon)\n",
    "        + (target_alphas - alphas)\n",
    "        * (\n",
    "            tf.compat.v1.digamma(target_alphas + epsilon)\n",
    "            - tf.compat.v1.digamma(target_precision + epsilon)\n",
    "        ),\n",
    "        axis=1,\n",
    "        keepdims=True,\n",
    "    )\n",
    "    cost = tf.squeeze(precision_term + alphas_term)\n",
    "    return cost\n",
    "\n",
    "def reverse_kl(alphas, target_alphas,  precision=None, target_precision=None, epsilon=1e-8):\n",
    "    return _KL(target_alphas,alphas, precision=None, target_precision=None, epsilon=1e-8)\n",
    "\n",
    "def DirichletKLLoss(labels, logits, reverse=True):\n",
    "    # alpha = tf.exp(logits)\n",
    "    alpha = tf.exp(tf.clip_by_value(logits/10,-10,10))\n",
    "    target_concentration = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    target_alphas = (tf.ones_like(alpha) + (target_concentration * labels))\n",
    "    alpha = alpha + 1\n",
    "    if reverse:\n",
    "        cost = reverse_kl(alpha, target_alphas)\n",
    "    else:\n",
    "        cost = _KL(alpha, target_alphas)\n",
    "    if tf.math.is_nan(tf.reduce_sum(cost)):\n",
    "        tf.print(\"logits\",logits, summarize=-1)\n",
    "        tf.print(\"alpha\",alpha, summarize=-1)\n",
    "        tf.print(\"cost\", cost, summarize=-1)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51600ec0-aa60-4197-9676-a0feba89300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class lambda_update(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, annealing_max,  lambda_t=0, max_t=1, starting_epoch = 0):\n",
    "        self.starting_epoch = starting_epoch\n",
    "        self.start_val = tf.Variable(initial_value=lambda_t, dtype=tf.float32) \n",
    "        \n",
    "        self.lambda_t = tf.Variable(initial_value=lambda_t, dtype=tf.float32) #updates each epoch\n",
    "        self.max_t = tf.Variable(initial_value=max_t, dtype=tf.float32)\n",
    "        self.annealing_max = tf.Variable(initial_value=annealing_max, dtype=tf.float32)\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}): #needs to be on begin, otherwise the epoch update won't increase the value from 0 to 0.1 till the 3rd epoch...\n",
    "        val = 0\n",
    "        if epoch >= self.starting_epoch:\n",
    "            val = tf.reduce_min([self.max_t, tf.cast((epoch - self.starting_epoch) +self.start_val , tf.dtypes.float32) / tf.cast(self.annealing_max, tf.dtypes.float32)])\n",
    "        tf.print(\"annealing coef updated to:\", val)\n",
    "        self.lambda_t.assign(val)\n",
    "        \n",
    "class growth_update(lambda_update):\n",
    "    ''' callback update method that checks the performance of the model against the validation set to decide if the annealing coef should be increased.\n",
    "        provides greater control of the additional loss elements by updating their hyperparameters inteligently, rather then with only a preset schedule.\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, annealing_max,  lambda_t=0, max_t=1, starting_epoch = 0):\n",
    "        self.starting_epoch = starting_epoch\n",
    "        self.start_val = tf.Variable(initial_value=lambda_t, dtype=tf.float32) \n",
    "        \n",
    "        self.step = tf.Variable(initial_value = 0,dtype=tf.float32)\n",
    "        self.lambda_t = tf.Variable(initial_value=lambda_t, dtype=tf.float32) #updates each epoch\n",
    "        self.max_t = tf.Variable(initial_value=max_t, dtype=tf.float32)\n",
    "        self.annealing_max = tf.Variable(initial_value=annealing_max, dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        self.training = tf.Variable(initial_value=False, dtype=tf.bool)              \n",
    "        self.past_val_acc= tf.Variable(initial_value =0, dtype=tf.float32)\n",
    "        self.val_acc= tf.Variable(initial_value =0, dtype=tf.float32)\n",
    "        \n",
    "    def on_training_begin(self, logs={}):\n",
    "        ''' indicate that training has begun, so val growth is an option.\n",
    "        '''\n",
    "        tf.print(\"training commenced, validation growth enabled\")\n",
    "        self.training.assign(True)\n",
    "#     def on_training_end(self, logs={}):\n",
    "#         ''' indicate that training has ended, so turn off val growth. Not sure if this is actually needed...\n",
    "#         '''\n",
    "#         tf.print(\"training commenced, validation growth enabled\")\n",
    "#         self.training.assign(False)\n",
    "    def on_epoch_begin(self, epoch, logs={}): #needs to be on begin, otherwise the epoch update won't increase the value from 0 to 0.1 till the 3rd epoch...\n",
    "        val = self.lambda_t\n",
    "        if epoch >= self.starting_epoch:\n",
    "            if self.val_acc >= self.past_val_acc:\n",
    "                \n",
    "                val = tf.reduce_min([self.max_t, tf.cast((self.step - self.starting_epoch) +self.start_val , tf.dtypes.float32) / tf.cast(self.annealing_max, tf.dtypes.float32)])\n",
    "                tf.print(\"annealing coef updated to:\", val)\n",
    "                self.lambda_t.assign(val)\n",
    "                self.past_val_acc.assign(self.val_acc)\n",
    "                self.step.assign(self.step + 1)\n",
    "            else:\n",
    "                tf.print(\"val acc did not improve from {}, annealing coef not updated, remains at:{}\".format(self.past_val_acc.numpy(), val.numpy()))\n",
    "     # tf.print(\"past val acc =\", self.past_val_acc)\n",
    "        # self.past_val_acc.assign(self.val_acc)\n",
    "        \n",
    "    def on_test_end(self, logs=None):\n",
    "        \"\"\" if training, save the performance results\n",
    "        \"\"\"\n",
    "        self.val_acc.assign(logs.get('branch_exit_1_accuracy')+ logs.get('branch_exit_accuracy'))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b58a6-68ec-4362-bc9f-14311dd22ddd",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee6172f-ad71-4611-9417-0421ff9b7b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 319s 220ms/step - loss: 0.4256 - accuracy: 0.8664 - val_loss: 0.2363 - val_accuracy: 0.9244\n",
      "313/313 [==============================] - 18s 57ms/step - loss: 0.2315 - accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.inception_v3.InceptionV3(input_shape=(224, 224, 3),\n",
    "     weights='imagenet',include_top=False)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "\n",
    "model.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "# train_ds, test_ds, validation_ds = prepareDataset(32)\n",
    "\n",
    "EPOCHS = 1\n",
    "for i in range(EPOCHS):\n",
    "    history = model.fit(train_ds, epochs=EPOCHS, validation_data = validation_ds, batch_size=32)\n",
    "    loss, accuracy = model.evaluate(test_ds, batch_size=32)\n",
    "    model.save(\"inception_finetuned.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7c27f-d781-4005-9079-a6e96369bd6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 423/1407 [========>.....................] - ETA: 3:20 - loss: 1.0879 - accuracy: 0.6529"
     ]
    }
   ],
   "source": [
    "# ### from scratch model\n",
    "\n",
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# model.save('./models/cifaroutlier_EDL_adam.hdf5')\n",
    "# loss = kl_loss(lambda_callback)\n",
    "# loss = brevisEnergy(lambda_callback)\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "# _base_model = tf.keras.applications.inception_v3.InceptionV3(input_shape=(224, 224, 3),\n",
    "#      weights='imagenet',include_top=False)\n",
    "\n",
    "# x = _base_model.output\n",
    "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "# x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "# x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
    "\n",
    "# base_model = tf.keras.models.Model(inputs=_base_model.input, outputs=x)\n",
    "# base_model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "#               loss=loss,\n",
    "#               metrics=['accuracy'])\n",
    "# history = base_model.fit(train_ds, validation_data=validation_ds, epochs=30,callbacks=[lambda_callback,earlyStop])\n",
    "\n",
    "\n",
    "base_model = keras.models.load_model(\"./inception_finetuned.hdf5\")\n",
    "base_model.compile(\n",
    "            # optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "            \n",
    "              tf.keras.optimizers.Adam(),\n",
    "              # tf.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "base_model.fit(train_ds, validation_data = validation_ds, epochs=3)\n",
    "# from keras_flops import get_flops    \n",
    "# flops = get_flops(base_model, batch_size=1)\n",
    "# print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0616635-a453-410c-bac6-ad9ca2b4efe4",
   "metadata": {},
   "source": [
    "## Branch the model\n",
    "First we will train the BrevisNet version of the model with BrevisEnergy loss\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0228e30c-4ece-4552-832e-bd0d01c50ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _branch_flat(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    \n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "    branchLayer = layers.Dense(1024, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch1024\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch512\"))(branchLayer)\n",
    "    # output = branch.CrossEntropyEndpoint(targets.shape[-1], name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer, targets)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "def _branch_conv1(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "def _branch_conv2(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "\n",
    "def _branch_conv1_SM(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, activation='softmax', name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "def _branch_conv2_SM(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, activation='softmax', name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fda2de1-ea79-4477-a970-dad83f69f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import tf_logging as logging\n",
    "class BrevisEarlyStopping(keras.callbacks.EarlyStopping):\n",
    "    def __init__(self,\n",
    "               monitor='val_loss',\n",
    "               min_delta=0,\n",
    "               patience=0,\n",
    "               verbose=0,\n",
    "               mode='auto',\n",
    "               baseline=None,\n",
    "               restore_best_weights=False):\n",
    "        self.monitor = monitor\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.baseline = baseline\n",
    "        self.min_delta = abs(min_delta)\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "        # super(_earlyStopping, self).__init__(monitor=)\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            logging.warning('EarlyStopping mode %s is unknown, '\n",
    "                          'fallback to auto mode.', mode)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "        else:\n",
    "            \n",
    "            # if (self.monitor.endswith('acc') or self.monitor.endswith('accuracy') or self.monitor.endswith('auc')):\n",
    "            self.monitor_op = np.greater\n",
    "            # else:\n",
    "                # self.monitor_op = np.less\n",
    "\n",
    "        if self.monitor_op == np.greater:\n",
    "            self.min_delta *= 1\n",
    "        else:\n",
    "            self.min_delta *= -1\n",
    "\n",
    "        self.monitor_op = np.greater\n",
    "        self.min_delta *= 1\n",
    "        \n",
    "    def get_monitor_value(self, logs):\n",
    "        logs = logs or {}\n",
    "        monitor_value = 0\n",
    "        if type(self.monitor) is list:\n",
    "            for i in self.monitor:\n",
    "                _log_val = logs.get(i)\n",
    "                # logging.warning(\"values are {}, {}\".format(i,_log_val))\n",
    "                if _log_val is None:\n",
    "                    logging.warning('Metric `%s` '\n",
    "                          'for early stopping is not available. Available metrics are: %s',\n",
    "                          i, ','.join(list(logs.keys())))\n",
    "                else:\n",
    "                    monitor_value += _log_val\n",
    "        # monitor_value = logs.get(self.monitor)\n",
    "        if monitor_value is None:\n",
    "            logging.warning('Early stopping conditioned on metric `%s` '\n",
    "                          'which is not available. Available metrics are: %s',\n",
    "                          self.monitor, ','.join(list(logs.keys())))\n",
    "        return monitor_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9612187-a7ff-405f-a284-59be37d081c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  mixed0\n",
      "add Branch to branch point  mixed1\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n",
      "branch added <brevis.core_v2.BranchModel object at 0x0000024810688B48>\n",
      "Freezing Main Layers and setting branch layers training to true\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def loss_wrapper(lambda_callback: lambda_update):\n",
    "    ''' Loss function of Evidential Dirichlet Networks\n",
    "        Expected Mean Square Error + KL divergence\n",
    "    '''\n",
    "    def custom_loss_function(p, logits):\n",
    "    #     alpha = alpha + 1\n",
    "        evidence = exp_evidence(logits)\n",
    "        # evidence = tf.nn.softplus(logits)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha,axis=1,keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((p-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "        annealing_coef =  lambda_callback.lambda_t\n",
    "        \n",
    "        bool_mask = tf.cast(p,tf.bool)\n",
    "        ic_mask = tf.cast(1 - p,tf.bool)\n",
    "        ic_bool_mask = tf.cast(ic_mask,tf.bool)\n",
    "        ic_alpha_masked = tf.cast(tf.ragged.boolean_mask(alpha, ic_bool_mask).to_tensor(),tf.float32)\n",
    "        #### info reg\n",
    "        _A = (ic_alpha_masked -1) ** 2\n",
    "        B_1 = tf.math.polygamma(1.,ic_alpha_masked) \n",
    "        B_2 = tf.math.polygamma(1., tf.reduce_sum(ic_alpha_masked,axis=1,keepdims=True))\n",
    "        _B = (B_1 - B_2)\n",
    "        info_reg =  .5* tf.reduce_sum(_A * _B,axis=1)\n",
    "        info_reg = annealing_coef * (info_reg * 2)\n",
    "        \n",
    "        # annealing_coef =  0.0001\n",
    "        # alp = E*(1-p) + 1 \n",
    "        # C =   annealing_coef * KL(alp,10)\n",
    "        # C =   annealing_coef * DirichletKLLoss(p,logits, True)\n",
    "        D = 0.0001 * -tf.reduce_mean(tfp.distributions.Dirichlet(alpha).entropy())\n",
    "        # tf.print((A + B),summarize=-1)\n",
    "        # tf.print((info_reg + D),summarize=-1)\n",
    "        \n",
    "        # tf.print(((A + B) + info_reg + D).shape)\n",
    "        return (A + B) + info_reg +  D # info_reg + D  #+ info_reg #+ C + D\n",
    "    return custom_loss_function\n",
    "\n",
    "def auxLoss(lambda_callback: lambda_update):\n",
    "    def auxloss(p, logits):\n",
    "        evidence = exp_evidence(logits)\n",
    "            # evidence = tf.nn.softplus(logits)\n",
    "        alpha = evidence + 1\n",
    "        S = tf.reduce_sum(alpha,axis=1,keepdims=True) \n",
    "        E = alpha - 1\n",
    "        m = alpha / S\n",
    "        A = tf.reduce_sum((p-m)**2, axis=1, keepdims=True) \n",
    "        B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True) \n",
    "        annealing_coef =  lambda_callback.lambda_t\n",
    "\n",
    "        bool_mask = tf.cast(p,tf.bool)\n",
    "        ic_mask = tf.cast(1 - p,tf.bool)\n",
    "        ic_bool_mask = tf.cast(ic_mask,tf.bool)\n",
    "        ic_alpha_masked = tf.cast(tf.ragged.boolean_mask(alpha, ic_bool_mask).to_tensor(),tf.float32)\n",
    "        #### info reg\n",
    "        _A = (ic_alpha_masked -1) ** 2\n",
    "        B_1 = tf.math.polygamma(1.,ic_alpha_masked) \n",
    "        B_2 = tf.math.polygamma(1., tf.reduce_sum(ic_alpha_masked,axis=1,keepdims=True))\n",
    "        _B = (B_1 - B_2)\n",
    "        info_reg =  .5* tf.reduce_sum(_A * _B,axis=1)\n",
    "        info_reg = annealing_coef * (info_reg * 2)\n",
    "        C =   annealing_coef * DirichletKLLoss(p,logits, True)\n",
    "        D = 0.0001 * -tf.reduce_mean(tfp.distributions.Dirichlet(alpha).entropy())\n",
    "        # return (A + B) + C #+ D #+ info_reg #+ C + D\n",
    "        # tf.print(C)\n",
    "        return tf.reduce_mean(info_reg+ D )\n",
    "    return auxloss     \n",
    "\n",
    "\n",
    "growth_callback = growth_update(100,0.,max_t = 1, starting_epoch =0)\n",
    "earlyStop = _earlyStopping(monitor=[\"val_classification_accuracy\",\"val_branch_exit_accuracy\",\"val_branch_exit_1_accuracy\"],patience=5,restore_best_weights=True)\n",
    "auxlossMetric = auxLoss(growth_callback)\n",
    "branch_loss = loss_wrapper(growth_callback)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "CE_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "model = brevis.BranchModel(name=\"./inception_finetuned.hdf5\", custom_objects={})\n",
    "# model.add_branches([_branch_flat,_branch_flat],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           target_input=False,loop=False,num_outputs=10)\n",
    "\n",
    "model.add_branches([_branch_conv2,_branch_conv2],\n",
    "                          [\"mixed0\",\"mixed1\",#\"mixed6\"\n",
    "                          ],\n",
    "                          target_input=False,loop=False,num_outputs=10)\n",
    "\n",
    "model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "                  optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  # optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.1),\n",
    "                  # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "                  # optimizer=\"adam\",\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model.setTrainable(True)\n",
    "# model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "#                   optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "#                   # optimizer = tf.optimizers.RMSprop(0.045),\n",
    "#                   # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "#               metrics=['accuracy'])\n",
    "# model.evaluate(test_ds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a109c265-d029-4aa9-86e3-c4fe9138b435",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " branch_conv2d (Conv2D)         (None, 25, 25, 128)  32896       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " branch_conv2d_3 (Conv2D)       (None, 25, 25, 128)  36992       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " branch_batchnorm (BatchNormali  (None, 25, 25, 128)  512        ['branch_conv2d[0][0]']          \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " branch_batchnorm_3 (BatchNorma  (None, 25, 25, 128)  512        ['branch_conv2d_3[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " branch_conv2d_1 (Conv2D)       (None, 25, 25, 128)  16512       ['branch_batchnorm[0][0]']       \n",
      "                                                                                                  \n",
      " branch_conv2d_4 (Conv2D)       (None, 25, 25, 128)  16512       ['branch_batchnorm_3[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " branch_batchnorm_1 (BatchNorma  (None, 25, 25, 128)  512        ['branch_conv2d_1[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_4 (BatchNorma  (None, 25, 25, 128)  512        ['branch_conv2d_4[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " branch_maxpool (MaxPooling2D)  (None, 12, 12, 128)  0           ['branch_batchnorm_1[0][0]']     \n",
      "                                                                                                  \n",
      " branch_maxpool_2 (MaxPooling2D  (None, 12, 12, 128)  0          ['branch_batchnorm_4[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " branch_conv2d_2 (Conv2D)       (None, 12, 12, 512)  66048       ['branch_maxpool[0][0]']         \n",
      "                                                                                                  \n",
      " branch_conv2d_5 (Conv2D)       (None, 12, 12, 512)  66048       ['branch_maxpool_2[0][0]']       \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " branch_batchnorm_2 (BatchNorma  (None, 12, 12, 512)  2048       ['branch_conv2d_2[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " branch_batchnorm_5 (BatchNorma  (None, 12, 12, 512)  2048       ['branch_conv2d_5[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " branch_maxpool_1 (MaxPooling2D  (None, 5, 5, 512)   0           ['branch_batchnorm_2[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " branch_maxpool_3 (MaxPooling2D  (None, 5, 5, 512)   0           ['branch_batchnorm_5[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " branch_flatten (Flatten)       (None, 12800)        0           ['branch_maxpool_1[0][0]']       \n",
      "                                                                                                  \n",
      " branch_flatten_1 (Flatten)     (None, 12800)        0           ['branch_maxpool_3[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " branch_dense (Dense)           (None, 1024)         13108224    ['branch_flatten[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_2 (Dense)         (None, 1024)         13108224    ['branch_flatten_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         2098176     ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " branch_dropout (Dropout)       (None, 1024)         0           ['branch_dense[0][0]']           \n",
      "                                                                                                  \n",
      " branch_dropout_1 (Dropout)     (None, 1024)         0           ['branch_dense_2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          524800      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " branch_dense_1 (Dense)         (None, 512)          524800      ['branch_dropout[0][0]']         \n",
      "                                                                                                  \n",
      " branch_dense_3 (Dense)         (None, 512)          524800      ['branch_dropout_1[0][0]']       \n",
      "                                                                                                  \n",
      " classification (Dense)         (None, 10)           5130        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " branch_exit (Dense)            (None, 10)           5130        ['branch_dense_1[0][0]']         \n",
      "                                                                                                  \n",
      " branch_exit_1 (Dense)          (None, 10)           5130        ['branch_dense_3[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51,948,350\n",
      "Trainable params: 27,514,388\n",
      "Non-trainable params: 24,433,962\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ad12cfb-d061-4bf7-b800-f3f033fd0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "annealing coef updated to: 0\n",
      "Epoch 1/60\n",
      "1407/1407 [==============================] - 184s 121ms/step - loss: 1.1416 - classification_loss: 0.1178 - branch_exit_loss: 0.5217 - branch_exit_1_loss: 0.5021 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.6041 - branch_exit_1_accuracy: 0.6192 - val_loss: 1.0467 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4795 - val_branch_exit_1_loss: 0.3990 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.6486 - val_branch_exit_1_accuracy: 0.7122\n",
      "annealing coef updated to: 0.01\n",
      "Epoch 2/60\n",
      "1407/1407 [==============================] - 174s 120ms/step - loss: 0.9303 - classification_loss: 0.1178 - branch_exit_loss: 0.4177 - branch_exit_1_loss: 0.3947 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.7440 - branch_exit_1_accuracy: 0.7595 - val_loss: 0.9571 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4132 - val_branch_exit_1_loss: 0.3757 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7354 - val_branch_exit_1_accuracy: 0.7676\n",
      "annealing coef updated to: 0.02\n",
      "Epoch 3/60\n",
      "1407/1407 [==============================] - 175s 121ms/step - loss: 0.8019 - classification_loss: 0.1178 - branch_exit_loss: 0.3555 - branch_exit_1_loss: 0.3285 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.7912 - branch_exit_1_accuracy: 0.8089 - val_loss: 0.9442 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3746 - val_branch_exit_1_loss: 0.4014 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7816 - val_branch_exit_1_accuracy: 0.7646\n",
      "annealing coef updated to: 0.03\n",
      "Epoch 4/60\n",
      "1407/1407 [==============================] - 175s 121ms/step - loss: 0.7181 - classification_loss: 0.1178 - branch_exit_loss: 0.3145 - branch_exit_1_loss: 0.2857 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.8245 - branch_exit_1_accuracy: 0.8438 - val_loss: 0.8648 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3716 - val_branch_exit_1_loss: 0.3250 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7864 - val_branch_exit_1_accuracy: 0.8196\n",
      "annealing coef updated to: 0.04\n",
      "Epoch 5/60\n",
      "1407/1407 [==============================] - 178s 123ms/step - loss: 0.6395 - classification_loss: 0.1178 - branch_exit_loss: 0.2734 - branch_exit_1_loss: 0.2483 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.8555 - branch_exit_1_accuracy: 0.8684 - val_loss: 0.9096 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3616 - val_branch_exit_1_loss: 0.3797 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8034 - val_branch_exit_1_accuracy: 0.7940\n",
      "val acc did not improve from 1.6059999465942383, annealing coef not updated, remains at:0.03999999910593033\n",
      "Epoch 6/60\n",
      "1407/1407 [==============================] - 178s 124ms/step - loss: 0.5664 - classification_loss: 0.1178 - branch_exit_loss: 0.2365 - branch_exit_1_loss: 0.2121 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.8765 - branch_exit_1_accuracy: 0.8896 - val_loss: 0.8920 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3761 - val_branch_exit_1_loss: 0.3477 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7940 - val_branch_exit_1_accuracy: 0.8114\n",
      "val acc did not improve from 1.6059999465942383, annealing coef not updated, remains at:0.03999999910593033\n",
      "Epoch 7/60\n",
      "1407/1407 [==============================] - 179s 124ms/step - loss: 0.4910 - classification_loss: 0.1178 - branch_exit_loss: 0.2005 - branch_exit_1_loss: 0.1727 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.8958 - branch_exit_1_accuracy: 0.9128 - val_loss: 0.8610 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3476 - val_branch_exit_1_loss: 0.3452 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8124 - val_branch_exit_1_accuracy: 0.8144\n",
      "annealing coef updated to: 0.05\n",
      "Epoch 8/60\n",
      "1407/1407 [==============================] - 181s 125ms/step - loss: 0.4430 - classification_loss: 0.1178 - branch_exit_loss: 0.1724 - branch_exit_1_loss: 0.1528 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9148 - branch_exit_1_accuracy: 0.9250 - val_loss: 0.8745 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3669 - val_branch_exit_1_loss: 0.3394 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8160 - val_branch_exit_1_accuracy: 0.8324\n",
      "annealing coef updated to: 0.06\n",
      "Epoch 9/60\n",
      "1407/1407 [==============================] - 183s 127ms/step - loss: 0.3976 - classification_loss: 0.1178 - branch_exit_loss: 0.1492 - branch_exit_1_loss: 0.1305 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9284 - branch_exit_1_accuracy: 0.9388 - val_loss: 0.8374 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3583 - val_branch_exit_1_loss: 0.3109 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8184 - val_branch_exit_1_accuracy: 0.8436\n",
      "annealing coef updated to: 0.07\n",
      "Epoch 10/60\n",
      "1407/1407 [==============================] - 185s 128ms/step - loss: 0.3514 - classification_loss: 0.1178 - branch_exit_loss: 0.1246 - branch_exit_1_loss: 0.1089 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9424 - branch_exit_1_accuracy: 0.9503 - val_loss: 0.8289 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3399 - val_branch_exit_1_loss: 0.3208 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8326 - val_branch_exit_1_accuracy: 0.8460\n",
      "annealing coef updated to: 0.08\n",
      "Epoch 11/60\n",
      "1407/1407 [==============================] - 223s 155ms/step - loss: 0.3213 - classification_loss: 0.1178 - branch_exit_loss: 0.1094 - branch_exit_1_loss: 0.0941 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9512 - branch_exit_1_accuracy: 0.9592 - val_loss: 0.9188 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3614 - val_branch_exit_1_loss: 0.3891 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8228 - val_branch_exit_1_accuracy: 0.8152\n",
      "val acc did not improve from 1.6786000728607178, annealing coef not updated, remains at:0.07999999821186066\n",
      "Epoch 12/60\n",
      "1407/1407 [==============================] - 220s 152ms/step - loss: 0.2964 - classification_loss: 0.1178 - branch_exit_loss: 0.0975 - branch_exit_1_loss: 0.0811 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9566 - branch_exit_1_accuracy: 0.9652 - val_loss: 0.8964 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3718 - val_branch_exit_1_loss: 0.3563 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8220 - val_branch_exit_1_accuracy: 0.8380\n",
      "val acc did not improve from 1.6786000728607178, annealing coef not updated, remains at:0.07999999821186066\n",
      "Epoch 13/60\n",
      "1407/1407 [==============================] - 221s 153ms/step - loss: 0.2712 - classification_loss: 0.1178 - branch_exit_loss: 0.0832 - branch_exit_1_loss: 0.0701 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9646 - branch_exit_1_accuracy: 0.9695 - val_loss: 0.8466 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3345 - val_branch_exit_1_loss: 0.3439 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8428 - val_branch_exit_1_accuracy: 0.8398\n",
      "annealing coef updated to: 0.09\n",
      "Epoch 14/60\n",
      "1407/1407 [==============================] - 217s 150ms/step - loss: 0.2484 - classification_loss: 0.1178 - branch_exit_loss: 0.0692 - branch_exit_1_loss: 0.0613 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9710 - branch_exit_1_accuracy: 0.9747 - val_loss: 0.8760 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3629 - val_branch_exit_1_loss: 0.3448 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8332 - val_branch_exit_1_accuracy: 0.8442\n",
      "val acc did not improve from 1.6826000213623047, annealing coef not updated, remains at:0.09000000357627869\n",
      "Epoch 15/60\n",
      "1407/1407 [==============================] - 220s 153ms/step - loss: 0.2265 - classification_loss: 0.1178 - branch_exit_loss: 0.0583 - branch_exit_1_loss: 0.0504 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9763 - branch_exit_1_accuracy: 0.9794 - val_loss: 0.8935 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3675 - val_branch_exit_1_loss: 0.3578 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8308 - val_branch_exit_1_accuracy: 0.8388\n",
      "val acc did not improve from 1.6826000213623047, annealing coef not updated, remains at:0.09000000357627869\n",
      "Epoch 16/60\n",
      "1407/1407 [==============================] - 220s 152ms/step - loss: 0.2154 - classification_loss: 0.1178 - branch_exit_loss: 0.0524 - branch_exit_1_loss: 0.0452 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9790 - branch_exit_1_accuracy: 0.9822 - val_loss: 0.8526 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3716 - val_branch_exit_1_loss: 0.3127 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8352 - val_branch_exit_1_accuracy: 0.8612\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 17/60\n",
      "1407/1407 [==============================] - 221s 153ms/step - loss: 0.2035 - classification_loss: 0.1178 - branch_exit_loss: 0.0466 - branch_exit_1_loss: 0.0391 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9816 - branch_exit_1_accuracy: 0.9853 - val_loss: 0.8563 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3645 - val_branch_exit_1_loss: 0.3236 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8330 - val_branch_exit_1_accuracy: 0.8566\n",
      "val acc did not improve from 1.6963999271392822, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 18/60\n",
      "1407/1407 [==============================] - 223s 154ms/step - loss: 0.1964 - classification_loss: 0.1178 - branch_exit_loss: 0.0416 - branch_exit_1_loss: 0.0370 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9839 - branch_exit_1_accuracy: 0.9858 - val_loss: 0.8501 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3565 - val_branch_exit_1_loss: 0.3254 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8390 - val_branch_exit_1_accuracy: 0.8538\n",
      "val acc did not improve from 1.6963999271392822, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 19/60\n",
      "1407/1407 [==============================] - 232s 160ms/step - loss: 0.1900 - classification_loss: 0.1178 - branch_exit_loss: 0.0392 - branch_exit_1_loss: 0.0330 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9848 - branch_exit_1_accuracy: 0.9876 - val_loss: 0.8442 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3575 - val_branch_exit_1_loss: 0.3184 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8418 - val_branch_exit_1_accuracy: 0.8610\n",
      "annealing coef updated to: 0.11\n",
      "Epoch 20/60\n",
      "1407/1407 [==============================] - 242s 167ms/step - loss: 0.1855 - classification_loss: 0.1178 - branch_exit_loss: 0.0362 - branch_exit_1_loss: 0.0315 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9861 - branch_exit_1_accuracy: 0.9888 - val_loss: 0.8548 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3582 - val_branch_exit_1_loss: 0.3283 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8416 - val_branch_exit_1_accuracy: 0.8594\n",
      "val acc did not improve from 1.7028000354766846, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 21/60\n",
      "1407/1407 [==============================] - 231s 160ms/step - loss: 0.1779 - classification_loss: 0.1178 - branch_exit_loss: 0.0325 - branch_exit_1_loss: 0.0276 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9879 - branch_exit_1_accuracy: 0.9900 - val_loss: 0.8372 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3488 - val_branch_exit_1_loss: 0.3201 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8502 - val_branch_exit_1_accuracy: 0.8632\n",
      "annealing coef updated to: 0.12\n",
      "Epoch 22/60\n",
      "1407/1407 [==============================] - 228s 157ms/step - loss: 0.1760 - classification_loss: 0.1178 - branch_exit_loss: 0.0325 - branch_exit_1_loss: 0.0257 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9883 - branch_exit_1_accuracy: 0.9909 - val_loss: 0.8724 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3626 - val_branch_exit_1_loss: 0.3415 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8552 - val_branch_exit_1_accuracy: 0.8606\n",
      "annealing coef updated to: 0.13\n",
      "Epoch 23/60\n",
      "1407/1407 [==============================] - 232s 160ms/step - loss: 0.1744 - classification_loss: 0.1178 - branch_exit_loss: 0.0308 - branch_exit_1_loss: 0.0258 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9887 - branch_exit_1_accuracy: 0.9913 - val_loss: 0.8727 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3751 - val_branch_exit_1_loss: 0.3294 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8444 - val_branch_exit_1_accuracy: 0.8650\n",
      "val acc did not improve from 1.7158000469207764, annealing coef not updated, remains at:0.12999999523162842\n",
      "Epoch 24/60\n",
      "1407/1407 [==============================] - 229s 158ms/step - loss: 0.1703 - classification_loss: 0.1178 - branch_exit_loss: 0.0291 - branch_exit_1_loss: 0.0234 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9899 - branch_exit_1_accuracy: 0.9919 - val_loss: 0.9025 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3889 - val_branch_exit_1_loss: 0.3454 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8390 - val_branch_exit_1_accuracy: 0.8568\n",
      "val acc did not improve from 1.7158000469207764, annealing coef not updated, remains at:0.12999999523162842\n",
      "Epoch 25/60\n",
      "1407/1407 [==============================] - 238s 164ms/step - loss: 0.1698 - classification_loss: 0.1178 - branch_exit_loss: 0.0301 - branch_exit_1_loss: 0.0218 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9901 - branch_exit_1_accuracy: 0.9924 - val_loss: 0.8768 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3814 - val_branch_exit_1_loss: 0.3271 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8474 - val_branch_exit_1_accuracy: 0.8672\n",
      "val acc did not improve from 1.7158000469207764, annealing coef not updated, remains at:0.12999999523162842\n",
      "Epoch 26/60\n",
      "1407/1407 [==============================] - 239s 165ms/step - loss: 0.1676 - classification_loss: 0.1178 - branch_exit_loss: 0.0277 - branch_exit_1_loss: 0.0220 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9910 - branch_exit_1_accuracy: 0.9924 - val_loss: 0.8969 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3792 - val_branch_exit_1_loss: 0.3494 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8484 - val_branch_exit_1_accuracy: 0.8624\n",
      "val acc did not improve from 1.7158000469207764, annealing coef not updated, remains at:0.12999999523162842\n",
      "Epoch 27/60\n",
      "1407/1407 [==============================] - 236s 163ms/step - loss: 0.1640 - classification_loss: 0.1178 - branch_exit_loss: 0.0258 - branch_exit_1_loss: 0.0204 - classification_accuracy: 0.9639 - branch_exit_accuracy: 0.9913 - branch_exit_1_accuracy: 0.9930 - val_loss: 0.8694 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3739 - val_branch_exit_1_loss: 0.3273 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8460 - val_branch_exit_1_accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x2475c56b188>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 60, validation_data=validation_ds, transfer=True,callbacks=[growth_callback, earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19f953d-a865-4e76-809c-57470ccecd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Main Layers  and branch layers training to true\n",
      "annealing coef updated to: 0\n",
      "Epoch 1/60\n",
      "   6/1407 [..............................] - ETA: 5:25 - loss: 76.9001 - classification_loss: 2.4161 - branch_exit_loss: 34.1105 - branch_exit_1_loss: 40.3735 - classification_accuracy: 0.6146 - branch_exit_accuracy: 0.1094 - branch_exit_1_accuracy: 0.1250WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1166s vs `on_train_batch_end` time: 0.1372s). Check your callbacks.\n",
      "1407/1407 [==============================] - 339s 228ms/step - loss: 4.3591 - classification_loss: 1.1437 - branch_exit_loss: 1.5966 - branch_exit_1_loss: 1.6187 - classification_accuracy: 0.6057 - branch_exit_accuracy: 0.5141 - branch_exit_1_accuracy: 0.5225 - val_loss: 2.7387 - val_classification_loss: 0.7501 - val_branch_exit_loss: 0.9975 - val_branch_exit_1_loss: 0.9911 - val_classification_accuracy: 0.7494 - val_branch_exit_accuracy: 0.6522 - val_branch_exit_1_accuracy: 0.6482\n",
      "annealing coef updated to: 0.01\n",
      "Epoch 2/60\n",
      "1407/1407 [==============================] - 319s 225ms/step - loss: 2.5443 - classification_loss: 0.6857 - branch_exit_loss: 0.9416 - branch_exit_1_loss: 0.9171 - classification_accuracy: 0.7707 - branch_exit_accuracy: 0.6702 - branch_exit_1_accuracy: 0.6789 - val_loss: 2.3817 - val_classification_loss: 0.6844 - val_branch_exit_loss: 0.8403 - val_branch_exit_1_loss: 0.8570 - val_classification_accuracy: 0.7684 - val_branch_exit_accuracy: 0.7000 - val_branch_exit_1_accuracy: 0.6944\n",
      "annealing coef updated to: 0.02\n",
      "Epoch 3/60\n",
      "1407/1407 [==============================] - 327s 231ms/step - loss: 2.0350 - classification_loss: 0.5154 - branch_exit_loss: 0.7722 - branch_exit_1_loss: 0.7473 - classification_accuracy: 0.8270 - branch_exit_accuracy: 0.7320 - branch_exit_1_accuracy: 0.7413 - val_loss: 2.5056 - val_classification_loss: 0.6790 - val_branch_exit_loss: 0.9147 - val_branch_exit_1_loss: 0.9118 - val_classification_accuracy: 0.7796 - val_branch_exit_accuracy: 0.6890 - val_branch_exit_1_accuracy: 0.7014\n",
      "val acc did not improve from 1.3944000005722046, annealing coef not updated, remains at:0.019999999552965164\n",
      "Epoch 4/60\n",
      "1407/1407 [==============================] - 330s 232ms/step - loss: 1.7444 - classification_loss: 0.4202 - branch_exit_loss: 0.6784 - branch_exit_1_loss: 0.6458 - classification_accuracy: 0.8596 - branch_exit_accuracy: 0.7648 - branch_exit_1_accuracy: 0.7770 - val_loss: 2.1501 - val_classification_loss: 0.5581 - val_branch_exit_loss: 0.8262 - val_branch_exit_1_loss: 0.7658 - val_classification_accuracy: 0.8232 - val_branch_exit_accuracy: 0.7226 - val_branch_exit_1_accuracy: 0.7468\n",
      "annealing coef updated to: 0.03\n",
      "Epoch 5/60\n",
      "1407/1407 [==============================] - 322s 227ms/step - loss: 1.5213 - classification_loss: 0.3515 - branch_exit_loss: 0.5946 - branch_exit_1_loss: 0.5753 - classification_accuracy: 0.8841 - branch_exit_accuracy: 0.7952 - branch_exit_1_accuracy: 0.8038 - val_loss: 2.0864 - val_classification_loss: 0.5321 - val_branch_exit_loss: 0.8125 - val_branch_exit_1_loss: 0.7418 - val_classification_accuracy: 0.8256 - val_branch_exit_accuracy: 0.7338 - val_branch_exit_1_accuracy: 0.7484\n",
      "annealing coef updated to: 0.04\n",
      "Epoch 6/60\n",
      "1407/1407 [==============================] - 325s 229ms/step - loss: 1.3012 - classification_loss: 0.2788 - branch_exit_loss: 0.5194 - branch_exit_1_loss: 0.5029 - classification_accuracy: 0.9063 - branch_exit_accuracy: 0.8178 - branch_exit_1_accuracy: 0.8290 - val_loss: 1.5392 - val_classification_loss: 0.3604 - val_branch_exit_loss: 0.5876 - val_branch_exit_1_loss: 0.5912 - val_classification_accuracy: 0.8832 - val_branch_exit_accuracy: 0.7990 - val_branch_exit_1_accuracy: 0.8056\n",
      "annealing coef updated to: 0.05\n",
      "Epoch 7/60\n",
      "1407/1407 [==============================] - 328s 231ms/step - loss: 1.1301 - classification_loss: 0.2242 - branch_exit_loss: 0.4598 - branch_exit_1_loss: 0.4461 - classification_accuracy: 0.9239 - branch_exit_accuracy: 0.8427 - branch_exit_1_accuracy: 0.8501 - val_loss: 1.7341 - val_classification_loss: 0.4276 - val_branch_exit_loss: 0.6575 - val_branch_exit_1_loss: 0.6489 - val_classification_accuracy: 0.8684 - val_branch_exit_accuracy: 0.7902 - val_branch_exit_1_accuracy: 0.7932\n",
      "val acc did not improve from 1.604599952697754, annealing coef not updated, remains at:0.05000000074505806\n",
      "Epoch 8/60\n",
      "1407/1407 [==============================] - 330s 233ms/step - loss: 0.9940 - classification_loss: 0.1864 - branch_exit_loss: 0.4065 - branch_exit_1_loss: 0.4011 - classification_accuracy: 0.9380 - branch_exit_accuracy: 0.8622 - branch_exit_1_accuracy: 0.8643 - val_loss: 1.5401 - val_classification_loss: 0.3623 - val_branch_exit_loss: 0.5842 - val_branch_exit_1_loss: 0.5936 - val_classification_accuracy: 0.8860 - val_branch_exit_accuracy: 0.8134 - val_branch_exit_1_accuracy: 0.8112\n",
      "annealing coef updated to: 0.06\n",
      "Epoch 9/60\n",
      "1407/1407 [==============================] - 333s 234ms/step - loss: 0.8676 - classification_loss: 0.1554 - branch_exit_loss: 0.3594 - branch_exit_1_loss: 0.3528 - classification_accuracy: 0.9473 - branch_exit_accuracy: 0.8756 - branch_exit_1_accuracy: 0.8798 - val_loss: 1.7164 - val_classification_loss: 0.4854 - val_branch_exit_loss: 0.6227 - val_branch_exit_1_loss: 0.6082 - val_classification_accuracy: 0.8576 - val_branch_exit_accuracy: 0.7952 - val_branch_exit_1_accuracy: 0.8110\n",
      "val acc did not improve from 1.6245999336242676, annealing coef not updated, remains at:0.05999999865889549\n",
      "Epoch 10/60\n",
      "1407/1407 [==============================] - 331s 233ms/step - loss: 0.7605 - classification_loss: 0.1258 - branch_exit_loss: 0.3178 - branch_exit_1_loss: 0.3169 - classification_accuracy: 0.9569 - branch_exit_accuracy: 0.8905 - branch_exit_1_accuracy: 0.8926 - val_loss: 1.5938 - val_classification_loss: 0.4261 - val_branch_exit_loss: 0.6142 - val_branch_exit_1_loss: 0.5535 - val_classification_accuracy: 0.8790 - val_branch_exit_accuracy: 0.8084 - val_branch_exit_1_accuracy: 0.8284\n",
      "annealing coef updated to: 0.07\n",
      "Epoch 11/60\n",
      "1407/1407 [==============================] - 333s 234ms/step - loss: 0.6772 - classification_loss: 0.1130 - branch_exit_loss: 0.2806 - branch_exit_1_loss: 0.2836 - classification_accuracy: 0.9617 - branch_exit_accuracy: 0.9039 - branch_exit_1_accuracy: 0.9033 - val_loss: 1.4731 - val_classification_loss: 0.3843 - val_branch_exit_loss: 0.5654 - val_branch_exit_1_loss: 0.5234 - val_classification_accuracy: 0.8924 - val_branch_exit_accuracy: 0.8242 - val_branch_exit_1_accuracy: 0.8332\n",
      "annealing coef updated to: 0.08\n",
      "Epoch 12/60\n",
      "1407/1407 [==============================] - 329s 232ms/step - loss: 0.5820 - classification_loss: 0.0976 - branch_exit_loss: 0.2380 - branch_exit_1_loss: 0.2464 - classification_accuracy: 0.9677 - branch_exit_accuracy: 0.9195 - branch_exit_1_accuracy: 0.9173 - val_loss: 1.6907 - val_classification_loss: 0.4486 - val_branch_exit_loss: 0.6419 - val_branch_exit_1_loss: 0.6002 - val_classification_accuracy: 0.8790 - val_branch_exit_accuracy: 0.8084 - val_branch_exit_1_accuracy: 0.8232\n",
      "val acc did not improve from 1.6573998928070068, annealing coef not updated, remains at:0.07999999821186066\n",
      "Epoch 13/60\n",
      "1407/1407 [==============================] - 353s 249ms/step - loss: 0.5317 - classification_loss: 0.0842 - branch_exit_loss: 0.2168 - branch_exit_1_loss: 0.2308 - classification_accuracy: 0.9719 - branch_exit_accuracy: 0.9268 - branch_exit_1_accuracy: 0.9227 - val_loss: 1.5776 - val_classification_loss: 0.3706 - val_branch_exit_loss: 0.6498 - val_branch_exit_1_loss: 0.5572 - val_classification_accuracy: 0.8998 - val_branch_exit_accuracy: 0.8204 - val_branch_exit_1_accuracy: 0.8430\n",
      "annealing coef updated to: 0.09\n",
      "Epoch 14/60\n",
      "1407/1407 [==============================] - 370s 261ms/step - loss: 0.4827 - classification_loss: 0.0756 - branch_exit_loss: 0.2003 - branch_exit_1_loss: 0.2068 - classification_accuracy: 0.9749 - branch_exit_accuracy: 0.9328 - branch_exit_1_accuracy: 0.9312 - val_loss: 1.5938 - val_classification_loss: 0.4008 - val_branch_exit_loss: 0.5908 - val_branch_exit_1_loss: 0.6021 - val_classification_accuracy: 0.8974 - val_branch_exit_accuracy: 0.8284 - val_branch_exit_1_accuracy: 0.8356\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 15/60\n",
      "1407/1407 [==============================] - 384s 271ms/step - loss: 0.4395 - classification_loss: 0.0706 - branch_exit_loss: 0.1800 - branch_exit_1_loss: 0.1889 - classification_accuracy: 0.9763 - branch_exit_accuracy: 0.9402 - branch_exit_1_accuracy: 0.9380 - val_loss: 1.6423 - val_classification_loss: 0.4108 - val_branch_exit_loss: 0.6423 - val_branch_exit_1_loss: 0.5893 - val_classification_accuracy: 0.8996 - val_branch_exit_accuracy: 0.8172 - val_branch_exit_1_accuracy: 0.8392\n",
      "val acc did not improve from 1.6640000343322754, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 16/60\n",
      "1407/1407 [==============================] - 385s 271ms/step - loss: 0.3969 - classification_loss: 0.0587 - branch_exit_loss: 0.1682 - branch_exit_1_loss: 0.1700 - classification_accuracy: 0.9802 - branch_exit_accuracy: 0.9446 - branch_exit_1_accuracy: 0.9445 - val_loss: 1.8067 - val_classification_loss: 0.4005 - val_branch_exit_loss: 0.7741 - val_branch_exit_1_loss: 0.6321 - val_classification_accuracy: 0.8988 - val_branch_exit_accuracy: 0.8048 - val_branch_exit_1_accuracy: 0.8368\n",
      "val acc did not improve from 1.6640000343322754, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 17/60\n",
      "1407/1407 [==============================] - 373s 263ms/step - loss: 0.3707 - classification_loss: 0.0612 - branch_exit_loss: 0.1509 - branch_exit_1_loss: 0.1586 - classification_accuracy: 0.9802 - branch_exit_accuracy: 0.9503 - branch_exit_1_accuracy: 0.9484 - val_loss: 1.8793 - val_classification_loss: 0.4756 - val_branch_exit_loss: 0.7969 - val_branch_exit_1_loss: 0.6068 - val_classification_accuracy: 0.8846 - val_branch_exit_accuracy: 0.8174 - val_branch_exit_1_accuracy: 0.8402\n",
      "val acc did not improve from 1.6640000343322754, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 18/60\n",
      "1407/1407 [==============================] - 382s 269ms/step - loss: 0.3470 - classification_loss: 0.0559 - branch_exit_loss: 0.1467 - branch_exit_1_loss: 0.1445 - classification_accuracy: 0.9816 - branch_exit_accuracy: 0.9520 - branch_exit_1_accuracy: 0.9533 - val_loss: 1.7208 - val_classification_loss: 0.3822 - val_branch_exit_loss: 0.7379 - val_branch_exit_1_loss: 0.6007 - val_classification_accuracy: 0.9068 - val_branch_exit_accuracy: 0.8192 - val_branch_exit_1_accuracy: 0.8386\n",
      "val acc did not improve from 1.6640000343322754, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 19/60\n",
      "1407/1407 [==============================] - 394s 278ms/step - loss: 0.3061 - classification_loss: 0.0474 - branch_exit_loss: 0.1276 - branch_exit_1_loss: 0.1311 - classification_accuracy: 0.9841 - branch_exit_accuracy: 0.9580 - branch_exit_1_accuracy: 0.9577 - val_loss: 1.6503 - val_classification_loss: 0.4348 - val_branch_exit_loss: 0.6429 - val_branch_exit_1_loss: 0.5726 - val_classification_accuracy: 0.8980 - val_branch_exit_accuracy: 0.8412 - val_branch_exit_1_accuracy: 0.8536\n",
      "annealing coef updated to: 0.11\n",
      "Epoch 20/60\n",
      "1407/1407 [==============================] - 444s 313ms/step - loss: 0.2998 - classification_loss: 0.0497 - branch_exit_loss: 0.1207 - branch_exit_1_loss: 0.1294 - classification_accuracy: 0.9833 - branch_exit_accuracy: 0.9615 - branch_exit_1_accuracy: 0.9590 - val_loss: 1.8819 - val_classification_loss: 0.5306 - val_branch_exit_loss: 0.7249 - val_branch_exit_1_loss: 0.6264 - val_classification_accuracy: 0.8846 - val_branch_exit_accuracy: 0.8290 - val_branch_exit_1_accuracy: 0.8432\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 21/60\n",
      "1407/1407 [==============================] - 385s 271ms/step - loss: 0.2916 - classification_loss: 0.0453 - branch_exit_loss: 0.1232 - branch_exit_1_loss: 0.1231 - classification_accuracy: 0.9855 - branch_exit_accuracy: 0.9599 - branch_exit_1_accuracy: 0.9612 - val_loss: 1.7061 - val_classification_loss: 0.4235 - val_branch_exit_loss: 0.6679 - val_branch_exit_1_loss: 0.6146 - val_classification_accuracy: 0.8992 - val_branch_exit_accuracy: 0.8482 - val_branch_exit_1_accuracy: 0.8448\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 22/60\n",
      "1407/1407 [==============================] - 390s 275ms/step - loss: 0.2649 - classification_loss: 0.0410 - branch_exit_loss: 0.1119 - branch_exit_1_loss: 0.1120 - classification_accuracy: 0.9858 - branch_exit_accuracy: 0.9643 - branch_exit_1_accuracy: 0.9643 - val_loss: 1.8131 - val_classification_loss: 0.4287 - val_branch_exit_loss: 0.7556 - val_branch_exit_1_loss: 0.6289 - val_classification_accuracy: 0.9078 - val_branch_exit_accuracy: 0.8384 - val_branch_exit_1_accuracy: 0.8426\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 23/60\n",
      "1407/1407 [==============================] - 385s 272ms/step - loss: 0.2539 - classification_loss: 0.0409 - branch_exit_loss: 0.1034 - branch_exit_1_loss: 0.1096 - classification_accuracy: 0.9870 - branch_exit_accuracy: 0.9665 - branch_exit_1_accuracy: 0.9657 - val_loss: 1.7514 - val_classification_loss: 0.3902 - val_branch_exit_loss: 0.7645 - val_branch_exit_1_loss: 0.5967 - val_classification_accuracy: 0.9030 - val_branch_exit_accuracy: 0.8386 - val_branch_exit_1_accuracy: 0.8528\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 24/60\n",
      "1407/1407 [==============================] - 384s 271ms/step - loss: 0.2397 - classification_loss: 0.0369 - branch_exit_loss: 0.1033 - branch_exit_1_loss: 0.0995 - classification_accuracy: 0.9877 - branch_exit_accuracy: 0.9670 - branch_exit_1_accuracy: 0.9688 - val_loss: 1.9457 - val_classification_loss: 0.4915 - val_branch_exit_loss: 0.7436 - val_branch_exit_1_loss: 0.7106 - val_classification_accuracy: 0.8942 - val_branch_exit_accuracy: 0.8392 - val_branch_exit_1_accuracy: 0.8240\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 25/60\n",
      "1407/1407 [==============================] - 391s 275ms/step - loss: 0.2324 - classification_loss: 0.0387 - branch_exit_loss: 0.0942 - branch_exit_1_loss: 0.0995 - classification_accuracy: 0.9874 - branch_exit_accuracy: 0.9710 - branch_exit_1_accuracy: 0.9693 - val_loss: 1.9907 - val_classification_loss: 0.5613 - val_branch_exit_loss: 0.8073 - val_branch_exit_1_loss: 0.6222 - val_classification_accuracy: 0.8872 - val_branch_exit_accuracy: 0.8400 - val_branch_exit_1_accuracy: 0.8522\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 26/60\n",
      "1407/1407 [==============================] - 392s 276ms/step - loss: 0.2269 - classification_loss: 0.0378 - branch_exit_loss: 0.0960 - branch_exit_1_loss: 0.0932 - classification_accuracy: 0.9874 - branch_exit_accuracy: 0.9704 - branch_exit_1_accuracy: 0.9714 - val_loss: 1.8005 - val_classification_loss: 0.4081 - val_branch_exit_loss: 0.7379 - val_branch_exit_1_loss: 0.6546 - val_classification_accuracy: 0.9030 - val_branch_exit_accuracy: 0.8376 - val_branch_exit_1_accuracy: 0.8542\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 27/60\n",
      "1407/1407 [==============================] - 403s 284ms/step - loss: 0.2138 - classification_loss: 0.0319 - branch_exit_loss: 0.0885 - branch_exit_1_loss: 0.0933 - classification_accuracy: 0.9894 - branch_exit_accuracy: 0.9723 - branch_exit_1_accuracy: 0.9712 - val_loss: 1.9408 - val_classification_loss: 0.4048 - val_branch_exit_loss: 0.8587 - val_branch_exit_1_loss: 0.6773 - val_classification_accuracy: 0.9110 - val_branch_exit_accuracy: 0.8326 - val_branch_exit_1_accuracy: 0.8568\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 28/60\n",
      "1407/1407 [==============================] - 406s 286ms/step - loss: 0.2006 - classification_loss: 0.0350 - branch_exit_loss: 0.0817 - branch_exit_1_loss: 0.0840 - classification_accuracy: 0.9884 - branch_exit_accuracy: 0.9748 - branch_exit_1_accuracy: 0.9741 - val_loss: 2.0881 - val_classification_loss: 0.4501 - val_branch_exit_loss: 0.8403 - val_branch_exit_1_loss: 0.7978 - val_classification_accuracy: 0.9020 - val_branch_exit_accuracy: 0.8398 - val_branch_exit_1_accuracy: 0.8394\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 29/60\n",
      "1407/1407 [==============================] - 390s 275ms/step - loss: 0.2076 - classification_loss: 0.0348 - branch_exit_loss: 0.0824 - branch_exit_1_loss: 0.0904 - classification_accuracy: 0.9893 - branch_exit_accuracy: 0.9748 - branch_exit_1_accuracy: 0.9722 - val_loss: 1.9501 - val_classification_loss: 0.4543 - val_branch_exit_loss: 0.7762 - val_branch_exit_1_loss: 0.7195 - val_classification_accuracy: 0.8988 - val_branch_exit_accuracy: 0.8424 - val_branch_exit_1_accuracy: 0.8508\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 30/60\n",
      "1407/1407 [==============================] - 400s 282ms/step - loss: 0.1861 - classification_loss: 0.0284 - branch_exit_loss: 0.0822 - branch_exit_1_loss: 0.0755 - classification_accuracy: 0.9906 - branch_exit_accuracy: 0.9751 - branch_exit_1_accuracy: 0.9765 - val_loss: 1.9401 - val_classification_loss: 0.4326 - val_branch_exit_loss: 0.7320 - val_branch_exit_1_loss: 0.7755 - val_classification_accuracy: 0.9076 - val_branch_exit_accuracy: 0.8420 - val_branch_exit_1_accuracy: 0.8480\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 31/60\n",
      "1407/1407 [==============================] - 411s 289ms/step - loss: 0.1877 - classification_loss: 0.0316 - branch_exit_loss: 0.0746 - branch_exit_1_loss: 0.0815 - classification_accuracy: 0.9897 - branch_exit_accuracy: 0.9765 - branch_exit_1_accuracy: 0.9753 - val_loss: 2.0033 - val_classification_loss: 0.4457 - val_branch_exit_loss: 0.7935 - val_branch_exit_1_loss: 0.7641 - val_classification_accuracy: 0.9008 - val_branch_exit_accuracy: 0.8412 - val_branch_exit_1_accuracy: 0.8374\n",
      "val acc did not improve from 1.6948000192642212, annealing coef not updated, remains at:0.10999999940395355\n",
      "Epoch 32/60\n",
      "1407/1407 [==============================] - 408s 286ms/step - loss: 0.1901 - classification_loss: 0.0316 - branch_exit_loss: 0.0739 - branch_exit_1_loss: 0.0845 - classification_accuracy: 0.9900 - branch_exit_accuracy: 0.9772 - branch_exit_1_accuracy: 0.9743 - val_loss: 1.9233 - val_classification_loss: 0.4103 - val_branch_exit_loss: 0.8279 - val_branch_exit_1_loss: 0.6852 - val_classification_accuracy: 0.9108 - val_branch_exit_accuracy: 0.8306 - val_branch_exit_1_accuracy: 0.8554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x243e7d05b88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 60, validation_data=validation_ds, transfer=False,callbacks=[growth_callback, earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70da2f92-dc0e-4252-9120-b1104f62dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/journal_models/inception_EDL_ES_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3eb4993f-e2eb-4a73-b959-99c457eda3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  mixed0\n",
      "add Branch to branch point  mixed1\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n",
      "branch added <brevis.core_v2.BranchModel object at 0x0000015D1D6B2E48>\n",
      "Freezing Main Layers and setting branch layers training to true\n",
      "\n",
      "preset: Other\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "growth_callback = growth_update(50,0.,max_t = 0.1, starting_epoch =0)\n",
    "\n",
    "auxlossMetric = auxLoss(growth_callback)\n",
    "branch_loss = loss_wrapper(growth_callback)\n",
    "\n",
    "\n",
    "# branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# lambda_callback = lambda_update(1000,0,max_t = 0.01)\n",
    "# branch_loss = brevisEnergy(lambda_callback)\n",
    "# branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "# trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# loss = kl_loss(lambda_callback)\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "\n",
    "model = brevis.BranchModel(name=\"./inception_finetuned.hdf5\", custom_objects={})\n",
    "# model.add_branches([_branch_flat,_branch_flat],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           target_input=False,loop=False,num_outputs=10)\n",
    "\n",
    "model.add_branches([_branch_conv2,_branch_conv2],\n",
    "                          [\"mixed0\",\"mixed1\",#\"mixed6\"\n",
    "                          ],\n",
    "                          target_input=False,loop=False,num_outputs=10)\n",
    "# model.compile(loss = [trunk_loss,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),metrics=['accuracy'])\n",
    "model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "                  optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  # optimizer = tf.optimizers.RMSprop(0.045),\n",
    "                  # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "              preset=\"\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e0a4a97-9a9d-4c13-9ed4-a24358085817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "annealing coef updated to: 0\n",
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 231s 153ms/step - loss: 1.1369 - classification_loss: 0.1178 - branch_exit_loss: 0.5099 - branch_exit_1_loss: 0.5091 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.6125 - branch_exit_1_accuracy: 0.6108 - val_loss: 1.0231 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4162 - val_branch_exit_1_loss: 0.4388 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7016 - val_branch_exit_1_accuracy: 0.6878\n",
      "annealing coef updated to: 0.02\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 200s 138ms/step - loss: 1.0239 - classification_loss: 0.1178 - branch_exit_loss: 0.4473 - branch_exit_1_loss: 0.4587 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7361 - branch_exit_1_accuracy: 0.7220 - val_loss: 1.0470 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4295 - val_branch_exit_1_loss: 0.4492 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7466 - val_branch_exit_1_accuracy: 0.7302\n",
      "annealing coef updated to: 0.04\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 199s 138ms/step - loss: 0.8654 - classification_loss: 0.1178 - branch_exit_loss: 0.3798 - branch_exit_1_loss: 0.3677 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7917 - branch_exit_1_accuracy: 0.7957 - val_loss: 0.9734 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4138 - val_branch_exit_1_loss: 0.3914 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7640 - val_branch_exit_1_accuracy: 0.7798\n",
      "annealing coef updated to: 0.06\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 198s 137ms/step - loss: 0.7859 - classification_loss: 0.1178 - branch_exit_loss: 0.3426 - branch_exit_1_loss: 0.3254 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8207 - branch_exit_1_accuracy: 0.8306 - val_loss: 1.0213 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4833 - val_branch_exit_1_loss: 0.3697 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7426 - val_branch_exit_1_accuracy: 0.8072\n",
      "annealing coef updated to: 0.08\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 199s 137ms/step - loss: 0.7218 - classification_loss: 0.1178 - branch_exit_loss: 0.3124 - branch_exit_1_loss: 0.2916 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8445 - branch_exit_1_accuracy: 0.8561 - val_loss: 1.0674 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4975 - val_branch_exit_1_loss: 0.4016 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7460 - val_branch_exit_1_accuracy: 0.7968\n",
      "val acc did not improve from 1.5498000383377075, annealing coef not updated, remains at:0.07999999821186066\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 198s 137ms/step - loss: 0.6389 - classification_loss: 0.1178 - branch_exit_loss: 0.2734 - branch_exit_1_loss: 0.2476 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8649 - branch_exit_1_accuracy: 0.8773 - val_loss: 1.0274 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4382 - val_branch_exit_1_loss: 0.4209 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7844 - val_branch_exit_1_accuracy: 0.7930\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 202s 140ms/step - loss: 0.5851 - classification_loss: 0.1178 - branch_exit_loss: 0.2424 - branch_exit_1_loss: 0.2248 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8848 - branch_exit_1_accuracy: 0.8952 - val_loss: 0.9826 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4274 - val_branch_exit_1_loss: 0.3870 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7970 - val_branch_exit_1_accuracy: 0.8180\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 202s 139ms/step - loss: 0.5206 - classification_loss: 0.1178 - branch_exit_loss: 0.2146 - branch_exit_1_loss: 0.1882 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9000 - branch_exit_1_accuracy: 0.9132 - val_loss: 0.9517 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3887 - val_branch_exit_1_loss: 0.3948 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8164 - val_branch_exit_1_accuracy: 0.8110\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 206s 142ms/step - loss: 0.4536 - classification_loss: 0.1178 - branch_exit_loss: 0.1757 - branch_exit_1_loss: 0.1600 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9177 - branch_exit_1_accuracy: 0.9267 - val_loss: 0.9644 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4020 - val_branch_exit_1_loss: 0.3942 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8118 - val_branch_exit_1_accuracy: 0.8114\n",
      "val acc did not improve from 1.6273999214172363, annealing coef not updated, remains at:0.10000000149011612\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 201s 139ms/step - loss: 0.4064 - classification_loss: 0.1178 - branch_exit_loss: 0.1509 - branch_exit_1_loss: 0.1376 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9312 - branch_exit_1_accuracy: 0.9379 - val_loss: 0.9037 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.3868 - val_branch_exit_1_loss: 0.3487 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8230 - val_branch_exit_1_accuracy: 0.8384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x15d186f0708>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 10, validation_data=validation_ds, transfer=True,callbacks=[growth_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e780564-61f5-4c80-8369-650f4c9c2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/journal_models/inception_Brevis_10_frozen.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf155ab-f92b-43b4-bc0e-10e1310fa8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "Freezing Main Layers and setting branch layers training to true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "growth_callback = growth_update(10,1.,max_t = 1., starting_epoch =0)\n",
    "\n",
    "auxlossMetric = auxLoss(growth_callback)\n",
    "branch_loss = loss_wrapper(growth_callback)\n",
    "\n",
    "\n",
    "# branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "\n",
    "# model = brevis.BranchModel(name=\"./inception_finetuned.hdf5\", custom_objects={})\n",
    "model = tf.keras.models.load_model(\"./models/journal_models/inception_CE_15_adam.hdf5\",custom_objects={\"BranchModel\":brevis.BranchModel,\"custom_loss_function\":loss_wrapper(growth_callback)})\n",
    "# model.compile(loss = [trunk_loss,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),metrics=['accuracy'])\n",
    "model.setTrainable(True)\n",
    "model.compile(loss=[trunk_loss,trunk_loss,trunk_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.05, momentum=0.9),\n",
    "                  # optimizer = tf.optimizers.RMSprop(0.045),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "             metrics=['accuracy'])\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6229ca1-c0be-4d58-8ebf-732b83308fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "annealing coef updated to: 0.1\n",
      "Epoch 1/6\n",
      "   6/1407 [..............................] - ETA: 2:03 - loss: 0.3015 - classification_loss: 0.1001 - branch_exit_loss: 0.0775 - branch_exit_1_loss: 0.1239 - classification_accuracy: 0.9583 - branch_exit_accuracy: 0.9688 - branch_exit_1_accuracy: 0.9427WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0792s vs `on_train_batch_end` time: 0.0796s). Check your callbacks.\n",
      "1407/1407 [==============================] - 140s 92ms/step - loss: 1.2460 - classification_loss: 0.1178 - branch_exit_loss: 0.6271 - branch_exit_1_loss: 0.5011 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.6972 - branch_exit_1_accuracy: 0.7469 - val_loss: 1.2377 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.5433 - val_branch_exit_1_loss: 0.5261 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7282 - val_branch_exit_1_accuracy: 0.7404\n",
      "annealing coef updated to: 0.2\n",
      "Epoch 2/6\n",
      "1407/1407 [==============================] - 132s 92ms/step - loss: 1.1089 - classification_loss: 0.1178 - branch_exit_loss: 0.5165 - branch_exit_1_loss: 0.4746 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7704 - branch_exit_1_accuracy: 0.7909 - val_loss: 1.5176 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.6510 - val_branch_exit_1_loss: 0.6984 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7110 - val_branch_exit_1_accuracy: 0.6854\n",
      "val acc did not improve from 1.4686000347137451, annealing coef not updated, remains at:0.20000000298023224\n",
      "Epoch 3/6\n",
      "1407/1407 [==============================] - 133s 92ms/step - loss: 1.0028 - classification_loss: 0.1178 - branch_exit_loss: 0.4633 - branch_exit_1_loss: 0.4216 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7936 - branch_exit_1_accuracy: 0.8184 - val_loss: 1.2122 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.5300 - val_branch_exit_1_loss: 0.5140 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7698 - val_branch_exit_1_accuracy: 0.7762\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 4/6\n",
      "1407/1407 [==============================] - 133s 93ms/step - loss: 1.0818 - classification_loss: 0.1178 - branch_exit_loss: 0.5034 - branch_exit_1_loss: 0.4606 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7922 - branch_exit_1_accuracy: 0.8132 - val_loss: 1.4193 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.6716 - val_branch_exit_1_loss: 0.5795 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7044 - val_branch_exit_1_accuracy: 0.7522\n",
      "val acc did not improve from 1.5460000038146973, annealing coef not updated, remains at:0.30000001192092896\n",
      "Epoch 5/6\n",
      "1407/1407 [==============================] - 134s 93ms/step - loss: 1.0613 - classification_loss: 0.1178 - branch_exit_loss: 0.4897 - branch_exit_1_loss: 0.4538 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.7972 - branch_exit_1_accuracy: 0.8182 - val_loss: 1.3223 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.5803 - val_branch_exit_1_loss: 0.5738 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7592 - val_branch_exit_1_accuracy: 0.7640\n",
      "val acc did not improve from 1.5460000038146973, annealing coef not updated, remains at:0.30000001192092896\n",
      "Epoch 6/6\n",
      "1407/1407 [==============================] - 135s 94ms/step - loss: 1.0592 - classification_loss: 0.1178 - branch_exit_loss: 0.4894 - branch_exit_1_loss: 0.4519 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8012 - branch_exit_1_accuracy: 0.8220 - val_loss: 1.3227 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.5911 - val_branch_exit_1_loss: 0.5634 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.7492 - val_branch_exit_1_accuracy: 0.7726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x1fad7b331c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 6, validation_data=validation_ds, transfer=True,callbacks=[growth_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "491dc4a3-5e0b-4b97-b450-8247478ca402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preset: Other\n"
     ]
    }
   ],
   "source": [
    "growth_callback = growth_update(10,3.,max_t = .3, starting_epoch =0)\n",
    "\n",
    "auxlossMetric = auxLoss(growth_callback)\n",
    "branch_loss = loss_wrapper(growth_callback)\n",
    "\n",
    "model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "                  optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  # optimizer = tf.optimizers.RMSprop(0.045),\n",
    "                  # optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,  beta_1=0.99,  beta_2=0.999,),\n",
    "              preset=\"\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1acff5c5-af45-406c-97ce-660194a8aaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 1/6\n",
      "1407/1407 [==============================] - 147s 98ms/step - loss: 0.8075 - classification_loss: 0.1178 - branch_exit_loss: 0.3659 - branch_exit_1_loss: 0.3238 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8489 - branch_exit_1_accuracy: 0.8731 - val_loss: 1.0398 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4393 - val_branch_exit_1_loss: 0.4323 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8252 - val_branch_exit_1_accuracy: 0.8306\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 2/6\n",
      "1407/1407 [==============================] - 136s 95ms/step - loss: 0.6640 - classification_loss: 0.1178 - branch_exit_loss: 0.2906 - branch_exit_1_loss: 0.2556 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8791 - branch_exit_1_accuracy: 0.8958 - val_loss: 1.0227 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4425 - val_branch_exit_1_loss: 0.4119 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8272 - val_branch_exit_1_accuracy: 0.8420\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 3/6\n",
      "1407/1407 [==============================] - 138s 96ms/step - loss: 0.5860 - classification_loss: 0.1178 - branch_exit_loss: 0.2524 - branch_exit_1_loss: 0.2158 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.8930 - branch_exit_1_accuracy: 0.9111 - val_loss: 1.0101 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4374 - val_branch_exit_1_loss: 0.4045 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8330 - val_branch_exit_1_accuracy: 0.8434\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 4/6\n",
      "1407/1407 [==============================] - 139s 96ms/step - loss: 0.5232 - classification_loss: 0.1178 - branch_exit_loss: 0.2181 - branch_exit_1_loss: 0.1873 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9050 - branch_exit_1_accuracy: 0.9219 - val_loss: 1.0387 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4512 - val_branch_exit_1_loss: 0.4193 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8340 - val_branch_exit_1_accuracy: 0.8510\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 5/6\n",
      "1407/1407 [==============================] - 140s 97ms/step - loss: 0.4802 - classification_loss: 0.1178 - branch_exit_loss: 0.1958 - branch_exit_1_loss: 0.1665 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9140 - branch_exit_1_accuracy: 0.9292 - val_loss: 1.0238 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4477 - val_branch_exit_1_loss: 0.4079 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8336 - val_branch_exit_1_accuracy: 0.8522\n",
      "annealing coef updated to: 0.3\n",
      "Epoch 6/6\n",
      "1407/1407 [==============================] - 142s 99ms/step - loss: 0.4452 - classification_loss: 0.1178 - branch_exit_loss: 0.1758 - branch_exit_1_loss: 0.1516 - classification_accuracy: 0.9638 - branch_exit_accuracy: 0.9218 - branch_exit_1_accuracy: 0.9338 - val_loss: 1.0368 - val_classification_loss: 0.1682 - val_branch_exit_loss: 0.4594 - val_branch_exit_1_loss: 0.4092 - val_classification_accuracy: 0.9442 - val_branch_exit_accuracy: 0.8396 - val_branch_exit_1_accuracy: 0.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x1fad7b331c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 6, validation_data=validation_ds, transfer=True,callbacks=[growth_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc9ec73-de75-4874-887a-a8eb6aed436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 19s 59ms/step - loss: 1.1192 - classification_loss: 0.1892 - branch_exit_loss: 0.4793 - branch_exit_1_loss: 0.4507 - classification_accuracy: 0.9394 - branch_exit_accuracy: 0.8328 - branch_exit_1_accuracy: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1191997528076172,\n",
       " 0.1891820728778839,\n",
       " 0.4793119728565216,\n",
       " 0.45070552825927734,\n",
       " 0.9394000172615051,\n",
       " 0.8327999711036682,\n",
       " 0.8504999876022339]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0534226a-d0de-4130-9589-bcb9616771ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/journal_models/inception_brevis_final.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aeb9ae29-2041-4cfd-86c7-4c9adbf0f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _branch_flat(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    \n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "    branchLayer = layers.Dense(1024, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch1024\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch512\"))(branchLayer)\n",
    "    # output = branch.CrossEntropyEndpoint(targets.shape[-1], name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(branchLayer, targets)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "def _branch_conv1(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=64, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(2,2), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output\n",
    "\n",
    "def _branch_conv2(prevLayer, targets=None, teacher_sm = None, teaching_features=None):\n",
    "    \"\"\" Add a new branch to a model connecting at the output of prevLayer. \n",
    "        NOTE: use the substring \"branch\" in all names for branch nodes. this is used as an identifier of the branching layers as opposed to the main branch layers for training\n",
    "    \"\"\" \n",
    "#     branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(prevLayer)\n",
    "#     branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "#     branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "#     output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(prevLayer.shape))(prevLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.Conv2D(filters=128, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)  \n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Conv2D(filters=512, kernel_size=(1,1), strides=(1,1), activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_conv2d\"), input_shape=(branchLayer.shape))(branchLayer)\n",
    "    branchLayer = keras.layers.BatchNormalization(name=tf.compat.v1.get_default_graph().unique_name(\"branch_batchnorm\"))(branchLayer)\n",
    "    branchLayer = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2),name=tf.compat.v1.get_default_graph().unique_name(\"branch_maxpool\"))(branchLayer)\n",
    "    # branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(1024,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    branchLayer = keras.layers.Dropout(0.2,name=tf.compat.v1.get_default_graph().unique_name(\"branch_dropout\"))(branchLayer)\n",
    "    branchLayer = layers.Dense(512,activation='relu',name=tf.compat.v1.get_default_graph().unique_name(\"branch_dense\"))(branchLayer)\n",
    "    output = keras.layers.Dense(10, name=tf.compat.v1.get_default_graph().unique_name(\"branch_exit\"))(branchLayer)\n",
    "    # output = (layers.Softmax(name=tf.compat.v1.get_default_graph().unique_name(\"branch_softmax\"))(output))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0e9b8b9-6197-4f51-a094-30006d951550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  conv2_block1_out\n",
      "add Branch to branch point  conv2_block3_out\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\")\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_4')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_5')>]\n",
      "branch added <brevis.core_v2.BranchModel object at 0x00000156AB073C48>\n",
      "Freezing Main Layers and setting branch layers training to true\n",
      "\n",
      "preset: Other\n"
     ]
    }
   ],
   "source": [
    "\n",
    "growth_callback = growth_update(50,0.,max_t = 0.1, starting_epoch =0)\n",
    "\n",
    "auxlossMetric = auxLoss(growth_callback)\n",
    "branch_loss = loss_wrapper(growth_callback)\n",
    "\n",
    "\n",
    "# branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# loss = kl_loss(lambda_callback)\n",
    "# earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "model = brevis.BranchModel(name=\"./models/journal_models/resnet_CE_entropy_finetuned.hdf5\", custom_objects={})\n",
    "# model.add_branches([_branch_flat,_branch_flat],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           target_input=False,loop=False,num_outputs=10)\n",
    "\n",
    "model.add_branches([_branch_conv2,_branch_conv2],\n",
    "                          [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "                          ],\n",
    "                          target_input=False,loop=False,num_outputs=10)\n",
    "# model.compile(loss = [trunk_loss,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),metrics=['accuracy'])\n",
    "model.setTrainable(True)\n",
    "\n",
    "model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "                  optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  # optimizer=\"adam\",\n",
    "              preset=\"\", metrics=['accuracy',auxlossMetric])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afac18f9-dd8c-42c1-bd1a-009f7179ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/journal_models/Inception_EDL_IAR_e15.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72b6d23-c073-4dad-a686-ef826811a7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06f2554a-6113-4d4c-b97e-28d84b9baf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "preset: Other\n",
      "313/313 [==============================] - 18s 52ms/step - loss: 0.1502 - accuracy: 0.9585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15015941858291626, 0.9585000276565552]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = brevis.BranchModel(name=\"./models/inception_finetuned.hdf5\", custom_objects={})\n",
    "# flops = get_flops(model, batch_size=1)\n",
    "# print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "model.compile(loss=[trunk_loss], \n",
    "                  # optimizer=tf.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "                  optimizer=\"adam\",\n",
    "              preset=\"\", metrics=['accuracy'])\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66079fab-1678-4cdf-a0eb-205134d9cf9f",
   "metadata": {},
   "source": [
    "## Get the flop cost for each branch output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c80a30e9-6f63-497e-95b2-e310d177e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>]\n",
      "WARNING:tensorflow:From C:\\Users\\Sanity\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOPS: 1.89 G\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n",
      "FLOPS: 2.35 G\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>]\n",
      "FLOPS: 5.92 G\n"
     ]
    }
   ],
   "source": [
    "outputs = [ [model.get_layer(\"branch_exit\").get_output_at(0)],\n",
    "            [model.get_layer(\"branch_exit\").get_output_at(0),model.get_layer(\"branch_exit_1\").get_output_at(0)],\n",
    "            [model.get_layer(\"branch_exit\").get_output_at(0),model.get_layer(\"branch_exit_1\").get_output_at(0),model.get_layer(\"classification\").get_output_at(0)]\n",
    "          ]\n",
    "from keras_flops import get_flops    \n",
    "for _outputs in outputs:\n",
    "    temp_model = tf.keras.models.Model(inputs=model.inputs, outputs=_outputs)\n",
    "    # Calculae FLOPS\n",
    "    print(temp_model.outputs)\n",
    "    flops = get_flops(temp_model, batch_size=1)\n",
    "    print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba40d975-173c-446f-a13e-c583cfe132c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "lambda_callback = lambda_update(100,0,max_t = 0.01)\n",
    "model = tf.keras.models.load_model(\"./models/journal_models/inception_CE_15_adam.hdf5\",custom_objects={\"BranchModel\":brevis.BranchModel,\"custom_loss_function\":loss_wrapper(lambda_callback)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3884ded-7fa7-4313-96a6-078f26940860",
   "metadata": {},
   "source": [
    "## Get the Branch output results\n",
    "Collect the branch output results for both the ID and OOD test sets then evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d86afcd6-a024-4071-885e-f3aef2da79cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 3\n",
      "['entropy']\n",
      "prediction: 312 of 313\r"
     ]
    }
   ],
   "source": [
    "output_ID= evaluate.getPredictions_Energy(model, test_ds,  values =['entropy'], stopping_point=None)\n",
    "for i in output_ID:\n",
    "    i['outlier']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46de421d-ec98-42e5-87a6-3b21269cf745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs 3\n",
      "['entropy']\n",
      "prediction: 312 of 313\r"
     ]
    }
   ],
   "source": [
    "output_OOD = evaluate.getPredictions_Energy(model, test_ds100,  values =['entropy'], stopping_point=None)\n",
    "for i in output_OOD:\n",
    "    i['correct']=0\n",
    "    i['outlier']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abea903a-0d06-4f18-8272-34245f2c77d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_OOD_svhn = getPredictions_Energy(model, test_ds_svhn,stopping_point=313)\n",
    "# output_OOD_svhn['correct']=0\n",
    "# output_OOD_svhn['outlier']=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dafe9be9-40e2-403f-807e-8e8abe47973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateOOD(ID,OOD,metrics=[\"energy\"], threshold=None, exit=-1, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True,plot=True,exit_labels=['exit_1']):\n",
    "    '''\n",
    "    Build an evaluation plot of the branched model's performance on ID and OOD datasets.\n",
    "\n",
    "    ::Variables::\n",
    "    ID: in-distribution dataset\n",
    "    OOD: out of distribution dataset\n",
    "    metrics: list of strings of metrics to evaluate branch results with. can be any of the following: [\"gmean\", \"mean\", \"PR_AUC\"]\n",
    "    exit: #if a specific exit number is specified, only output the results of that exit. counts from 0 - N, with 0 being the main exit. -1 returns all exits\n",
    "    legend: specify a legend to use for the plot\n",
    "    main_exit_included: specify if the last exit must answer all inputs recieved, if False, it will use the threshold to accept and reject inputs\n",
    "    plot: choose to produce a plot or just the table of branch results\n",
    "    exit_labels: what labels to use for the exits, defaults to \"exit_N\" \n",
    "    '''\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    if type(metrics) is not list:\n",
    "        metrics = [metrics]\n",
    "    for j, metric in enumerate(metrics):\n",
    "        print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "        rollOver_ID_indices = pd.Index([])\n",
    "        rollOver_OOD_indices = pd.Index([])\n",
    "        Exit_Name=[]\n",
    "        _ID = ID.copy()\n",
    "        _OOD = OOD.copy()\n",
    "        _ID.append(_ID.pop(0))\n",
    "        _OOD.append(_OOD.pop(0))\n",
    "        Accepted_df = pd.DataFrame()\n",
    "        Input_ID=[]\n",
    "        Input_OOD=[]\n",
    "        Accepted_list =[]\n",
    "        Accepted_ID_list = []\n",
    "        Accepted_OOD_list = []\n",
    "        Acceptance_correct =[]\n",
    "        Input_predictions =[]\n",
    "        Accepted_Ratio_list=[]\n",
    "        Accepted_Accuracy_list=[]\n",
    "        Branch_flops = []\n",
    "        Thresholds=[]\n",
    "        Test_accuracy =[]\n",
    "        Rollover_accuracy=[]\n",
    "        Results=[]\n",
    "        \n",
    "        if exit > 0: #if a specific exit number is specified, only output the results of that exit.\n",
    "            _ID = [_ID[max(exit-1,0)]]\n",
    "            _OOD = [_OOD[max(exit-1,0)]]\n",
    "            exit_labels=['exit_{}'.format(exit)]\n",
    "        for i, (output_ID, output_OOD) in enumerate(zip(_ID, _OOD)): \n",
    "            Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "            if threshold:\n",
    "                if type(threshold) is list:\n",
    "                    if i >= len(threshold): #no threshold in the array so treat as None.\n",
    "                        continue\n",
    "                    _threshold = threshold[i]\n",
    "                    print(\"threshold\",_threshold)\n",
    "                else:\n",
    "                    _threshold = threshold\n",
    "                if _threshold == \"mean\":\n",
    "                    Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                    _threshold = np.array(Correct[metric]).mean()\n",
    "                if _threshold == \"gmean\":\n",
    "                    AUC_thresholds = evaluate.calc_AUC(output_ID, metrics=metric, plot = False)\n",
    "                    _threshold = AUC_thresholds[j]\n",
    "                if _threshold == \"PR_AUC\":\n",
    "                    precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                    _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                else:\n",
    "                    _threshold = np.float32(_threshold)\n",
    "\n",
    "            if len(rollOver_ID_indices)>0:\n",
    "                # print(\"rollover enabled, {} ID predictions provided\".format(len(rollOver_ID_indices)))\n",
    "                output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "            if len(rollOver_OOD_indices)>0:\n",
    "                # if plot:\n",
    "                # print(\"rollover enabled, {} OOD predictions provided\".format(len(rollOver_OOD_indices)))\n",
    "                output_OOD = output_OOD.iloc[rollOver_OOD_indices]\n",
    "            \n",
    "            legend = [\"Branch Threshold\",\"Correct ID Predictions\",\"Incorrect ID Predictions\", \"OOD Inputs\"]\n",
    "            Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "            Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "            if plot:\n",
    "                \n",
    "                _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                _ = plt.hist(output_OOD[metric].tolist(), bins=100,color=\"grey\",alpha=0.5)  # arguments are passed to np.histogram\n",
    "\n",
    "            if plot:\n",
    "                plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                plt.title(metric.capitalize() + \" Outliers\", weight=\"bold\")\n",
    "                # plt.legend(legend)\n",
    "                plt.xlabel(metric.capitalize() + \" Score\", weight=\"bold\")\n",
    "                plt.ylabel(\"Frequency\", weight=\"bold\")\n",
    "                plt.legend(legend,frameon=True)\n",
    "                \n",
    "                ## arrow annotation\n",
    "                if lessThanMetrics:\n",
    "                    ymax = plt.gca().get_ylim()\n",
    "                    xmax = plt.gca().get_xlim()\n",
    "                    ywidth = abs(ymax[0] - ymax[1])\n",
    "                    xwidth = abs(xmax[0] - xmax[1])\n",
    "                    print(ymax, ywidth)\n",
    "                    print(xmax, _threshold- xmax[1]/10 )\n",
    "                    \n",
    "                    plt.text(max(_threshold- xwidth/4,xmax[0]) , (ywidth/1.5) + ywidth/60 ,\"Accepted Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold - xwidth/4, ywidth/1.5), xytext=(_threshold, ywidth/1.5), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                    plt.text(min(_threshold + xwidth/80,xmax[1]), (ywidth/2)+ ywidth/60,\"Rejected Inputs\",wrap=True)\n",
    "                    plt.annotate(\"\", xy=(_threshold + xwidth/4, ywidth/2), xytext=(_threshold, ywidth/2),  arrowprops=dict(arrowstyle=\"->\"))\n",
    "                else:\n",
    "                    plt.annotate(\"\", xy=(_threshold, 100), xytext=(_threshold, 0), arrowprops=dict(arrowstyle=\"->\"))\n",
    "                    \n",
    "                plt.show()\n",
    "            if main_exit_included and i == len(_ID)-1 :\n",
    "                Exit_Name.append(\"Main_exit\")\n",
    "                _threshold\n",
    "                if plot:\n",
    "                    print(\"main_exit\")\n",
    "                OOD_accepted = output_OOD\n",
    "                OOD_rejected = None\n",
    "                ID_accepted = output_ID\n",
    "                ID_rejected = None\n",
    "                accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                rejected_correct = None\n",
    "                accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                rejected_incorrect = None\n",
    "                accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                _threshold = \"NA\"\n",
    "            else:\n",
    "                if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() <= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() > _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                else: ### metrics that require greater than metric\n",
    "                    OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() >= _threshold)] #FP\n",
    "                    OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() < _threshold)] #TN\n",
    "                    ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                    ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                    accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                    rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "                    accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                    rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "                    accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                    overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                rollOver_ID_indices = ID_rejected.index\n",
    "                rollOver_OOD_indices = OOD_rejected.index\n",
    "                if i >= len(exit_labels):\n",
    "                    exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                print(exit_labels)\n",
    "                Exit_Name.append(exit_labels[i])\n",
    "            Thresholds.append(_threshold)\n",
    "            \n",
    "            Results.append(accepted_correct + accepted_incorrect)\n",
    "            Input_ID.append(len(output_ID))\n",
    "            Input_OOD.append(len(output_OOD))\n",
    "            Accepted_ID_list.append(len(ID_accepted))\n",
    "            Accepted_OOD_list.append(len(OOD_accepted))\n",
    "            Accepted_Ratio_list.append(len(ID_accepted)/(len(ID_accepted) + len(OOD_accepted)))\n",
    "            Acceptance_correct.append(len(accepted_correct))\n",
    "            Accepted_Accuracy_list.append(overall_accepted_acc)\n",
    "        df = pd.DataFrame({\n",
    "        \"Exit_Name\":Exit_Name,\n",
    "        \"ID_Inputs\":Input_ID,\n",
    "        \"OOD_Inputs\":Input_OOD,\n",
    "        \"Test_Accuracy\":Test_accuracy,\n",
    "        # \"RollOver_Accuracy\":Rollover_accuracy,\n",
    "        \"Threshold\":Thresholds,\n",
    "        \"Accepted ID\":Accepted_ID_list,\n",
    "        \"Accepted OOD\":Accepted_OOD_list,\n",
    "            \n",
    "        \"Accepted_Correct\":Acceptance_correct,\n",
    "        \"Accepted_ID_Ratio\":Accepted_Ratio_list,\n",
    "        \"Acceptance_Accuracy\":Accepted_Accuracy_list,\n",
    "\n",
    "        # \"Flops\":Branch_flops,\n",
    "        # \"Cost Ratio\":,                                  \n",
    "                        })\n",
    "        with pd.option_context('expand_frame_repr', False):\n",
    "            print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00ba9a-3de1-4176-ae5c-a6171f093adf",
   "metadata": {},
   "source": [
    "### T/F in distribution performance\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9838d3e-5420-4074-ba69-c51af86e4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "['exit_1']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8246  0.014288         6246          1870              6033           0.769591             0.743346\n",
      "1     exit_2       3754        8130         0.8448   0.04645         1360          1295              1194           0.512241             0.449718\n",
      "2  Main_exit       2394        6835         0.8996        NA         2394          6835              1740           0.259400             0.188536\n"
     ]
    }
   ],
   "source": [
    "# CE early stopping\n",
    "EvaluateOOD(output_ID, output_OOD, [\"entropy\"], \"gmean\",plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a7032b-4143-4bd8-9858-241364af3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  energy threshold:  gmean\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'energy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'energy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2856/902358390.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# EDL frozen, 15epochs no kl or info_reg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mEvaluateOOD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_OOD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"energy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gmean\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2856/4273641987.py\u001b[0m in \u001b[0;36mEvaluateOOD\u001b[1;34m(ID, OOD, metrics, threshold, exit, legend, main_exit_included, plot, exit_labels)\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0m_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCorrect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_threshold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gmean\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                     \u001b[0mAUC_thresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_AUC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_ID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                     \u001b[0m_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAUC_thresholds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_threshold\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"PR_AUC\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MachineLearning\\Keras_branchynet\\brevis\\evaluate\\evaluate.py\u001b[0m in \u001b[0;36mcalc_AUC\u001b[1;34m(output_df, metrics, plot, pos_label)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# print(\"metric\", metric)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mlr_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlessThanMetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mpos_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3457\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3458\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3459\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'energy'"
     ]
    }
   ],
   "source": [
    "# EDL frozen, 15epochs no kl or info_reg\n",
    "EvaluateOOD(output_ID, output_OOD, [\"entropy\"], \"gmean\",plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e53f485-a669-4d3e-a903-b61e62fa41aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  energy threshold:  gmean\n",
      "m energy\n",
      "metric energy\n",
      "energy  lr_auc 0.15123779708403612 Best Threshold=-81.88243865966797, G-Mean=0.773923409926957, TPR=0.8205285802089736, FPR=0.2700346351367491\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1']\n",
      "m energy\n",
      "metric energy\n",
      "energy  lr_auc 0.14366578647296668 Best Threshold=-79.849853515625, G-Mean=0.7847462473127419, TPR=0.8188539741219963, FPR=0.24794079025904261\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "m energy\n",
      "metric energy\n",
      "energy  lr_auc 0.07529892333495643 Best Threshold=-2.4509100914001465, G-Mean=0.8572885706881755, TPR=0.8729372937293729, FPR=0.15807962529274006\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAApoElEQVR4nO3de3xU5bX/8U8iglAughfaI1IK2CV66oXUqggaEfWAVerlKHikovUgBz0CogURhXqtipdK5aJoabVWRPCGUPyJRTmCoCkUacdFFREUpYAGxBCEkN8feweHMJMMSWYms/m+Xy9e7nnm2XvWkjArz7P3fnZeeXk5IiKyb8vPdgAiIpJ9KgYiIqJiICIiKgYiIoKKgYiIoGIgIiKoGIjUK2Z2jpndFm73N7OZ4fZkM+uR3egkyhpkOwAR2c0JQKvKje5+VRZikX2IioHkLDM7FxgFNARKgBvcfaGZjQHaAd8Dvg+sBy5x97VmdhjwW6AtsD/wjLvfZWbtgPlALNz3NOBsYASwFXgdGBzu8z7wv+7+ahjHY8Byd/9Npfh+BowG9gM2A9e7++IwvoPd/dqw3xjgYOBJYCCwn5ltAv4Zd6x5wG/d/Tkz6wLcA3wH2AmMcfeZZtYf+EXYvgnoC/whPDbAK+5+y17/j5Z9gqaJJCeZ2RHAXUAvdz8eGADMMLPvhF26Af/p7kcCXwJXh+1PAk+4ewHwE6CHmV0cvtcGuN3dfwi0JPjC7REefzOwn7uXAxOAq8I4mgO9gd9Xiu9IYCJwobsfA9wKvBj2T8jdF4X7THX3m5Pk3RL4HdDP3TsD5wETzKxt2OVooNDdTwf+G1gZ9usGHGFmLZJ9vuzbNDKQXHUmwW/+c82som0n0DHcnufum8PtJUCrsFCcFm7fHr7XFDgOWAzsABaG7WcDr7r7J+HrccCYcHsKMNrMDgEuAma6e3Gl+LoDc919JYC7v25m/wIKap4yACcT5P1CXN7lwDHh9rK4vP8MzAoLxWvACHffVMvPl4hSMZBctR/Bl+0lFQ1mdjiwFjifYGqnQjmQF+6TB3Rx95Jwn4OBUoKplG3uviPcZ0fYt0JZxYa7F5vZNOAy4FLgmgTxJRp15xNMM1XEU6FhdcnG2Q+IufuJFQ1m9m8EU2H/BWyJi/MdM/sB0IOgOC02s5+5+4K9+DzZR2iaSHLV68BZ4XQMZtYLWAYckGyH8Dfmt4Hrw30OBN4imOapbA7BFNJh4evKJ3AfAa4D8t19cRXxtQ8/qztwOLCI4Iu7wMzywtHKWXH77SAoGMm8TTDdc2p43OMIzi38W+WOZvZr4BZ3f4HgfMffgR9WcWzZh6kYSE5y978TnCd4xsz+BtwOnOfuX1ez66XASWb2HsEX85/c/Y8Jjr8CGArMMbN3gU4EJ6kr3v8bwbmIiUni+wcwiOA8xnLg18C54TTNHwkKwj+BWXw7NQUwFzjPzMYlOe564ELgvjDvJwnOH3ycoPtDwHHh578LfAT8KdFxRfK0hLXInsLplZ8TnFDeaWYXAMMrpmfMrAMwD7CKKSeRXKZzBiKJfUIw9fKeme0guFTzSoDwprABwGAVAokKjQxERETnDERERMVARERQMRAREXL4BHJRUZFOdoiI1EBBQUFe5bacLQYABQW1vbN/d7FYjE6dOtXpMTOlsLAQgHnz5u1qy+V8kolaTlHLB6KXU9TyKSoqStie08VAvjVq1KhshyAiOUzFICJ69NBzT0Sk5nQCOSKWLl3K0qVLsx2GiOQojQwiYsiQIcDu5wxERFKlkYGIiKgYiIiIioGIiKBiICJSrW3btjFt2jTGjRvHn/5Ud4+EOOWUU1Lu2717d7Zt27Zb25tvvsmIESPqJJZ98gRyuxGv7Npe9etzshhJ3bnrrruyHYJIZK1fv55p06bRrVu3bIeSNvtkMYiiLl26ZDsEkYypuOM+3sUXX8ygQYMoKSmhV69ee7zfv39/+vfvz4YNG7jooot2e6+6q/AmTpzIBx98wLJly+jatSt//vOfKS4uZvDgwXTv3p3TTz+d9u3b06FDB6644gpuueUWtm3bRqNGjbj99ttp1aoVgwcPZsuWLWzdupWhQ4fStWtXvvnmG4YNG8batWs58MADefjhh9m6dSs33ngjW7ZsoaysjMGDB3PyySfviuXDDz9k5MiRNG7cmMaNG9OiRYsa/T+sTMUgIhYsCJ5xrqIgUvcGDhzIihUr6NatG59//jl33nknixYtYvLkyXTv3p3PPvuMGTNm0LJlS4YMGUK/fv047bTTWLhwIWPHjmXgwIEUFxczefJkNm7cyKpVqwAoKSlh6NChtGnThn79+hGLxZg9ezZdunTh8ssvZ926dfTt25e5c+fuiuXee+/luuuu45RTTuHRRx9l5cqVdZKjikFEjBw5EtB9BrJvqOrnvEmTJlW+f/DBB9fq38nRRx+96zilpaUAtGzZkpYtWwKwYsUKJk2axOTJkykvL6dBgwYcccQRXHLJJVx//fXs2LGDfv36AdCiRQvatGmz63hbt27lww8/5NxzzwWgdevWNG3alI0bN+76/FWrVnHMMccA0LlzZxUDEZFMyc/PZ+fOnQDk5e2x4Cf5+d9ei9O+fXuuvPJKOnfuzIcffsg777yDu/P111/z6KOP8q9//Ys+ffpw+umnJzxWhw4dePfddznqqKNYt24dmzdv5sADD9zt/SVLlnDqqaeyfPnyOstRxUBEpBoHHXQQ27dv3zUSqMrw4cMZM2YM27Zto7S0lJtvvpl27drxyCOPMHv2bHbu3Ml1112XdP+rr76akSNHMmfOHEpLS7ntttto0ODbr+oRI0YwfPhwHn/8cVq1akWjRo3qJEcVAxGRajRq1IgXX3xxt7YOHTrw5JNPAvDWW2/taj/88MN5/PHH9zjGww8/vEdb/H4PPvjgru3x48fv0ff1118HoG3btnV6eWsF3WcgIiIaGUTFQw89lO0QRCSHqRhExHHHHZftEEQkh2maKCJee+01XnvttWyHISI5Km0jAzM7FCgCzgR2AFOAcmA5cI277zSz0cA54ftD3H2xmXVM1DddcUbFHXfcAeiJZyJSM2kZGZjZ/sAkYGvY9AAwyt27AXlAbzPrDJwGnAj0AR5J1jcdMYqIyLfSNTIYC0wEbgpfFwBvhNuzgbMAB15193JgtZk1MLNDkvR9Pk1xikgOil9ssi7UtwUri4uLmT9//q47kTOhzouBmfUH1rv7HDOrKAZ54Zc+wFdAC6A5sDFu14r2RH0TisVitY43/hilpaV1csxsKCkpAaKTTzJRyylq+UBu5lRVvNnI57333mPOnDl07NgxY5+ZjpHBlUC5mfUAjgP+ABwa934zoBjYHG5Xbt+ZoC2hTp061TDEb9fyiD9GLBarxTGzq0mTJkB08kkmajlFLR/IVE51sx5PharircintLSUm266ibVr17J9+3ZGjhzJM888wyeffEJZWRlXXHEFvXr1ol+/frRq1YpNmzZxzjnn8MILL+y667i4uJgpU6aQn59PQUEBN9xwA1988QXDhw/nq6++ory8nHvuuYfZs2fz/vvvs2zZMi655JI6zbWoqChhe50XA3c/tWLbzOYBA4H7zKzQ3ecBPYG/AB8A95rZWKANkO/uG8xsSYK+Uo1JkyZlOwSRSHvmmWc47LDDePDBB1m1ahWzZs2iVatWjB07li1btnDBBRdw0kknAfDTn/6UM888kxkzZtC8eXMmTJhAcXExl156KdOnT6dx48bceOONvPXWW/zlL3+he/fu9O3bl7/+9a8sW7aMgQMH8swzz9R5IahKpu4zGAY8ZmYNgRjwnLuXmdl8YCHBiexrkvXNUIw5zcyyHYJIpK1cuZJTTw1+123Xrh3r16/ftWR806ZN6dChA2vWrAHgBz/4wa79KrZXr17NF198wYABAwD4+uuvWb16NR999NGu5yt07tyZzp07s2jRoozlVSGtxcDdC+Nenpbg/THAmEptKxL1laq9/PLLABk94SSyL+nQoQPvvfcePXr0YM2aNbzyyis0bNiQM888ky1btrBixYpdy1HHr0ZasaJpmzZt+N73vscTTzzB/vvvz4wZM+jUqRMfffQR7733HkceeSTvvPMO8+bNo7CwcNcqqZmiO5Aj4v777wdUDETSpU+fPowcOZLLLruMsrIyJk+ezB//+Ef69u3Ltm3buPbaaznooIOS7t+qVSv69+9Pv379KCsr47DDDqNnz54MHDiQkSNH8tJLLwHBI2wbNmzIihUrmDJlCv37989IfioGIpJzsnEpaKNGjXb90lWh4iEz8SpWMgW44IILdnuvd+/e9O69+61TjRs3ZuLEiXscZ/bs2bUJd69pOQoREVExEBERFQMREUHnDCIjfp5SRGRvqRhExOGHH57tEEQkh2maKCKmTp3K1KlTsx2GiOQojQwiYsKECQAZvX1dJGvGjMn48d58800+++yzevFvbO3atbz//vt07969zo6pYiAikoKKpSjqg7fffpuVK1eqGIiIZNqMGTOYP38+a9eu5bvf/S5r1qzhRz/6Eb/61a8SrjzaqlUrbrzxRrZs2UJZWRmDBw/m5JNP5qc//Snt2rVj//33p3379ixZsoSSkhLuvPNOFixYwMyZM8nLy6NXr178/Oc/Z9WqVYwaNYrt27dzwAEHcP/99/Poo49SWlrK8ccfzxlnnFEn+akYiIjshVWrVvH444/TuHFjevTowfr165k0adIeK4/GYjG6dOnC5Zdfzrp16+jbty9z586lpKSEQYMGcdRRRzFu3Djat2/PqFGj+OCDD5g1axZPP/00AFdccQVdu3blvvvuY8CAAZx66qnMnTuX999/nwEDBrBy5co6KwSgYiAislfatm1L06ZNATjkkEPYtm1bwpVHZ86cuWutsNatW9O0aVM2bgye55VoVdMVK1awdu3aXWsRbdq0iY8//piPPvqI448/HmDXl/+MGTPqPC8Vg4h47jmt9C2SCfErklaoWNE0fuXRDh068O6773LUUUexbt06Nm/ezIEHHgh8u5Jp/Hb79u3p2LEjkydPJi8vjylTpmBmu47dpUsXXnrpJTZt2kSzZs3qfFVTFYOIOPjgg7Mdgsg+K9HKo82aNWPkyJHMmTOH0tJSbrvtNho0SP6Ve+SRR3LyySfTt29fvvnmG4455hhat27NL3/5S2699VYmTJjAAQccwH333cfatWuZMGECRx99NOecUzeL9uWVl5dX36seKioqKi8oKKjRvvEP045f/TCXH0E4ZcoUgN2Wu83lfJKJWk5Ryweil1PU8ikqKqKgoGCP4U1aRgZmth/wGGBAOcGjL/cHZgL/DLtNcPepZjYaOAfYAQxx98Vm1hGYEu67HLjG3TP7pIcck6gYiIikKl13IJ8L4O6nAKOAO4EC4AF3Lwz/TDWzzgRPNTsR6AM8Eu7/ADDK3bsBeUDvyh8gIiJ1Jy0jA3d/wcxmhi+/DxQTFAMzs94Eo4MhQFfgVXcvB1abWQMzOyTs+0a4/2zgLOD5dMQqIiJpPIHs7jvM7PfA+cBFwGHAZHcvMrObgdEERWJj3G5fAS2AvLBAxLftIRaL1TrO+GOUlpbWyTGzoaSkBIhOPslELaeo5QPRyylq+SST1quJ3P1yMxsOLAK6uPun4VvPA+OAF4Fmcbs0IygQOxO07aHmJ3VWJjxGLp8oatKkCRCdfJKJWk5Ryweil1PU8ikqKkrYnpZzBmbWz8xuCl+WEHy5zzCzn4RtZwBFwFvA2WaWb2ZtgXx33wAsMbPCsG9PYH464oySWbNmMWvWrGyHISI5Kl0jgxnA78zsTYKriIYAa4BxZrYd+BwY4O6bzWw+sJCgMF0T7j8MeMzMGgIxQHdUVaNiZCCyL5g3b16dHq+wsDClfmvWrOHee++luLiY7du3c+SRR3LDDTfQtGlT3n77bcaPH095eTnbt2/n7LPPpn///uTl5dGvXz+2bt1K48aN2b59O23atOHmm2+mZcuWdZpHbaTrBPLXwMUJ3jolQd8xwJhKbSsIrjKSFI0fPx6AQYMGZTkSkWgqLS1l0KBB3HHHHRx77LEAPP/88wwbNoxhw4Zxzz33MGnSJA499FB27NjBmDFjePzxx7nqqqsAuOeee+jQoQMAL730Erfeeivjxo3LWj6V6eE2EfHss8/y7LPPZjsMkciaN28eJ5xwwq5CAHD++efz5ZdfMnbsWK6++moOPfRQABo0aMCIESOSPnDqvPPO4+9//zvbtm3LSOypUDEQEUnBmjVraNu27R7tbdq0YdGiRXu817RpU7Zu3Zp0DaHmzZuzefPmtMRaEyoGIiIpaN26NZ988ske7R9//DGdO3fm008/3a19y5YtNGzYcLdF6SqUl5ezYcMGDjrooLTFu7dUDEREUnDGGWewYMECli1btqtt2rRptGzZkhtuuIEJEyawfv16ALZv386dd95Jnz59Eh7rueee46STTkpYKLJFq5aKiKTgO9/5DhMnTuSuu+6iuLiYsrIyzIwHHniA5s2bM3ToUIYOHUpZWRk7duzgzDPP3HXyGGD48OE0btwYCEYZo0ePzlYqCakYRERdX2onUp+leiloXWvbti0TJ05M+F63bt3o1q1bwveefPLJdIZVJ+rPGEVERLJGxSAixo4dy9ixY7MdhojkKBWDiJg5cyYzZ86svqOISAIqBiIiomIgIiIqBiIigi4tjYyK65dFRGpCxSAiZs+ene0QRCSHaZpIRERUDKLi9ttv5/bbb892GCKSo9IyTWRm+wGPAQaUAwOBUmBK+Ho5cI277zSz0cA5wA5giLsvNrOOifqmI9aomDt3LgC33HJLliMRkVyUrpHBuQDufgowCrgTeAAY5e7dgDygt5l1Jnii2YlAH+CRcP89+qYpThERIU3FwN1fAAaEL78PFAMFwBth22ygB9AVeNXdy919NdDAzA5J0ldERNIkbVcTufsOM/s9cD5wEXCmu5eHb38FtACaAxvjdqtoz0vQdw+xWKzWccYfo7S0tE6OmQ0lJSVAdPJJJmo5RS0fiF5OUcsnmbReWurul5vZcGAREH8hfDOC0cLmcLty+84EbXvo1KlTDSNbmfAYsVisFsfMrsMPPxyITj7JRC2nqOUD0cspavkUFRUlbE/LNJGZ9TOzm8KXJQRf7u+aWWHY1hOYD7wFnG1m+WbWFsh39w3AkgR9pQrTp09n+vTp2Q5DRHJUukYGM4DfmdmbwP7AECAGPGZmDcPt59y9zMzmAwsJCtM14f7DKvdNU5wiIkKaioG7fw1cnOCt0xL0HQOMqdS2IlFfSe6mm4KB2N13353lSEQkF2k5iohYuHBhtkMQkRymO5BFRETFQEREVAxERASdM4iMNm3aZDsEEclhKgYR8dRTT2U7BBHJYZomEhERFYOoGDJkCEOGDMl2GCKSozRNFBFLly7NdggiksM0MhARERUDERFRMRAREVI4Z2Bm7wJPAX9w9y/SH5LUxA9/+MNshyAiOSyVE8g9gEuBl81sDTDZ3V9Lb1iytx599NFshyAiOazaaSJ3L3b38cBVBA+pedrMFpnZ+WmPTkREMiKVaaJBwM8JHlE5Gbic4IE1bwPPpzU6SdmAAQMAjRBEpGZSmSY6DOjj7qvi2rab2dWJOpvZ/sATQDugEXAHsAaYCfwz7DbB3aea2WjgHGAHMMTdF5tZR2AKUA4sB65x951IlVasWJHtEEQkh6VyNdEi4AoAM/uzmZ0F4O7JnqZyGbDR3bsB/wH8FigAHnD3wvDPVDPrTPA0sxOBPsAj4f4PAKPC/fOA3jVLTUREUpXKyGAMcHq4fQkwG3i1iv7T+PaZxXkEv/UXAGZmvQlGB0OArsCr7l4OrDazBmZ2SNj3jXD/2cBZaDpKRCStUikG2919E4C7bzKzsqo6u/sWADNrRlAURhFMF0129yIzuxkYDRQDG+N2/QpoAeSFBSK+LaFYLJZC+FWLP0ZpaWmdHDMbSkpKgOjkk0zUcopaPhC9nKKWTzKpFIPFZvY0sBD4CbCkuh3M7HCC3+bHu/vTZnaguxeHbz8PjANeBJrF7daMoEDsTNCWUKdOnVIIP5GVCY8Ri8Vqcczs6tKlCxCdfJKJWk5Ryweil1PU8ikqKkrYnsqlpf8LPAs0AZ519+uq6m9mrQmmkYa7+xNh8xwz+0m4fQZQBLwFnG1m+WbWFsh39w3AEjMrDPv2BOZXF6PAQw89xEMPPZTtMEQkR6VyaWkzoCHwGdDSzH7u7n+oYpeRQEvgFjO7JWy7HnjQzLYDnwMD3H2zmc0nGHHkA9eEfYcBj5lZQyDGt+cfREQkTVKZJnoRWEtweSgEl3wm5e6DgcEJ3jolQd8xBCeo49tWEFxlJHvhsssuA/TEMxGpmVSKQb67X5b2SKRWPvnkk2yHICI5LJVisMzMTgSWEo4K3P2bdAYlIiKZlUoxOA04N+51OdA+PeGIiEg2VFsM3P1YADM7CPgi7h4AERGJiFSuJjoVGA/sB0wzs4/d/fG0RyZ75eSTT852CCKSw1KZJroDOBWYDtxFcH+AikE9c/fdd2c7BBHJYaksVLczfMJZubuXEiwRISIiEZJKMfjAzO4GDjKzEcDHaY5JauDCCy/kwgsvzHYYIpKjUikGAwkKwP8BW4D/TmtEUiMbN25k48aN1XcUEUkglXMGXYB/hH8ATgLeTFtEIiKScakUg/8J/5sHHA2sQsVARCRSUrnPoG/Fdrh43LNpjUhERDIulZFB5f66+7geOuOMM7IdgojksFRuOvuMYAmKvLD/b9IdlOy9W265pfpOIiJJpDJN9L1MBCIiItmTysjgiWTvufuVdRuO1FTPnj0BmD17dpYjEZFclMo5g53Ah8BfgB8D/0HwDOOEzGx/4AmgHdCIYDmLfwBTCKablgPXuPtOMxsNnAPsAIa4+2Iz65iobw1y26ds3bo12yGISA5L5aaz77v73e7+trv/Fmjk7nPcfU6S/pcBG929G0Hh+C3wADAqbMsDeptZZ4LlsU8E+gCPhPvv0bemyYmISGpSGRk0NbPuwDtAtxT6T+Pb5xbnEfzWXwC8EbbNBs4CHHg1XBJ7tZk1MLNDkvR9PoXPFRGRGkqlGFwJjCWY9lkG/KKqzu6+BcDMmhEUhVHA2LjnIHwFtACaA/HrJ1S05yXoKyIiaZTK1UQxMxsKHAH8Dfi0un3M7HCC3+bHu/vTZnZv3NvNgGJgc7hduX1ngraEYrFYdaFUK/4YpaWldXLMbDjhhBOA6OSTTNRyilo+EL2copZPMqlcTXQtcD7QiuDE7hHAtVX0bw28Clzr7nPD5iVmVuju84CeBCejPwDuNbOxQBsg3903mFmivgl16tSp2gQTW5nwGLFYrBbHzK777rtvj7ZczieZqOUUtXwgejlFLZ+ioqKE7alME/UheLjNXHf/jZm9U03/kUBL4BYzq7gTajDwcLicRQx4zt3LzGw+sJDgRPY1Yd9hwGPxfVOIUUREaiGVYpBPcJlnxTz+tqo6u/tggi//yk5L0HcMMKZS24pEfaVqhYWFAMybNy+rcYhIbkqlGDxNsErp981sFvBCWiMSEZGMS6UY/D9gLvDvgLv7svSGJCIimZZKMXjc3bsSzN+LiEgEJS0GZtbC3TcBX5vZgwQ3ie0EcPdHMxSfiIhkQFUjg1eArsBHwJfAoRmJSGrk4osvznYIIpLDqioG28PLSI9g9ymicuC2tEYle23QoEHZDkFEclhVxaAHcBgwAdA3TT1XUlICQJMmTbIciYjkoqTFwN3LgNUES0xLPderVy9A9xmISM2ksoS1iIhEnIqBiIioGIiIiIqBiIiQ2h3IkgP69++f7RBEJIepGESEioGI1IamiSJiw4YNbNiwIdthiEiO0sggIi666CJA9xmISM1oZCAiIukbGZjZicA97l5oZscDM4F/hm9PcPepZjaa4A7nHcAQd19sZh0JnrVcDiwHrnH3nemKU0RE0lQMzOyXQD/g67CpAHjA3e+P69OZ4PGWJwKHA9OBE4AHgFHuPs/MJgK9gefTEaeIiATSNTL4ELgAeDJ8XQCYmfUmGB0MIVge+1V3LwdWm1kDMzsk7PtGuN9s4CxUDERE0iotxcDdp5tZu7imxcBkdy8ys5uB0UAxsDGuz1dACyAvLBDxbQnFYrV/+Fr8MUpLS+vkmNlw3nnnAdHJJ5mo5RS1fCB6OUUtn2QydTXR8+5eXLENjANeBJrF9WlGUCB2JmhLqFOnTjUMZ2XCY8RisVocM7sSxZ3L+SQTtZyilg9EL6eo5VNUVJSwPVNXE80xs5+E22cARcBbwNlmlm9mbYF8d98ALDGzwrBvT2B+hmLMaWvWrGHNmjXZDkNEclSmRgb/A4wzs+3A58AAd99sZvOBhQRF6Zqw7zDgMTNrSPCEtecyFGNO69evH6D7DESkZtJWDNx9FXBSuP1X4JQEfcYAYyq1rSC4ykhERDJEN52JiIiKgYiIqBiIiAhaqC4yhg0blu0QRCSHqRhExLnnnpvtEEQkh2maKCLcHXfPdhgikqM0MoiIq6++GtB9BiJSMxoZiIiIioGIiKgYiIgIKgYiIoJOIEfGqFGjsh2CiOQwFYOI6NGjR7ZDEJEcpmmiiFi6dClLly7NdhgikqM0MoiIIUOGALrPQERqRiMDERFJ38jAzE4E7nH3QjPrCEwByoHlwDXuvtPMRgPnADuAIe6+OFnfdMXZbsQru7ZnX94+XR8jIlKvpWVkYGa/BCYDB4RNDwCj3L0bkAf0NrPOBE80OxHoAzySrG86YhQRkW+la5roQ+CCuNcFwBvh9mygB9AVeNXdy919NdDAzA5J0ldERNIoLdNE7j7dzNrFNeW5e3m4/RXQAmgObIzrU9GeqG9CsViszmIGKC0trfNjZsqAAQOA3f+f5HI+yUQtp6jlA9HLKWr5JJOpq4ni5/ybAcXA5nC7cnuivgl16tSphuGsTNh6wAEH1OKY2ZUo7lgslrP5JBO1nKKWD0Qvp6jlU1RUlLA9U1cTLTGzwnC7JzAfeAs428zyzawtkO/uG5L0lWosWLCABQsWZDsMEclRmRoZDAMeM7OGQAx4zt3LzGw+sJCgKF2TrG+GYsxpI0eOBHSfgYjUTNqKgbuvAk4Kt1cQXDlUuc8YYEyltoR9RUQkfXTTmYiIqBiIiIiKgYiIoIXqIuOhhx7KdggiksNUDCLiuOOOy3YIIpLDNE0UEa+99hqvvfZatsMQkRylkUFE3HHHHYCeeCYiNaORgYiIqBiIiIiKgYiIoGIgIiLoBHJkTJo0KdshiEgOUzGICDPLdggiksM0TRQRL7/8Mi+//HK2wxCRHKWRQUTcf//9AJx77rlZjkREcpFGBiIiktmRgZn9leDZxwAfAZOA3wA7gFfd/Vdmlg+MB44FtgFXufsHmYiv5+9XUvF85FW/PicTHykiUi9krBiY2QFAnrsXxrUtBS4k+AZ+xcyOB34AHODuJ5vZScD9QO9MxSkisi/K5MjgWKCJmb0afu4YoJG7fwhgZnOAHsD3gD8DuPvbZvbjDMYoIrJPymQxKAHGApOBI4DZQHHc+18B7YHmwKa49jIza+DuOyofMBaLpS3YdB47HW699VZg97hLS0tzLo/qRC2nqOUD0cspavkkk8lisAL4wN3LgRVmtgloFfd+M4Li0CTcrpCfqBAAdOrUqYahrKy2R82PnR2J4o3FYjmXR3WillPU8oHo5RS1fIqKihK2Z/JqoisJ5v8xs38j+NL/2sw6mFkecDYwH3gL6BX2Owl4L4Mx5qypU6cyderUbIchIjkqkyODx4EpZvZ/QDlBcdgJ/BHYj+BqokVm9g5wppktAPKAKzIYY86aMGECAJdcckmWIxGRXJSxYuDu3wCXJnjrpEr9dgIDMxKUiIgAugM5qXYjXtm1rXsORCTqdAeyiIioGIiIiKaJIuO5557LdggiksNUDCLi4IMPznYIIpLDNE0UEVOmTGHKlCnZDkNEcpSKQUSoGIhIbagYiIiIzhmkQvcciETTvHnzdm0XFhbWef9comIgIpGR7Ms6vj2VfeO1bt16r/rnapFQMdhLFaMEjRBE6odkX8qpFIBULF++nHXr1tUonlwqDCoGNVTfpo5mzZqV7RBEaqSuvrSldlQM6kB9KAxNmjTJyueKwO5f6PHTKvv6F30uTSWpGETE+PHjARg0aFCWI5H6KJNfyns7rbIvqo9TSftkMTiuwacJ25fuOKzWx042Sohvj1dXI4lnn30WUDGIstpc+SJSnX2yGCRT10UiWQHY233rwzkJqVptftOryZe2vuijo75MJdXLYmBm+cB44FhgG3CVu3+QrXjqskhUPtbPRj1a7XETFZVcLBCVf+hTufQv2T+IVL589/YLc2/jqYurWNavX88hhxyScn+RdKmXxQD4GXCAu58cPgf5fqB3dkPaU7IikYnjVi4iyz/6DNj9i+ih11YQPFYahvT4YZ3FV5XgM0npM2ty7ff69ev3mI+uq9+Sa3Mtukiuq6/FoCvwZwB3f9vMfpzleHJG/JdxKu3plL7P/DKlXvHFKFksyQrW3sS+t8eI7//Hv31JonzqIq5UxH/O209M/3a77Y+q7L83RT+h+KJaT06g1jeZPsmcV15envYP2VtmNhmY7u6zw9ergfbuvqOiT1FRUf0LXEQkBxQUFORVbquvI4PNQLO41/nxhQASJyMiIjVTX1ctfQvoBRCeM3gvu+GIiERbfR0ZPA+caWYLgDzgiizHIyISafXynEE6mVkL4CmgOdAQuN7dFybolw+8Arzo7hPNbD/gAeDHQCNgjLvPzFzkidUinzzgE+CfYZeF7n5ThsKuUk1zims/ElgEtHb30sxEnVwt/o6+AzwNtAS+AS539/RcwraXapFTSvtlWh38zJ0P/Ke7X5qhkOtcfZ0mSqfrgbnufhrQH3gkSb87CP4RVugH7O/upxBc5toxnUHuhZrm0wH4q7sXhn/qRSEI1TQnzKw5waXI29IZ4F6qaT7/DRS5+6kEX1S/TGeQe6mmOaW6X6bV5mfuN8Dd5Pj3aX2dJkqnB/n2i6IBsMdvjmZ2EbCT8PLW0NnAcjN7hWDq6n/THGeqappPAXCYmf0F2AoMdXdPc6ypqlFO4WjnUWAk8GL6w0xZjfJx94fCESlAW6A4vWHulZr+3FW7X5bUNB+ABcALwNVpjC/tIl0MzOwXwNBKzVe4+ztm9l2C37aGVNrn34FLgYuAW+PeOphgNPBT4FTgd+F/M6aO8/kMuNvdp5lZ13DfE9IVezJ1nNNo4BV3/5uZpS/oKtRxPrh7mZm9DvwIODNdcVelLnNy9+Lw/YT7ZUIa/o6mmllh2gLOkH3unAGAmf0IeAa4oeJehrj37gVOI/htuR3BXO11BEPHae4+Pez3ubt/N4NhJ1XDfN4Edrj7N2G/T4E27l4vfiBqmNNvCc6DAJwELA6nWLKuJvm4e/yo50iCQtchY0FXo6Y5VbVfNtXm7ygsBgPdvU8mY65LkR4ZJGJmRwHTgEvc/W+V33f3X8b1HQN8Hv4AdyS43HW6mR0LrM5QyFWqRT73ABuBe8N81tSjQlCjnIg7j2Nmq4Cz0h5sCmrxd3QT8Im7PwlsAcoyFHK1apFTlftlSy1+5iJjnysGBCd6DgB+E04lbHL33mZ2PfCBu7+UZL/HgAlm9jbBOYOBGYm2ejXN59fAU2Z2DrCDYORTX9Q0p/qqpvk8Afw+nNbYj/p1iXVNc0q4XyYCrkbUfub22j45TSQiIrvL6UuhRESkbqgYiIiIioGIiKgYiIgIKgYiIoKKgUitmNm12Y5BpC6oGIjUzqhsByBSF3SfgUglZrY/MBE4guAXplHAw8AbwDFAOcHKtdcSrIc0GVgMXBn2Hw18l2B9m20Ey4QPAP4L+BnBU/wOBm4jeHDTU+7+k/CzpwL3u/vitCcqEkcjA5E9XQVsCNc16k2wnHFz4E/hEsefAj3d/U7gC3cfFO73pbt3BZYCvwK6h6+L+XZFy+8QLDh3FsHzMVYCW83sKDNrBfxAhUCyYV9cjkKkOj8CupnZieHrBgS/yS8JX68hWLqgsoolwNsDf3f3r8LXbxJ8+S8C3nD3ncA6M/sSOIRgqZP+BOtdPVW3qYikRiMDkT29TzAKKAR6Eixg9gXB9FBleXHbO8P/fgQcFT6pDILVLleE2wUAZtaaYLTxL+A5gmJxPioGkiUqBiJ7mgQcaWZvEDy45GO+/aKv7B9mttsXuLtvIDhv8JdwYcODgQnh2981s7kEj04c5O5l4aM53wT+5e5f1H06ItXTCWSRDDGz/sCR7j4iwXuPANPd/fWMByaCRgYiWWdmrwItVQgkmzQyEBERjQxERETFQEREUDEQERFUDEREBBUDERFBxUBERID/D81gaYHoqeWeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8373 -81.882439         6405          1782              6112           0.782338             0.746549\n",
      "1     exit_2       3595        8218         0.8377 -79.849854         1141          1033               995           0.524839             0.457682\n",
      "2  Main_exit       2454        7185         0.9394         NA         2454          7185              2088           0.254591             0.216620\n"
     ]
    }
   ],
   "source": [
    "# EDL frozen, 15epochs no kl or info_reg\n",
    "buildComparePlot(output_ID, output_OOD, [\"energy\"], \"gmean\",plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e62f6aa-51c5-44cd-a5fc-ab70c0b8462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "m entropy\n",
      "metric entropy\n",
      "entropy  lr_auc 0.12849606083586113 Best Threshold=3.2198143005371094, G-Mean=0.7958496889074013, TPR=0.8523255813953489, FPR=0.2568840579710145\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1']\n",
      "m entropy\n",
      "metric entropy\n",
      "entropy  lr_auc 0.12466646047371904 Best Threshold=3.2200355529785156, G-Mean=0.8054832866006317, TPR=0.8408812729498164, FPR=0.22842457566339947\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "m entropy\n",
      "metric entropy\n",
      "entropy  lr_auc 0.13248245670676545 Best Threshold=3.2185394763946533, G-Mean=0.7972006669250856, TPR=0.8439269981120201, FPR=0.2469385328736179\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8280  3.219814         6408          2139              6153           0.749737             0.719902\n",
      "1     exit_2       3592        7861         0.8366  3.220036         1143          1319               997           0.464257             0.404955\n",
      "2  Main_exit       2449        6542         0.8411        NA         2449          6542              1567           0.272383             0.174285\n"
     ]
    }
   ],
   "source": [
    "# CE not frozen, 15epochs\n",
    "buildComparePlot(output_ID, output_OOD, [\"entropy\"], \"gmean\",plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f34f7-5fe1-445c-a2ce-0c2c5b0f37e8",
   "metadata": {},
   "source": [
    "### ID/OOD branch performance\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f82b13af-c1ee-4b09-9293-32d901de7267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  energy threshold:  gmean\n",
      "energy  lr_auc 0.12200723534832629 Best Threshold=-70.56578826904297, G-Mean=0.8083515421874572, TPR=0.8510765550239234, FPR=0.23222862632084534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "energy  lr_auc 0.12585868238042153 Best Threshold=-79.33734130859375, G-Mean=0.8056013219699143, TPR=0.8240802675585285, FPR=0.21246325690770135\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoyklEQVR4nO3df5xWc/7/8UdJKhWlNvsRm8JL7PrRrBX6MZK1FZtfH8qKWKvEZyuykmytn4tY1lKIL8KGan1W6sOKaEkxq6U1vVqSSnZMZUpq0kzz/eOca0zTddU101znXDPzvN9ue9tzneuccz2vozmv6/0+57xPg7KyMkREpH5rGHcAERGJn4qBiIioGIiIiIqBiIigYiAiIqgYiIgIKgYiWcXM+pnZTeH0YDObGU5PNrPe8aaTuqxR3AFEZDvHAa0rz3T3y2LIIvWIioHUWmZ2BjAWaAxsAka5+3wzGw90AL4P/AAoBM5399VmdgDwJ+AgYE9gqrvfZmYdgHlAfrhuT+A0YDSwGXgNGB6uswT4H3d/JczxCLDY3e+rlO9MYBywB7ABuNrdF4b52rj7VeFy44E2wBRgKLCHma0H/l1hW3OBP7n7NDM7EbgD2BvYBox395lmNhj4ZTh/PTAQeDLcNsBL7n5jlXe01AvqJpJaycwOBW4D+rr7scDlwAwz2ztcpDvw3+5+OPAVMCScPwV4zN1zgJ8Avc3svPC99sDN7n4Y0IrggNs73P4GYA93LwMmApeFOVoC/YEnKuU7HJgEnOPuRwG/Bf43XD4pd18QrvOsu9+Q4nu3Av4fMMjduwA/Byaa2UHhIkcCue5+MvArYFm4XHfgUDPbJ9XnS/2mloHUVqcS/PKfY2aJeduAQ8Lpue6+IZx+H2gdFoqe4fTN4XvNgWOAhUAJMD+cfxrwiruvCl/fD4wPpx8HxplZW+BcYKa7F1XK1wuY4+7LANz9NTP7Esip/lcG4ASC7/1Che9dBhwVTn9Q4Xv/HzArLBSvAqPdff1ufr7UUSoGUlvtQXCwPT8xw8wOBFYDZxF07SSUAQ3CdRoAJ7r7pnCdNkAxQVfKFncvCdcpCZdNKE1MuHuRmT0PXAhcAFyZJF+yVndDgm6mRJ6Exrv6shXsAeS7+/GJGWb2XwRdYb8ANlbI+a6ZHQz0JihOC83sTHd/uwqfJ/WEuomktnoN+GnYHYOZ9QU+AJqkWiH8xfwOcHW4zr7AWwTdPJW9TNCFdED4uvIJ3AeAXwMN3X3hTvJ1DD+rF3AgsIDgwJ1jZg3C1spPK6xXQlAwUnmHoLunR7jdYwjOLfxX5QXN7PfAje7+AsH5jn8Bh+1k21KPqRhIreTu/yI4TzDVzP4J3Az83N2/2cWqFwBdzexDggPzn9396STbXwqMBF42s/eAzgQnqRPv/5PgXMSkFPk+AoYRnMdYDPweOCPspnmaoCD8G5jFd11TAHOAn5vZ/Sm2WwicA9wVfu8pBOcPPkuy+L3AMeHnvwd8Cvw52XZFGmgIa5Edhd0rFxGcUN5mZmcD1yW6Z8ysEzAXsESXk0htpnMGIsmtIuh6+dDMSggu1bwUILwp7HJguAqB1BVqGYiIiM4ZiIiIioGIiKBiICIi1OITyHl5eTrZISJSDTk5OQ0qz6u1xQAgJ2d37+xPLj8/n86dO2dk25mk3NGpjZlBuasqNzcXgLlz51Zr/Wzc33l5eUnn1+piICKSSWPHjo07QmRUDEREUujdu/48T0gnkEVEUli0aBGLFi2KO0Yk1DIQEUlhxIgRQPXPGdQmahmIiEjmWgZmdjxwh7vnhsPs3k8wJvwW4CJ3LzCzXxE8gaoEuCV8dF8b4BmgKcHY9Jdo/BcRkczKSMvAzH4DTOa7seXvI3hmbC4wA7jOzPYnGA/+JIKnSt1uZnsRPB7wGXfvTvCEqiGIiEhGZaqb6BPg7AqvB7j7onC6EcGTpX4CvOXuW8Ix3j8meHRfN4LH9QHMJnhKU62wZcsWnn/+ee6//37+/OeaGzb+pJNOSnvZXr16sWXLlu3mvfnmm4wePbrG8ohI3ZORbiJ3n25mHSq8/gLAzE4ErgJ6ELQGKj6P9WtgH6BlhfmJeUnl5+fXaO6E4uLiam27oKCAJ598kmOPPZaSkpIay5futoqLi/n2229ZsmQJjRt/9yTFlStXUlRUlLH9tbuqu7/jVBszg3JX1eWXXw5U/VizePFiAA455JBas78ju5rIzM4HbgD6uXuhmW0AWlRYpAVQBCTmb64wL6ld3dmXuHuwovPOO49hw4axadMm+vbtu8P7gwcP5vjjj6dt27ace+652723qysKnn76aT7//HP+/e9/061bNxYtWkRRURHDhw+nV69enHzyyXTs2JFOnTpxySWXcOONN7Jlyxb22msvbr75Zlq3bs3w4cPZuHEjmzdvZuTIkXTr1o1t27YxefJkVq9ezb777ssf//hHNm/ezLXXXsvGjRspLS1l+PDh7LvvvjRu3JjDDz+cVatWMWbMGJo2bUrTpk3Zd999s+5OyIRsvEtzV2pjZlDuqqruZxYUFADQpEmTrNvfsd6BbGYXEvT957r7unD2QuBWM2sC7EXwWMHFBM+k7Qs8DvQB5kWRsSYMHTqUpUuX0r17d/7zn/9w6623smDBAiZPnkyvXr344osvmDFjBq1atWLEiBEMGjSInj17Mn/+fCZMmMDQoUMpKipi8uTJrF27luXLlwOwadMmRo4cSfv27Rk0aBD5+fnMnj2bE088kYsvvpiCggIGDhzIn/70p/Isd955J7/+9a856aSTePjhh1m2bFlMe0Wk9nr77bcBOPHEE2NOknkZLwZmtgfwR2AFwfNgAd5w93Fm9keCg31D4AZ3LzazW4AnwiuN1hA8s7ZadvZLvlmzZinfz8/Pp02bNrt1bfGRRx4JQJs2bSguLgagVatWtGrVCoClS5fy0EMPMXnyZMrKymjUqBGHHnoo559/PldffTUlJSUMGjQIgH322Yf27duXb2/z5s188sknnHHGGQC0a9eO5s2bs379d71uy5cv56ijjgKgS5cuKgYi1TBmzBigftxnkLFi4O7Lga7hy9YplnkEeKTSvALgZ5nKlUkNGzZk27ZtADRosMOggDRs+N35+o4dO3LppZfSpUsXPvnkE959913cnW+++YaHH36YL7/8kgEDBnDyyScn3VanTp147733OOKIIygoKGDDhg20aNFiu/fff/99evToUd5/KSKSiu5ArkH77bcfW7duLW8J7Mx1113H+PHj2bJlC8XFxdxwww106NCBBx54gNmzZ7Nt2zZ+/etfp1x/yJAhjBkzhpdffpni4mJuuukm9thjj/L3R48ezXXXXcejjz5K69at2WuvvWrkO4pI3VRrn4Gcl5dXpiGst6fc0amNmUG5q6q6Q1gnlm/Xrl3W7e+8vLykzzPQcBQiIqJuIhGRVO69997dWn/x4sXll5kmu9Q9m6gYiIikcMwxx8QdITLqJhIRSeHVV1/l1VdfjTtGJNQyEBFJ4ZZbbgHqxxPP1DIQEZG63TLoMPql3Vh7xzt2l/++325sr2YVFRUxb9688ruQRUR2h1oGtZS789prr8UdQ0TqiDrdMohacXEx119/PatXr2br1q2MGTOGqVOnsmrVKkpLS7nkkkvo27cvgwYNonXr1qxfv55+/frxwgsvlN9xXFRUxOOPP07Dhg3Jyclh1KhRrFu3juuuu46vv/6asrIy7rjjDiZNmsSSJUt49tlnOf/88+P+6iJSy6kY1KCpU6dywAEH8Ic//IHly5cza9YsWrduzYQJE9i4cSNnn302XbsGwzWdfvrpnHrqqcyYMYOWLVsyceJEioqKuOCCC5g+fTpNmzbl2muv5a233uL111+nV69eDBw4kH/84x988MEHDB06lKlTp6oQiGTQQw89FHeEyKgY1KBly5bRo0cPADp06EBhYWH50LfNmzenU6dOrFy5EoCDDz64fL3E9IoVK1i3bl35AzW++eYbVqxYwaefflr+bIUuXbrQpUsXFixYENn3EqmvwlGW6wWdM6hBnTp14sMPPwSCp4u99NJLvPfeewBs3LiRpUuXlg9FXXEk0sRopu3bt+f73/8+jz32GFOmTOHCCy/kmGOO2W677777Lnfdddd2I6SKSGa8+OKLvPjii3HHiIRaBjVowIABjBkzhgsvvJDS0lImT57M008/zcCBA9myZQtXXXUV++23X8r1W7duzeDBgxk0aBClpaUccMAB9OnTh6FDhzJmzBj++te/AnDbbbfRuHFjli5dyuOPP87gwYMj+oYi9cvdd98NUC+u2qvTxaC6l4JWd4TEvfbaq/wfT0LiATMVTZkypXz67LPP3u69/v37079//+3mNW3alEmTJu2wndmzZ1c5o4hIMuomEhERFQMREVExEBER6vg5AxGR3VHx/F5dp2IgIpLCgQceGHeEyKibSEQkhWeffZZnn3027hiRqNstg/Hjq7Vam8JCaNu2Wtt78803+eKLL7JimIjVq1ezZMkSevXqFXcUkVpp4sSJAFnx95xpdbsYxCAxHEU2eOedd1i2bJmKgYjskopBDZsxYwbz5s1j9erV7L///qxcuZIf/ehH/O53v0s6+mjr1q259tpr2bhxI6WlpQwfPpwTTjiB008/nQ4dOrDnnnvSsWNH3n//fTZt2sStt97K22+/zcyZM2nQoAF9+/bloosuYvny5dxwww3sueeeNGnShLvvvpuHH36Y4uJijj32WE455ZS4d42IZDEVgwxZvnw5jz76KE2bNqV3794UFhby0EMP7TD6aH5+PieeeCIXX3wxBQUFDBw4kDlz5rBp0yaGDRvGEUccwf3330/Hjh0ZO3YsH3/8MbNmzeKZZ54B4JJLLqFbt27cddddnHPOOfziF79gzpw5LFmyhMsvv5xly5apEIjILmWsGJjZ8cAd7p5rZocAjwNlwGLgSnffZmbjgH5ACTDC3RemWjZTOTPloIMOonnz5gC0bduWLVu2JB19dObMmeXjnrRr147mzZuzdu1aIPnIpkuXLmX16tXl4xGtX7+ezz77jE8//ZRf/vKXAOUH/xkzZmT+i4pInZCRq4nM7DfAZKBJOOseYKy7dwcaAP3NrAvQEzgeGAA8kGrZTGTMtIqjkiYkG320U6dO5SObFhQUsGHDBvbdd1/gu9FMK0537NiRQw45hCeffJIpU6Zw9tlnY2Z06tSJjz/+GIC//vWvTJkyRSObiuymadOmMW3atLhjRCJTLYNPgLOBxB0bOcAb4fRs4KeAA6+4exmwwswamVnbFMv+JUM5I5Vs9NEWLVowZswYXn75ZYqLi7npppto1Cj1f5bDDz+cE044gYEDB/Ltt99y1FFH0a5dO37zm99wzTXX8NJLL9GkSRPuuusuVq9ezcSJEznyyCPp1y97nt8sUlu0adMm7giRaVBWVpaRDZtZB2Cqu3c1s9Xu/l/h/F7ApcASYK27TwznvxnOf7Pysu5+YeXt5+XllTVr1iwj2YuLi2nSpMmuF8wyyh2d2pgZlLuq/vKX4HfoWWedVaX1Fi9eDEBJSUn5j7sf/vCHNRuumjZt2kROTs4OXRdRnUCu2FfRAigCNoTTlecnWzap6gwznY7qDmEdN+WOTm3MDMpdVVdccQUAY8aMqdJ6BQUFABQWFtI2vGcpW/Z7Xl5e0vlR3YH8vpnlhtN9gHnAW8BpZtbQzA4CGrr7mhTLiohIBkXVMrgGeMTMGgP5wDR3LzWzecB8gqJ0ZaplI8ooIrJb5s6dG3eEastYMXD35UDXcHopwZVDlZcZD4yvNC/psiIikjkaqE5ERHQHsohIKrNmzYo7QmTqdDGobv9dYWFh+dUAFeXm5u5y3ZUrV3LnnXdSVFTE1q1bOfzwwxk1ahTNmzfnnXfe4cEHH6SsrIytW7dy2mmnMXjwYBo0aMCgQYPYvHkzTZs2ZevWrbRv354bbriBVq1aVes7iMjuy9Tl69lI3UQ1qLi4mGHDhnHZZZcxZcoUpk6dytFHH80111zD0qVLueOOO5gwYQJTpkzhqaee4pNPPuHRRx8tX/+OO+4oX69Hjx789re/jfHbiMiDDz7Igw8+GHeMSKgY1KC5c+dy3HHHcfTRR5fPO+uss/jqq6+YMGECQ4YM4Xvf+x4AjRo1YvTo0SkfnPHzn/+cf/3rX2zZsiWS7CKyo+eee47nnnsu7hiRUDGoQStXruSggw7aYX779u1ZsGDBDu81b96czZs3pxw/qGXLlmzYsCEjWUVEKlIxqEHt2rVj1apVO8z/7LPP6NKlC59//vl28zdu3Ejjxo23G5AuoaysjDVr1rDffvtlLK+ISIKKQQ065ZRTePvtt/nggw/K5z3//PO0atWKUaNGMXHiRAoLCwHYunUrt956KwMGDEi6rWnTptG1a9ekhUJEpKbV6auJorb33nszadIkbrvtNoqKiigtLcXMuOeee2jZsiUjR45k5MiRlJaWUlJSwqmnnspll11Wvv51111H06ZNgaCVMW7cuLi+iojUM3W6GKRzKWgyuzMo1kEHHcSkSZOSvte9e3e6d++e9L0pU6YknS8i8anNw0tUlfogRERExUBEJJUJEyYwYcKEuGNEQsVARCSFmTNnMnPmzLhjRELFQEREVAxERETFQEREqOOXloqI7I7EfT/1gYqBiEgKs2fPjjtCZNRNJCIiKgYiIqncfPPN3HzzzXHHiISKgYhICnPmzGHOnDlxx4iEioGIiKgYiIiIioGIiKBLS0VEUkr3SYN1YahrFQMRkRSmT58ed4TIqJtIRESiaxmY2Z7AE0AHoBT4FVACPA6UAYuBK919m5mNA/qF749w94VR5RQRSbj++usBuP3222NOknlRdhP1BRq5+4lmdipwK7AnMNbd55rZJKC/mX0G9ASOBw4EpgPHRZhTRASA+fPnxx0hMlF2Ey0FGplZQ6AlsBXIAd4I358N9Aa6Aa+4e5m7rwjXaRthThGReifKlsFGgi6iJUAb4HSgh7uXhe9/DexDUCjWVlgvMb+w8gbz8/MzErS4uDhj284k5Y5ObcwMyl1VmzZtAnZ9rCks3OHwBEBJSUn5e9m+36MsBiOBl939ejM7EHgNaFzh/RZAEbAhnK48fwedO3fOSND8/PyMbTuTlDs6tTEzKHdVNWvWDNj1saagoCDp/MLCQtq2bZvWNqKSl5eXdH6U3URfAevD6XUE5wveN7PccF4fYB7wFnCamTU0s4OAhu6+JsKcIiIAtG/fnvbt28cdIxJRtgz+ADxmZvMIWgRjgPeAR8ysMZAPTHP30nCZ+QTF6soIM4qIlHvqqafijhCZyIqBu28EzkvyVs8ky44Hxmc4koiIhHTTmYhICiNGjGDEiBFxx4iEhqMQEUlh0aJFNbatxPhFubm5NbbNmqSWgYiIqBiIiIiKgYiIkMY5AzN7D3gKeNLd12U+kohIdjjssMPijhCZdE4g9wYuAF40s5XAZHd/NbOxRETi9/DDD8cdITK77CZy9yJ3fxC4DNgGPGNmC8zsrIynExGRSKTTTTQMuIhgzKDJwMUEQ0m8A/wlo+lERGJ0+eWXA/WjhZBON9EBwAB3X15h3lYzG5KZSCIi2WHp0qVxR4hMOlcTLQAuATCz/zOznwK4e/156oOISB2XTstgPHByOH0+wUNoXslUIBERiV46LYOt7r4eIPz/0sxGEhGRqKXTMlhoZs8QDCn9E+D9zEYSEckOxxxzTNwRIrPLYuDu/2NmZwIGPOfuL2Y8lYhIFrj33nvjjhCZXXYTmVkLgofRfAG0MrOLMp5KREQilU430f8Cq4GV4euynSwrIlJnXHjhhUD9eOJZOsWgobtfmPEkIiJZZtWqVXFHiEw6xeADMzseWETYKnD3bzMZSkREopVOMegJnFHhdRnQMTNxREQkDulcTXQ0gJntB6xzd50zEBGpY9IZqK4H8CCwB/C8mX3m7o9mPJmISMxOOOGEuCNEJp1uoluAHsB04DbgLUDFQETqvNtvvz3uCJFJZziKbeETzsrcvRj4OsOZREQkYum0DD42s9uB/cxsNPBZhjOJiGSFc845B4Dp06cnfX/u3LkRpsmsdFoGQwkKwN+BjcCvMppIRCRLrF27lrVr18YdIxLptAxOBD4K/wfQFXizOh9mZtcDPycY3uJB4A3gcYLLVRcDV7r7NjMbB/QDSoAR7r6wOp8nIiLpSacYXBH+fwPgSGA51SgGZpZLUFhOApoBo4B7gLHuPtfMJgH9zewzgnsbjgcOJDhxfVxVP09ERNKXzn0GAxPTZtYYeK6an3Ua8CHBc5NbAtcSdDm9Eb4/G/gp4MAr4f0MK8yskZm1dffCan6uiIjsQjotg8rLV/fu4zbAD4DTgYOBvxKMe5S4ie1rYB+CQlGxky4xX8VARCJ1yimnxB0hMuncdPYFQZ9+g3D5+6r5WWuBJeG4Rm5mxQTdQAktgCJgQzhdef4O8vPzqxll54qLizO27UxS7ujUxsyg3FV17rnnAqmPNYWFO/+NWlJSssMy2br/0+km+n4NfdbfgeFmdg/wfWBvYI6Z5br7XKAP8DrwMXCnmU0A2hO0HtYk22Dnzp1rKNr28vPzM7btTFLu6NTGzKDcNSVxSWnbtm13ulxhYeEOy8T9PfLy8pLOT6dl8Fiq99z90nQDuPvMcGiLhQSXtF4JfAo8Ep6LyAemuXupmc0jeMxmYjkRkcj16dMHgNmzZ8ecJPPSOWewDfiE4Ff7j4GfAfdX58Pc/TdJZvdMstx4YHx1PkNEpKZs3rw57giRSacY/MDdLwun3zGz/u7+ciZDiYhItNIpBs3NrBfwLtA9w3lERCQG6RSDS4EJQAfgA+CXmQwkIiLRS+dqonwzGwkcCvwT+DzjqUREssDpp58ed4TIpHM10VXAWUBrgnGEDgWuymwsEZH4jRo1Ku4IkUln1NIBwKlAkbvfRzBmkIiI1CHpFIOGBHcgJ4aN2JK5OCIi2SM3N5fc3Ny4Y0QinRPIzxCMUvoDM5sFvJDRRCIiErl0isHfgDnADwF39w8yG0lERKKWTjF41N27EQwXISIidVDKYmBm+7j7euAbM/sDwXMGtgG4+8MR5RMRkQjsrGXwEtCNYDC5r4DvRZJIRCRLnHfeeXFHiMzOisFWM3uX4L6Cil1EZcBNGU0lIpIFhg0bFneEyOysGPQGDgAmAvVnj4iIhDZt2gRAs2bNYk6SeSmLgbuXAiuAftHFERHJHn379gW+e5hNXZbOTWciIlLHqRiIiIiKgYiIqBiIiAjp3YEsIlIvDR48OO4IkVExEBFJoXIxqImrihLbyLbRUNVNJCKSwpo1a1izZk3cMSKhloGISArnnnsuoPsMRESknlAxEBERFQMREVExEBERYjiBbGbfA/KAU4ES4HGCYbEXA1e6+zYzG0cwQF4JMMLdF0adU0TkiiuuiDtCZCItBma2J/AQsDmcdQ8w1t3nmtkkoL+ZfQb0BI4HDgSmA8dFmVNEBOD888+PO0Jkou4mmgBMAlaHr3OAN8Lp2QTPUOgGvOLuZe6+AmhkZm0jzikiwsqVK1m5cmXcMSIRWcvAzAYDhe7+spldH85u4O5l4fTXwD5AS2BthVUT8wsrbzM/P7/yrBpRXFycsW1nknJHpzZmBuWuqosvvhiAJ554AoDCwh0OQztVUlKScp1s++8QZTfRpUCZmfUGjgGeZPvnKrcAioAN4XTl+Tvo3LlzBmIG/5Eyte1MUu7o1MbMoNxVlXjCWeKzCwoKqrR+YWEhbdsm79iI679DXl5e0vmRFQN375GYNrO5wFDgLjPLdfe5QB/gdeBj4E4zmwC0Bxq6e/24H1xEslJ9uAM57uEorgEeMbPGQD4wzd1LzWweMJ/gnMaVcQYUEakPYikG7p5b4WXPJO+PB8ZHFEdEpN6Lu2UgIpK1rrnmmrgjREbFQEQkhTPOOAPQOQMRkXrN3eOOEBmNTSQiksKQIUMYMmRI3DEioWIgIiLqJhIRqazD6JcA+M+ytXTtuF/MaaKhloGIiKhlICL1R+IXP8Dy3/fb5fLNG3xLUVFRBhNlDxUDERG2LxQJh3Xryzld2idd/t5Xl5ZPj+h9WMZyRUXFQEQkhe8d3JmcnO8O9BULQF2jYiAi9VKylkBl6/+zkt89tZJ99j8wgkTx0glkEZEUPvzbc3z4t+fijhEJtQxEpNaq6glhSU3FQETqhFTdPlEUibpwMlnFQETqtHTODdSkioXhF0e3ivSzd4fOGYiIiFoGIiIVHdPo8/LpdSefGV+QiKkYiIik0Lp9p7gjREbFQESyXp8nlgHLgGivGlq36hOgfhQFFQMRqVWiPCH80esvANBtUN1//KWKgYhkpaivAqrvdDWRiIioZSAi8dJdxNlBLQMREVHLQESyR7adJ/jRqefFHSEyKgYiErlsO+inUh+Grk5QMRARYfs7jxO+/DQfCB5yU9dFVgzMbE/gMaADsBdwC/AR8DhQBiwGrnT3bWY2DugHlAAj3H1hVDlFRBKW/n0WUD+KQZQnkC8E1rp7d+BnwJ+Ae4Cx4bwGQH8z6wL0BI4HBgAPRJhRRKReirIYPA/cGE43IPjVnwO8Ec6bDfQGugGvuHuZu68AGplZ2whziojUO5F1E7n7RgAzawFMA8YCE9y9LFzka2AfoCWwtsKqifmFlbeZn5+fkazFxcUZ23YmKXd0amNmqL25a6uSkhIKC3c4dAGZO35VV6QnkM3sQOAvwIPu/oyZ3Vnh7RZAEbAhnK48fwedO2emHy8/Pz9j284k5Y5ObcwM2ZR7WdwBIvHsv74un678BLSCggIAcnNzo4xEXl5e0vlRnkBuB7wCXOXuc8LZ75tZrrvPBfoArwMfA3ea2QSgPdDQ3ddElVNEqq4230Wc7CqihKP7/iLCJPGKsmUwBmgF3GhmiXMHw4E/mlljIB+Y5u6lZjYPmE9wTuPKCDOKSA2qzUUCoMV++8cdITJRnjMYTnDwr6xnkmXHA+MzHElEZKf+s/SfAOx/2NExJ8k83XQmIpLCxwteBVQMRERqTLYNQbGzcwX1kYqBiOxUbe/3l/SoGIhItWTbL33ZPSoGIlKjVCRqJxUDEdmBDuiBnP6XxB0hMioGIpK2ulAkqnLiuGnL1hlMkl302EsRkRQ+/+hdPv/o3bhjREItAxGRFD7NexOAA444LuYkmaeWgYiIqGUgIoG6cD5Aqk/FQETqhbjvOL731aXl05WHs84GKgYi9Vh9aA3EUQS6rviQdw76UeSfuztUDETqge2HlMiGh9vUDsedM2S3t1FbCoOKgUg9Ux9aA1AzLYK9mjXfrfW7rvhwl8vMnTsXiP6JZ5XpaiIRkRRW/PNtVvzz7bSWrXzgT6cQZBMVAxGRFFZ8MJ8VH8yPO0Yk1E0kUgvVl66eXUnWFbSo5IDIc9S2VkAyKgYiWUzPEqh9khWG2nASWcVAJMuk+tWv1kB64ryfoDa3EHTOQEQkAtleKNQyEMkC+tVfNVH9+u864H+Szw+7fbL9AF8VKgYiGaZ+/9qr0Z6N444QGRUDkQipBVC7fPreXAAO/nFurDmioGIgUkN0oN99cQ8mV9nn+XlAUAwqdw3VdBdR3HciqxiIVNF3B/1lseaQzEh2GWhNFYDEtrNxBNOsLAZm1hB4EDga2AJc5u4fx5tK6pJ0+vH1S18AWm7ZWKPbSxSUVPcdxNVCyMpiAJwJNHH3E8ysK3A30D/eSJIJFX9l787J1XQO3OlsXwVg9yW6ehJ3Amdb10/l7p7EQbnir/7E9Ac1XAiqIuqikK3FoBvwfwDu/o6Z/TjmPFJJVa+QqepBNhMHZd3M9Z3KB+zK82vyM6JU8YC+s0s/kx34o5buXclRFYUGZWVlGf2A6jCzycB0d58dvl4BdHT3ksQyeXl52RdcRKQWyMnJaVB5Xra2DDYALSq8blixEEDyLyMiItWTrcNRvAX0BQjPGdSd2/xERLJQtrYM/gKcamZvAw2AS2LOIyJSp2XlOYMomNlZwH+7+wUVXk8AVoaLjAPmkeQS17C1ch9QArzi7r+LMfcpwC3AVuBL4CJ332Rm/wu0Cedvdvc+ZnYI8DhQBiwGrnT3bTHl3mEfprqkOM79HWYdDfwsfLkvsL+7729mI4HLgMLwvSHACuAp4HvA18DF7l5IDMysAbAK+Hc4a767X29mZwC/Jdifj7n7I2bWNBtym9k+YY6WQGPganefX5W/z6gzV1ZbL43P1m6ijDKz+4Db2f775wC/cffc8H9vUOESV2A0wSWuAJOACwiuejrezI6NMfeDwJnu3oPgj/6ycP6hQLfwu/QJ590DjHX37gQtrkgu102RO9k+PJMs2t8J7v77xL8LgoPrReFbOQTFN/FvxoErgA/DffwkMDbKrJV0Av5RId/1ZrYn8Afgp0BP4HIza0f25L4amOPuPYHBwAPh/Kr8fcbtTLIz107Vy2IAvE3wj7+iHOBSM5tnZnebWSMqXeIK/NjMWgJ7ufsn7l4GvAz0jjF3rrsXhNONgOLwj3tf4EUz+7uZnR6+nwO8EU7PJqbcO9mH2ba/t2NmZwNfufsr4awc4PpwH18fziv/DkS7j5PJAQ4ws9fNbJaZGdAZ+Njdv3L3b4G/Az3Intx/AB4KpxsBxeF0Wn+fUYdNIVtz7VS2njOoEWb2S2BkpdmXuPuzZpZbaf7fgBeATwl+iQ4laKqur7BMaThvQ4V5XwMday511XK7+xfhOmcDJwM3Am0Jfo3cB7QG3jKzhUCD8ICayL1PTLlT7cNY9ndFO/kO7wLXAwMrzJ9K8Mt1A/CXsOhW/A41vo9TSZH7SuB2d3/ezLoRdL+MZPt9nMgYee6d7Wsz258g74hwflp/n2bWqPKVhzHI1lw7VaeLgbs/Cjya5uKPuXsRQNjffg7Bf9DtLnFlx8teWwBFu5u1oirmJuy7Phf4mbsXm9l/gEnhP74vzex9wICK5wfizJ1qHzYjhv1dUarvYGZHAEWJvt+wP/5ed18fvn4JOLZS3oxmrShZbjNrRnBeAHf/u5n9F8GBPtn+jDz3Tvb1jwgK7aiwOwjS/PvMkgPuLi+Nz0b1tZtoO+Ef9gdm1j6cdQqQR5JLXN19A/CtmXUK1zuN4ERWLMzsBqA70Nvd14SzewPPh+83B34I5APvV/iF3oeYcu9kH2bz/u5N0H2S0BJYbGbNw1y9qPRvhhj3cWgc4S9rMzua4OTrR8ChZtbazBoTdBHNJ0tyh0X3eeCCCjedpv33GX3ipLI1107V6ZZButy9zMwuA2aY2WaCP5hHCLopkl3iOhR4GtiD4OqWBTHEJjw3MA74BzA76BLmWXefaGanmdk7BK2BMe6+xsyuAR4JDwL5wLQ4cod22Idm9i7Zu7+NoKsCAHdfb2ZjgNcJrhiZ4+6zzGwu8ISZ/R34luDEd1x+DzxlZv0IWgiD3X2rmV1NcO6lIcEv7s/NbCLZkft2oAlwX/jveb2796/i32fcauWl8fX20lIREfmOuolERETFQEREVAxERAQVAxERQcVARERQMRDZLWZ2VdwZRGqCioHI7olzIDqRGqP7DEQqCUf2nEQw8mtDggP+HwkG+TuKYAjw/sBVBDf9TQYWApeGy48D9ie4+3cLwWiylwO/IBjRsgXB8OI3Edyd+pS7/yT87GeBu919Yca/qEgFahmI7OgyYE04LHh/gsHoWgJ/DodW/hzo4+63AuvcfVi43lfu3g1YBPwO6BW+LiJ41gHA3sCpBENI3wMsAzab2RFm1ho4WIVA4qDhKER29COgu5kdH75uRPBL/v3w9UqCIRMq8/D/OwL/cvevw9dvEhz8FwBvhA8UKjCzrwhGmH2EYOz+xINxRCKnloHIjpYQtAJyCQZtex5YR9A9VFmDCtOJUWE/BY4ws73D1z2BpeF0DpSPK9WS4Ol00wiKxVmoGEhMVAxEdvQQcLiZvUHwYJ7P2H7474o+MrPtDuDh6LHjgNfDwQLbABPDt/c3sznAS8Awdy9192KC1sOX7r6u5r+OyK7pBLJIRMxsMHC4u49O8t4DwHR3fy3yYCKoZSASOzN7BWilQiBxUstARETUMhARERUDERFBxUBERFAxEBERVAxERAQVAxERAf4/sE0+ZRB2ov8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "energy  lr_auc 0.07529751804220233 Best Threshold=-2.45090913772583, G-Mean=0.8573427660019882, TPR=0.8729372937293729, FPR=0.15797317436661698\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8328 -70.565788         6644          2070              6394           0.762451             0.733762\n",
      "1     exit_2       3356        7930         0.8505 -79.337341         1061          1059               920           0.500472             0.433962\n",
      "2  Main_exit       2295        6871         0.9394         NA         2295          6871              1921           0.250382             0.209579\n"
     ]
    }
   ],
   "source": [
    "evaluate.buildCompareDistribPlot(output_ID, output_OOD, [\"energy\"], \"gmean\",plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d41005b-ddcb-41e9-b000-914cf4dd8d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  energy threshold:  gmean\n",
      "energy  lr_auc 0.16797340378359926 Best Threshold=-31.158634185791016, G-Mean=0.7677011723681414, TPR=0.8454968944099379, FPR=0.3029364224137931\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "energy  lr_auc 0.1640018737186706 Best Threshold=-39.64511489868164, G-Mean=0.7648927562520043, TPR=0.7669270833333334, FPR=0.23713617463617465\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exit_1', 'exit_2']\n",
      "energy  lr_auc 0.07529751804220233 Best Threshold=-2.45090913772583, G-Mean=0.8573427660019882, TPR=0.8729372937293729, FPR=0.15797317436661698\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_exit\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.7424 -31.158634         5574          2053              5175           0.730825             0.678511\n",
      "1     exit_2       4426        7947         0.7696 -39.645115         1795          1742              1445           0.507492             0.408538\n",
      "2  Main_exit       2631        6205         0.9394         NA         2631          6205              2289           0.297759             0.259054\n"
     ]
    }
   ],
   "source": [
    "# buildCompareDistribPlot(output_ID, output_OOD, [\"energy\"], \"PR_AUC\",plot=False)\n",
    "\n",
    "evaluate.buildCompareDistribPlot(output_ID, output_OOD, [\"energy\"], \"gmean\",plot=True)\n",
    "# evaluate.buildCompareDistribPlot(output_ID, output_OOD, [\"uncert\"], \"gmean\",plot=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfc533b9-cb9f-4a77-adaf-eb0059b08e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "entropy  lr_auc 0.14161445588079627 Best Threshold=0.3423153758049011, G-Mean=0.7816157424761103, TPR=0.7985074626865671, FPR=0.23491864831038797\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.137654082629813 Best Threshold=0.28195253014564514, G-Mean=0.7901470688963526, TPR=0.8278520041109969, FPR=0.24584057611124907\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.0751540025196899 Best Threshold=3.2358973026275635, G-Mean=0.8573427660019882, TPR=0.8729372937293729, FPR=0.15797317436661698\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.7990  0.342315         6519          2561              6113           0.717952             0.673238\n",
      "1     exit_2       3481        7439         0.8054  0.281953         1235          1549              1044           0.443606             0.375000\n",
      "2  Main_exit       2246        5890         0.9394        NA         2246          5890              1914           0.276057             0.235251\n",
      "metric:  calibration threshold:  gmean\n",
      "calibration  lr_auc 0.8580906481360406 Best Threshold=0.9432957172393799, G-Mean=0.7827125481264507, TPR=0.774468085106383, FPR=0.208955223880597\n",
      "['exit_1', 'exit_2']\n",
      "calibration  lr_auc 0.8631658262024245 Best Threshold=0.9475840330123901, G-Mean=0.7895391578108429, TPR=0.7731561956791656, FPR=0.19373072970195274\n",
      "['exit_1', 'exit_2']\n",
      "calibration  lr_auc 0.9253854542362902 Best Threshold=0.21752400696277618, G-Mean=0.8572885706881757, TPR=0.84192037470726, FPR=0.12706270627062707\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.7990  0.943296         6608          2718              6188           0.708557             0.663521\n",
      "1     exit_2       3392        7282         0.8054  0.947584         1282          1731              1063           0.425490             0.352805\n",
      "2  Main_exit       2110        5551         0.9394        NA         2110          5551              1798           0.275421             0.234695\n"
     ]
    }
   ],
   "source": [
    "evaluate.buildCompareDistribPlot(output_ID, output_OOD, [\"entropy\"], \"gmean\",plot=False)\n",
    "evaluate.buildCompareDistribPlot(output_ID, output_OOD, [\"calibration\"], \"gmean\",plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d538d10-cf5f-407f-9ba4-ae09ee417968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "398fe505-2e5c-4482-b74d-ecf6e9a83bf8",
   "metadata": {},
   "source": [
    "## Entropy Branch version\n",
    "Now we build a branched model with the entropy metric and cross entropy loss for comparision.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9830e9-6e36-4f63-8de8-aa31f6194375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Branchpoint by id number\n",
      "Matching Branchpoint by name\n",
      "add Branch to branch point  mixed0\n",
      "add Branch to branch point  mixed1\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "[<KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'classification')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit')>, <KerasTensor: shape=(None, 10) dtype=float32 (created by layer 'branch_exit_1')>]\n",
      "branch added <brevis.core_v2.BranchModel object at 0x000001DC76EB0848>\n",
      "\n",
      "preset: Other\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "lambda_callback = lambda_update(1000,0,max_t = 0.01)\n",
    "# branch_loss = brevisEnergy(lambda_callback)\n",
    "branch_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "trunk_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "# loss = kl_loss(lambda_callback)\n",
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=4,restore_best_weights=True)\n",
    "\n",
    "\n",
    "model = brevis.BranchModel(name=\"./models/inception_finetuned.hdf5\", custom_objects={})\n",
    "# model.add_branches([_branch_flat,_branch_flat],\n",
    "#                           [\"conv2_block1_out\",\"conv2_block3_out\",\n",
    "#                             # \"dense\"\n",
    "#                           ],\n",
    "#                           target_input=False,loop=False,num_outputs=10)\n",
    "\n",
    "model.add_branches([_branch_conv2,_branch_conv2],\n",
    "                          [\"mixed0\",\"mixed1\",#\"mixed6\"\n",
    "                          ],\n",
    "                          target_input=False,loop=False,num_outputs=10)\n",
    "# model.compile(loss = [trunk_loss,loss_fn,loss_fn], optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),metrics=['accuracy'])\n",
    "model.compile(loss=[trunk_loss,branch_loss,branch_loss], \n",
    "                  optimizer=tf.optimizers.SGD(learning_rate=0.001, momentum=0.9),\n",
    "                  # optimizer=\"adam\",\n",
    "              preset=\"\", metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ead96e-2332-469c-86c7-c05fabff94c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing Main Layers and setting branch layers training to true\n",
      "annealing coef updated to: 0\n",
      "Epoch 1/5\n",
      "   6/1407 [..............................] - ETA: 5:22 - loss: 6.7994 - classification_loss: 0.0045 - branch_exit_loss: 3.3174 - branch_exit_1_loss: 3.4775 - classification_accuracy: 1.0000 - branch_exit_accuracy: 0.1354 - branch_exit_1_accuracy: 0.1146WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1214s vs `on_train_batch_end` time: 0.1350s). Check your callbacks.\n",
      "1407/1407 [==============================] - 356s 245ms/step - loss: 2.1845 - classification_loss: 0.0415 - branch_exit_loss: 1.0931 - branch_exit_1_loss: 1.0498 - classification_accuracy: 0.9855 - branch_exit_accuracy: 0.6214 - branch_exit_1_accuracy: 0.6342 - val_loss: 1.5822 - val_classification_loss: 0.0222 - val_branch_exit_loss: 0.7844 - val_branch_exit_1_loss: 0.7756 - val_classification_accuracy: 0.9926 - val_branch_exit_accuracy: 0.7164 - val_branch_exit_1_accuracy: 0.7246\n",
      "annealing coef updated to: 0.001\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 329s 232ms/step - loss: 1.3876 - classification_loss: 0.0258 - branch_exit_loss: 0.7093 - branch_exit_1_loss: 0.6525 - classification_accuracy: 0.9915 - branch_exit_accuracy: 0.7524 - branch_exit_1_accuracy: 0.7702 - val_loss: 1.3860 - val_classification_loss: 0.0156 - val_branch_exit_loss: 0.6570 - val_branch_exit_1_loss: 0.7133 - val_classification_accuracy: 0.9946 - val_branch_exit_accuracy: 0.7676 - val_branch_exit_1_accuracy: 0.7510\n",
      "annealing coef updated to: 0.002\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 316s 223ms/step - loss: 1.0644 - classification_loss: 0.0161 - branch_exit_loss: 0.5537 - branch_exit_1_loss: 0.4946 - classification_accuracy: 0.9951 - branch_exit_accuracy: 0.8047 - branch_exit_1_accuracy: 0.8264 - val_loss: 1.1046 - val_classification_loss: 0.0221 - val_branch_exit_loss: 0.5553 - val_branch_exit_1_loss: 0.5271 - val_classification_accuracy: 0.9926 - val_branch_exit_accuracy: 0.8054 - val_branch_exit_1_accuracy: 0.8130\n",
      "annealing coef updated to: 0.003\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 316s 223ms/step - loss: 0.8336 - classification_loss: 0.0132 - branch_exit_loss: 0.4414 - branch_exit_1_loss: 0.3790 - classification_accuracy: 0.9958 - branch_exit_accuracy: 0.8441 - branch_exit_1_accuracy: 0.8668 - val_loss: 1.1425 - val_classification_loss: 0.0247 - val_branch_exit_loss: 0.5996 - val_branch_exit_1_loss: 0.5181 - val_classification_accuracy: 0.9924 - val_branch_exit_accuracy: 0.7960 - val_branch_exit_1_accuracy: 0.8226\n",
      "annealing coef updated to: 0.004\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 317s 223ms/step - loss: 0.6509 - classification_loss: 0.0090 - branch_exit_loss: 0.3492 - branch_exit_1_loss: 0.2926 - classification_accuracy: 0.9971 - branch_exit_accuracy: 0.8767 - branch_exit_1_accuracy: 0.8957 - val_loss: 1.0666 - val_classification_loss: 0.0263 - val_branch_exit_loss: 0.5428 - val_branch_exit_1_loss: 0.4975 - val_classification_accuracy: 0.9916 - val_branch_exit_accuracy: 0.8116 - val_branch_exit_1_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<brevis.core_v2.BranchModel at 0x1dc74dae988>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 5, validation_data=validation_ds, transfer=True,callbacks=[lambda_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bede128-b080-45d0-b619-2c6e18c2c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 18s 57ms/step - loss: 1.3121 - classification_loss: 0.1717 - branch_exit_loss: 0.5767 - branch_exit_1_loss: 0.5637 - classification_accuracy: 0.9608 - branch_exit_accuracy: 0.8066 - branch_exit_1_accuracy: 0.8175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3121238946914673,\n",
       " 0.1716654747724533,\n",
       " 0.5767245292663574,\n",
       " 0.5637335181236267,\n",
       " 0.9607999920845032,\n",
       " 0.8065999746322632,\n",
       " 0.8174999952316284]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2afd5d43-5e44-413f-b697-315db34f9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/journal_models/inception_B_conv3_5.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd0a6a2-77ad-4e30-b7fe-50d20d3cbdeb",
   "metadata": {},
   "source": [
    "## Get the Branch output results\n",
    "Collect the branch output results for both the ID and OOD test sets then evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927906b4-4979-4bf3-ab12-87e740cfa58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# metrics =[\"energy\",\"entropy\",\"uncert\",\"confidence_alea_uncert\",\"entropy_of_expected\",\"expected_entropy\",\"calibration\"]\n",
    "# metrics =['energy','uncert','expected_entropy','calibration']\n",
    "\n",
    "metrics = [\"energy\",\"entropy\",\"uncert\",\"confidence_alea_uncert\",\"entropy_of_expected\",\"expected_entropy\",\"calibration\"]\n",
    "def calc_auc_OOD(ID,OOD,metrics=['energy'],OOD_rate=[.1,.2,.5,1], plot=False):\n",
    "    points = []\n",
    "    # OOD_rate = [0,.1,.2,.5,1]\n",
    "    _output_ID = ID\n",
    "    _output_OOD = OOD\n",
    "\n",
    "    _output_ID[\"outlier\"]=0\n",
    "    _output_OOD[\"outlier\"]=1\n",
    "    lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "    _thresholds = []\n",
    "    for i in OOD_rate:\n",
    "        # print(int(min((len(_output_ID) * i),len(_output_ID))))\n",
    "        _OOD = _output_OOD.iloc[0:int(min((len(_output_ID) * i),len(_output_ID)))]\n",
    "        print(\"OOD size\",len(_OOD))\n",
    "        _df = pd.concat([_output_ID,_OOD], ignore_index=True)\n",
    "        y_true = np.int32(_df['outlier'])\n",
    "\n",
    "    #     print(len(_df))\n",
    "    #     for metric in metrics:\n",
    "    #         points.append([])\n",
    "    #         # print(metric, \":\", average_precision_score(y_true, _df[metric]))\n",
    "\n",
    "    #         Correct = _df.loc[(_df['correct'] == True)]\n",
    "    #         Incorrect = _df.loc[(_df['correct'] == False)]\n",
    "    #         fpr, tpr, thresholds = roc_curve(np.int32(_output_ID['correct']), _output_ID[metric],pos_label=1)\n",
    "    #         gmeans = sqrt(tpr * (1-fpr))\n",
    "    #         ix = argmax(gmeans)\n",
    "    #         _threshold = thresholds[ix]\n",
    "    #         # _threshold = np.array(Correct[metric]).mean()\n",
    "        plots = []\n",
    "        for metric in metrics:    \n",
    "            lr_auc = roc_auc_score(y_true, _df[metric])\n",
    "            print(\"lr_auc\",lr_auc)\n",
    "            if metric in lessThanMetrics:\n",
    "                pos_label = 0\n",
    "            else:\n",
    "                pos_label = 1\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, _df[metric],pos_label=pos_label)\n",
    "            gmeans = sqrt(tpr * (1-fpr))\n",
    "            # print(gmeans)\n",
    "            # locate the index of the largest g-mean\n",
    "            ix = argmax(gmeans)\n",
    "            threshold = thresholds[ix]\n",
    "            print('Best Threshold={}, G-Mean={}, TPR={}, FPR={}'.format(threshold, gmeans[ix],tpr[ix],fpr[ix]))\n",
    "            _thresholds.append(threshold)\n",
    "            # plot the roc curve for the model\n",
    "            plots.append({\"fpr\":fpr,\"tpr\":tpr,\"label\":metric, \"ix\":ix})\n",
    "        # if plot:\n",
    "        pyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\n",
    "        for plot in plots:\n",
    "            ix = plot['ix']\n",
    "            pyplot.plot(plot[\"fpr\"], plot[\"tpr\"],  label=plot['label'])\n",
    "\n",
    "            pyplot.scatter(plot[\"fpr\"][ix], plot[\"tpr\"][ix], marker='o', color='black')\n",
    "        # axis labels\n",
    "        pyplot.xlabel('False Positive Rate')\n",
    "        pyplot.ylabel('True Positive Rate')\n",
    "        pyplot.title(metric)\n",
    "        pyplot.legend()\n",
    "        # show the plot\n",
    "        pyplot.show()\n",
    "\n",
    "# calc_auc_OOD(output_ID,output_OOD_svhn,metrics=metrics,OOD_rate=[1])       \n",
    "\n",
    "calc_auc_OOD(output_ID,output_OOD,metrics=metrics,OOD_rate=[1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e5320f-a0d6-47e2-ad65-c92914b9f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_auc_OOD(ID,OOD,metrics=[\"energy\"], threshold=None, legend=[\"In Distribution\",\"Out of Distribution\"],main_exit_included=True, OOD_rate=[.1,.2,.5,1], plot=True,exit_labels=['exit_1']):\n",
    "        lessThanMetrics = [\"energy\",\"uncert\",\"entropy\"]\n",
    "        if type(metrics ) is not list:\n",
    "            metrics = [metrics]\n",
    "        \n",
    "        for j, metric in enumerate(metrics):\n",
    "            print(\"metric: \", metric, \"threshold: \",threshold)\n",
    "            rollOver_ID_indices = pd.Index([])\n",
    "            rollOver_OOD_indices = pd.Index([])\n",
    "            Exit_Name=[]\n",
    "            _ID = ID.copy()\n",
    "            _OOD = OOD.copy()\n",
    "                # print(_branch_predictions)\n",
    "            if main_exit_included:\n",
    "                _ID.append(_ID.pop(0))\n",
    "                _OOD.append(_OOD.pop(0))\n",
    "            Accepted_df = pd.DataFrame()\n",
    "            Input_ID=[]\n",
    "            Input_OOD=[]\n",
    "            Accepted_list =[]\n",
    "            Accepted_ID_list = []\n",
    "            Accepted_OOD_list = []\n",
    "            Acceptance_correct =[]\n",
    "            Input_predictions =[]\n",
    "            Accepted_Ratio_list=[]\n",
    "            Accepted_Accuracy_list=[]\n",
    "            # Branch_cost =[17443270,29419724,132134023] #flat exit costs\n",
    "            # Branch_cost =[482376,1517643,80095445,114361924,112698838] #Conv2d exit costs\n",
    "\n",
    "            # Base_cost = 112698838\n",
    "            Branch_flops = []\n",
    "            Thresholds=[]\n",
    "            Test_accuracy =[]\n",
    "            Rollover_accuracy=[]\n",
    "            Results=[]\n",
    "            for rate in OOD_rate:\n",
    "                # print(int(min((len(_output_ID) * i),len(_output_ID))))\n",
    "                print(\"OOD size\",rate)\n",
    "                _OOD_frac=[]\n",
    "                Exit_Name=[]\n",
    "                rollOver_ID_indices = pd.Index([])\n",
    "                rollOver_OOD_indices = pd.Index([])\n",
    "                Input_ID=[]\n",
    "                Input_OOD=[]\n",
    "                Accepted_list =[]\n",
    "                Accepted_ID_list = []\n",
    "                Accepted_OOD_list = []\n",
    "                Acceptance_correct =[]\n",
    "                Input_predictions =[]\n",
    "                Accepted_Ratio_list=[]\n",
    "                Accepted_Accuracy_list=[]\n",
    "                # Branch_cost =[17443270,29419724,132134023] #flat exit costs\n",
    "                # Branch_cost =[482376,1517643,80095445,114361924,112698838] #Conv2d exit costs\n",
    "\n",
    "                # Base_cost = 112698838\n",
    "                Branch_flops = []\n",
    "                Thresholds=[]\n",
    "                Test_accuracy =[]\n",
    "                Rollover_accuracy=[]\n",
    "                Results=[]\n",
    "                for i, output in enumerate(_OOD):\n",
    "                    \n",
    "                    amount = min(len(_ID[i]) * rate,len(_ID[i]))\n",
    "                    # print(\"len\",amount)\n",
    "                    _OOD_frac.append(_OOD[i].iloc[0:int(amount)])\n",
    "                    # print(len(_OOD_frac[i]),len(_ID[i]))\n",
    "                # _df = pd.concat([_ID,_OOD], ignore_index=True)\n",
    "                # y_true = np.int32(_df['outlier'])\n",
    "                for i, (output_ID, output_OOD) in enumerate(zip(_ID, _OOD_frac)): \n",
    "                    Test_accuracy.append(len(output_ID.loc[(output_ID[\"correct\"] == True)])/len(output_ID))\n",
    "\n",
    "                    legend = [\"threshold\",\"correct\",\"incorrect\", \"OOD\"]\n",
    "                    Correct = output_ID.loc[(output_ID['correct'] == True)]\n",
    "                    Incorrect = output_ID.loc[(output_ID['correct'] == False)]\n",
    "                    if plot:\n",
    "                        _ = plt.hist(Correct[metric].tolist(), bins=100)  # arguments are passed to np.histogram\n",
    "                        _ = plt.hist(Incorrect[metric].tolist(), bins=100,color =\"red\", alpha = 0.5)  # arguments are passed to np.histogram\n",
    "                        _ = plt.hist(output_OOD[metric].tolist(), bins=100,color=\"grey\",alpha=0.5)  # arguments are passed to np.histogram\n",
    "\n",
    "\n",
    "                    if threshold:\n",
    "                        if type(threshold) is list:\n",
    "                            if j >= len(threshold): #no threshold in the array so treat as None.\n",
    "                                continue\n",
    "                            _threshold = threshold[j]\n",
    "                        else:\n",
    "                            _threshold = threshold\n",
    "                        if _threshold == \"mean\":\n",
    "                            # _threshold = np.array(ID[metric]).mean()\n",
    "                            Correct = output_ID.loc[(output_ID[\"correct\"] == True)]\n",
    "                            _threshold = np.array(Correct[metric]).mean()\n",
    "                        if _threshold == \"gmean\":\n",
    "                            AUC_thresholds = evaluate.calc_AUC(output_ID, metrics=metrics,plot = False)\n",
    "                            _threshold = AUC_thresholds[j]\n",
    "                        if _threshold == \"PR_AUC\":\n",
    "                            precision_, recall_, proba = precision_recall_curve(output_ID['correct'], output_ID[metric])\n",
    "                            _threshold = sorted(list(zip(np.abs(precision_ - recall_), proba)), key=lambda i: i[0], reverse=False)[0][1]\n",
    "                        else:\n",
    "                            _threshold = np.float32(_threshold)\n",
    "\n",
    "                    if len(rollOver_ID_indices)>0:\n",
    "                        # print(\"rollover enabled, {} ID predictions provided\".format(len(rollOver_ID_indices)))\n",
    "                        output_ID = output_ID.iloc[rollOver_ID_indices]\n",
    "                    if len(rollOver_OOD_indices)>0:\n",
    "                        # if plot:\n",
    "                        # print(\"rollover enabled, {} OOD predictions provided\".format(len(rollOver_OOD_indices)))\n",
    "                        output_OOD = output_OOD.iloc[rollOver_OOD_indices]\n",
    "\n",
    "                    if plot:\n",
    "                        plt.axvline(x=_threshold, color='k', linestyle='--',label=\"threshold\")\n",
    "                        plt.title(metric + \" outliers\")\n",
    "                        plt.legend(legend)\n",
    "                        plt.xlabel(\"entropy\")\n",
    "                        plt.ylabel(\"frequency\")\n",
    "                        plt.show()\n",
    "                    if main_exit_included and i == len(_ID)-1 :\n",
    "                        Exit_Name.append(\"Main_exit\")\n",
    "                        _threshold\n",
    "                        if plot:\n",
    "                            print(\"main_exit\")\n",
    "                        OOD_accepted = output_OOD\n",
    "                        OOD_rejected = None\n",
    "                        ID_accepted = output_ID\n",
    "                        ID_rejected = None\n",
    "                        accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                        rejected_correct = None\n",
    "                        accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                        rejected_incorrect = None\n",
    "                        accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                        overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                        _threshold = \"NA\"\n",
    "                        ### make a threshold that accepts everything, if less than, set to inf, if greater than, set to neg inf?\n",
    "                        # if metric in lessThanMetrics:\n",
    "                            # _threshold = math.inf\n",
    "                        # else:\n",
    "                            # _threshold = -math.inf\n",
    "                    # print(_threshold)\n",
    "                    else:\n",
    "                        if metric in lessThanMetrics: ## metrics that require less than metric\n",
    "                            OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() <= _threshold)] #FP\n",
    "                            OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() > _threshold)] #TN\n",
    "                            ID_accepted = output_ID.loc[(output_ID[metric] <= _threshold)] #TP\n",
    "                            ID_rejected = output_ID.loc[(output_ID[metric] > _threshold)] #FN\n",
    "\n",
    "\n",
    "                            accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                            rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "\n",
    "                            accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                            rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "                            accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                            overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                            # print(\"OOD accepted:\", len(OOD_accepted),\": with threshold:\",_threshold )\n",
    "                            # print(\"ID accepted:\", len(ID_accepted), \":with acc:\",(accepted_ID_acc))\n",
    "                            # print(\"overall Accepted acc:\",(overall_accepted_acc))\n",
    "\n",
    "                            # print(\"OOD accepted with avg ID \",metric,\" threshold of \",_threshold, \": \", len(OOD.loc[(OOD[metric].tolist() <= _threshold)]), \"out of \", len(OOD))\n",
    "                            # print(\"ID accepted with avg ID \",metric,\" threshold of \",_threshold, \": \", len(ID.loc[(ID[metric] <= _threshold)]), \"out of \", len(ID), \"with acc of \", len(ID.loc[(ID[metric] <= _threshold) & ID['correct'] == True])/len(ID.loc[(ID[metric] <= _threshold)]))\n",
    "                            # print(\"Overall accuracy of accepted inputs:\", len(ID.loc[(ID[metric] <= _threshold) & ID['correct'] == True])/(len(ID.loc[(ID[metric] <= _threshold)])+len(OOD.loc[(OOD[metric] <= _threshold)])))\n",
    "                        else: ### metrics that require greater than metric\n",
    "                            OOD_accepted = output_OOD.loc[(output_OOD[metric].tolist() >= _threshold)] #FP\n",
    "                            OOD_rejected = output_OOD.loc[(output_OOD[metric].tolist() < _threshold)] #TN\n",
    "                            ID_accepted = output_ID.loc[(output_ID[metric] >= _threshold)] #TP\n",
    "                            ID_rejected = output_ID.loc[(output_ID[metric] < _threshold)] #FN\n",
    "\n",
    "                            accepted_correct = ID_accepted.loc[(ID_accepted[\"correct\"] == True )] #TP\n",
    "                            rejected_correct = ID_rejected.loc[(ID_rejected[\"correct\"] == True)]  #FN\n",
    "\n",
    "                            accepted_incorrect = ID_accepted.loc[(ID_accepted[metric] ==False)] #FP\n",
    "                            rejected_incorrect = ID_rejected.loc[(ID_rejected[metric] ==False)] #TN\n",
    "\n",
    "\n",
    "\n",
    "                            accepted_ID_acc = len(accepted_correct) / (len( ID_accepted))\n",
    "                            overall_accepted_acc = len(accepted_correct) / (len( ID_accepted) + len(OOD_accepted))\n",
    "                            # print(\"OOD accepted:\", len(OOD_accepted),\": with threshold:\",_threshold )\n",
    "                            # print(\"ID accepted:\", len(ID_accepted), \":with acc:\",(accepted_ID_acc))\n",
    "                            # print(\"overall Accepted acc:\",(overall_accepted_acc))\n",
    "\n",
    "                            # print(\"OOD accepted with avg ID \",metric,\" threshold of \",_threshold, \": \", len(OOD.loc[(OOD[metric].tolist() >= _threshold)]), \"out of \", len(OOD))\n",
    "                            # print(\"ID accepted with avg ID \",metric,\" threshold of \",_threshold, \": \", len(ID.loc[(ID[metric] >= _threshold)]), \"out of \", len(ID), \"with acc of \", len(ID.loc[(ID[metric] >= _threshold) & ID['correct'] == True])/len(ID.loc[(ID[metric] >= _threshold)]))\n",
    "                            # print(\"Overall accuracy of accepted inputs:\", len(ID.loc[(ID[metric] <= _threshold) & ID['correct'] == True])/(len(ID.loc[(ID[metric] >= _threshold)])+len(OOD.loc[(OOD[metric] >= _threshold)])))\n",
    "                        rollOver_ID_indices = ID_rejected.index\n",
    "                        rollOver_OOD_indices = OOD_rejected.index\n",
    "                        if i >= len(exit_labels):\n",
    "                            exit_labels.append(\"exit_{}\".format(i+1))\n",
    "                        print(exit_labels)\n",
    "                        Exit_Name.append(exit_labels[i])\n",
    "                    Thresholds.append(_threshold)\n",
    "\n",
    "                    Results.append(accepted_correct +accepted_incorrect)\n",
    "                    Input_ID.append(len(output_ID))\n",
    "                    Input_OOD.append(len(output_OOD))\n",
    "                    Accepted_ID_list.append(len(ID_accepted))\n",
    "                    Accepted_OOD_list.append(len(OOD_accepted))\n",
    "                    Accepted_Ratio_list.append(len(ID_accepted)/(len(ID_accepted)+ len(OOD_accepted)))\n",
    "                    Acceptance_correct.append(len(accepted_correct))\n",
    "                    Accepted_Accuracy_list.append(overall_accepted_acc)\n",
    "                df = pd.DataFrame({\n",
    "                \"Exit_Name\":Exit_Name,\n",
    "                \"ID_Inputs\":Input_ID,\n",
    "                \"OOD_Inputs\":Input_OOD,\n",
    "                \"Test_Accuracy\":Test_accuracy,\n",
    "                # \"RollOver_Accuracy\":Rollover_accuracy,\n",
    "                \"Threshold\":Thresholds,\n",
    "                \"Accepted ID\":Accepted_ID_list,\n",
    "                \"Accepted OOD\":Accepted_OOD_list,\n",
    "\n",
    "                \"Accepted_Correct\":Acceptance_correct,\n",
    "                \"Accepted_ID_Ratio\":Accepted_Ratio_list,\n",
    "                \"Acceptance_Accuracy\":Accepted_Accuracy_list,\n",
    "\n",
    "                # \"Flops\":Branch_flops,\n",
    "                # \"Cost Ratio\":,                                  \n",
    "                              })\n",
    "                with pd.option_context('expand_frame_repr', False):\n",
    "                    print (df)\n",
    "                # print(\"TPR_ID-OOD\",len(ID_accepted)/(len(ID_accepted) + len(ID_rejected)))\n",
    "                # print(\"TPR_acc\",len(accepted_correct)/(len(accepted_correct) + len(rejected_correct)))\n",
    "                # if len(OOD) > 0:\n",
    "                #     print(\"FPR_ID-OOD\",len(OOD_accepted)/(len(OOD_accepted) + len(OOD_rejected)))\n",
    "                # else: \n",
    "                #     print(\"FPR for OOD is div by zero, was OOD included?\")\n",
    "                # print(\"FPR_acc\",len(accepted_incorrect)/(len(accepted_incorrect) + len(rejected_incorrect)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5095d99-7c6b-420d-a8f2-62d141546cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "OOD size 0.1\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        1000         0.8280  3.219811         6408           217              6153           0.967245             0.928755\n",
      "1     exit_2       3592         783         0.8366  3.220037         1143           147               997           0.886047             0.772868\n",
      "2  Main_exit       2449         636         0.8411        NA         2449           636              1567           0.793841             0.507942\n",
      "OOD size 0.2\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        2000         0.8280  3.219811         6408           420              6153           0.938489             0.901142\n",
      "1     exit_2       3592        1580         0.8366  3.220037         1143           265               997           0.811790             0.708097\n",
      "2  Main_exit       2449        1315         0.8411        NA         2449          1315              1567           0.650638             0.416312\n",
      "OOD size 0.5\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        5000         0.8280  3.219811         6408          1066              6153           0.857372             0.823254\n",
      "1     exit_2       3592        3934         0.8366  3.220037         1143           668               997           0.631143             0.550525\n",
      "2  Main_exit       2449        3266         0.8411        NA         2449          3266              1567           0.428521             0.274191\n",
      "OOD size 1\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8280  3.219811         6408          2139              6153           0.749737             0.719902\n",
      "1     exit_2       3592        7861         0.8366  3.220037         1143          1319               997           0.464257             0.404955\n",
      "2  Main_exit       2449        6542         0.8411        NA         2449          6542              1567           0.272383             0.174285\n"
     ]
    }
   ],
   "source": [
    "calc_auc_OOD(output_ID, output_OOD, [\"entropy\"], \"gmean\",OOD_rate=[.1,.2,.5,1],plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "711bac0b-636c-4569-820e-041947fb656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  energy threshold:  gmean\n",
      "OOD size 0.1\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        1000         0.8299 -84.521584         6404           200              6071           0.969715             0.919291\n",
      "1     exit_2       3596         800         0.8335  -84.60231         1088           108               938           0.909699             0.784281\n",
      "2  Main_exit       2508         692         0.9394         NA         2508           692              2150           0.783750             0.671875\n",
      "OOD size 0.2\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        2000         0.8299 -84.521584         6404           383              6071           0.943569             0.894504\n",
      "1     exit_2       3596        1617         0.8335  -84.60231         1088           215               938           0.834996             0.719877\n",
      "2  Main_exit       2508        1402         0.9394         NA         2508          1402              2150           0.641432             0.549872\n",
      "OOD size 0.5\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        5000         0.8299 -84.521584         6404           968              6071           0.868692             0.823521\n",
      "1     exit_2       3596        4032         0.8335  -84.60231         1088           494               938           0.687737             0.592920\n",
      "2  Main_exit       2508        3538         0.9394         NA         2508          3538              2150           0.414820             0.355607\n",
      "OOD size 1\n",
      "['exit_1', 'exit_2']\n",
      "['exit_1', 'exit_2']\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy  Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8299 -84.521584         6404          1955              6071           0.766120             0.726283\n",
      "1     exit_2       3596        8045         0.8335  -84.60231         1088           936               938           0.537549             0.463439\n",
      "2  Main_exit       2508        7109         0.9394         NA         2508          7109              2150           0.260788             0.223562\n"
     ]
    }
   ],
   "source": [
    "calc_auc_OOD(output_ID, output_OOD, [\"energy\"], \"gmean\",OOD_rate=[.1,.2,.5,1],plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b50bac7f-e3f3-4c72-9118-a02ffa66f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric:  entropy threshold:  gmean\n",
      "OOD size 0.1\n",
      "entropy  lr_auc 0.12849606083586113 Best Threshold=3.2198143005371094, G-Mean=0.7958496889074013, TPR=0.8523255813953489, FPR=0.2568840579710145\n",
      "['exit_1']\n",
      "entropy  lr_auc 0.12466646047371904 Best Threshold=3.2200355529785156, G-Mean=0.8054832866006317, TPR=0.8408812729498164, FPR=0.22842457566339947\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.13248245670676545 Best Threshold=3.2185394763946533, G-Mean=0.7972006669250856, TPR=0.8439269981120201, FPR=0.2469385328736179\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        1000         0.8280  3.219814         6408           217              6153           0.967245             0.928755\n",
      "1     exit_2       3592         783         0.8366  3.220036         1143           147               997           0.886047             0.772868\n",
      "2  Main_exit       2449         636         0.8411        NA         2449           636              1567           0.793841             0.507942\n",
      "OOD size 0.2\n",
      "entropy  lr_auc 0.12849606083586113 Best Threshold=3.2198143005371094, G-Mean=0.7958496889074013, TPR=0.8523255813953489, FPR=0.2568840579710145\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.12466646047371904 Best Threshold=3.2200355529785156, G-Mean=0.8054832866006317, TPR=0.8408812729498164, FPR=0.22842457566339947\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.13248245670676545 Best Threshold=3.2185394763946533, G-Mean=0.7972006669250856, TPR=0.8439269981120201, FPR=0.2469385328736179\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        2000         0.8280  3.219814         6408           420              6153           0.938489             0.901142\n",
      "1     exit_2       3592        1580         0.8366  3.220036         1143           265               997           0.811790             0.708097\n",
      "2  Main_exit       2449        1315         0.8411        NA         2449          1315              1567           0.650638             0.416312\n",
      "OOD size 0.5\n",
      "entropy  lr_auc 0.12849606083586113 Best Threshold=3.2198143005371094, G-Mean=0.7958496889074013, TPR=0.8523255813953489, FPR=0.2568840579710145\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.12466646047371904 Best Threshold=3.2200355529785156, G-Mean=0.8054832866006317, TPR=0.8408812729498164, FPR=0.22842457566339947\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.13248245670676545 Best Threshold=3.2185394763946533, G-Mean=0.7972006669250856, TPR=0.8439269981120201, FPR=0.2469385328736179\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000        5000         0.8280  3.219814         6408          1066              6153           0.857372             0.823254\n",
      "1     exit_2       3592        3934         0.8366  3.220036         1143           668               997           0.631143             0.550525\n",
      "2  Main_exit       2449        3266         0.8411        NA         2449          3266              1567           0.428521             0.274191\n",
      "OOD size 1\n",
      "entropy  lr_auc 0.12849606083586113 Best Threshold=3.2198143005371094, G-Mean=0.7958496889074013, TPR=0.8523255813953489, FPR=0.2568840579710145\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.12466646047371904 Best Threshold=3.2200355529785156, G-Mean=0.8054832866006317, TPR=0.8408812729498164, FPR=0.22842457566339947\n",
      "['exit_1', 'exit_2']\n",
      "entropy  lr_auc 0.13248245670676545 Best Threshold=3.2185394763946533, G-Mean=0.7972006669250856, TPR=0.8439269981120201, FPR=0.2469385328736179\n",
      "   Exit_Name  ID_Inputs  OOD_Inputs  Test_Accuracy Threshold  Accepted ID  Accepted OOD  Accepted_Correct  Accepted_ID_Ratio  Acceptance_Accuracy\n",
      "0     exit_1      10000       10000         0.8280  3.219814         6408          2139              6153           0.749737             0.719902\n",
      "1     exit_2       3592        7861         0.8366  3.220036         1143          1319               997           0.464257             0.404955\n",
      "2  Main_exit       2449        6542         0.8411        NA         2449          6542              1567           0.272383             0.174285\n"
     ]
    }
   ],
   "source": [
    "calc_auc_OOD(output_ID, output_OOD, [\"entropy\"], \"gmean\",OOD_rate=[.1,.2,.5,1],plot=False)\n",
    "\n",
    "# 268,519,1273,2539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf064d-0dd6-49fd-b62a-84aeb11863da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95, 181, 417, 798"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
