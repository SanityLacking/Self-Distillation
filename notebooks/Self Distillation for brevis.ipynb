{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Distillation rebuilt\n",
    "\n",
    "## A new from the ground attempt at self distillation to try to sort out some of the issues that we faced in previous builds and testing.\n",
    "\n",
    "## A new notebook for a new year.\n",
    "---\n",
    "## Primary issues\n",
    "The main problems faced previously were to do with establishing a baseline of performance of a model to compare the self distilation work against. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching\n",
    "# dataset = branching.dataset.prepare.dataset(tf.keras.datasets.cifar10.load_data(),64,5000,22500,(227,227),include_targets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = tf.keras.models.clone_model(student)\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=1,        \n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                (teacher_predictions / self.temperature),\n",
    "                (student_predictions / self.temperature),\n",
    "            )\n",
    "            student_loss = student_loss * self.alpha\n",
    "            distillation_loss = (distillation_loss) * (1 - self.alpha)\n",
    "#             loss = distillation_loss\n",
    "            loss=student_loss +distillation_loss\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"loss\":loss,\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def summarize_keras_trainable_variables(model, message):\n",
    "    s = sum(map(lambda x: x.sum(), model.get_weights()))\n",
    "    print(\"summary of trainable variables %s: %.13f\" % (message, s))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# tf.debugging.experimental.enable_dump_debug_info(logdir, tensor_debug_mode=\"FULL_HEALTH\", circular_buffer_size=-1)\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "CLASS_NAMES= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# import csv\n",
    "# with open('results/altTrain_labels.csv', newline='') as f:\n",
    "    # reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    # alt_trainLabels = list(reader)\n",
    "# with open('results/altTest_labels.csv', newline='') as f:\n",
    "    # reader = csv.reader(f,quoting=csv.QUOTE_NONNUMERIC)\n",
    "    # alt_testLabels = list(reader)\n",
    "\n",
    "# altTraining = tf.data.Dataset.from_tensor_slices((train_images,alt_trainLabels))\n",
    "\n",
    "# validation_images, validation_labels = train_images[:5000], alt_trainLabels[:5000]\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_images, alt_trainLabels))\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_images, alt_testLabels))\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels,10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels,10)\n",
    "\n",
    "###normal method\n",
    "validation_images, validation_labels = train_images[:5000], train_labels[:5000] #get the first 5k training samples as validation set\n",
    "train_images, train_labels = train_images[5000:], train_labels[5000:] # now remove the validation set from the training set.\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "\n",
    "def augment_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    # image = tf.image.per_image_standardization(image)\n",
    "    # Resize images from 32x32 to 277x277\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label\n",
    "\n",
    "train_ds_size = len(list(train_ds))\n",
    "test_ds_size = len(list(test_ds))\n",
    "validation_ds_size = len(list(validation_ds))\n",
    "\n",
    "train_ds = (train_ds\n",
    "                  .map(augment_images)\n",
    "                  .shuffle(buffer_size=train_ds_size,seed=42,reshuffle_each_iteration=False)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "test_ds = (test_ds\n",
    "                  .map(augment_images)\n",
    "                #   .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "validation_ds = (validation_ds\n",
    "                  .map(augment_images)\n",
    "                #   .shuffle(buffer_size=validation_ds_size)\n",
    "                  .batch(batch_size=32, drop_remainder=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teacher = tf.keras.models.load_model(\"models/alexNetv6_logits_teacher.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teacher.evaluate(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "inputs = keras.Input(shape=(227,227,3))\n",
    "# targets = keras.Input(shape=(10,))\n",
    "x = keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3))(inputs)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "x = keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\")(x)\n",
    "# x = keras.layers.BatchNormalization()(x)\n",
    "# x = keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2))(x)\n",
    "# x = keras.layers.Flatten()(x)\n",
    "# x = keras.layers.Dense(4096, activation='relu')(x)\n",
    "# x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "# ### first branch\n",
    "branchLayer = keras.layers.Flatten(name=tf.compat.v1.get_default_graph().unique_name(\"branch_flatten\"))(x)\n",
    "branchLayer = keras.layers.Dense(124, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch124\"))(branchLayer)\n",
    "branchLayer = keras.layers.Dense(64, activation=\"relu\",name=tf.compat.v1.get_default_graph().unique_name(\"branch64\"))(branchLayer)\n",
    "x = keras.layers.Dense(10, activation=\"softmax\", name=tf.compat.v1.get_default_graph().unique_name(\"branch_output\"))(branchLayer)\n",
    "\n",
    "\n",
    "student_model = keras.Model(inputs=(inputs), outputs=[x], name=\"alexnet\")\n",
    "\n",
    "student_model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9), metrics=['accuracy'])\n",
    "student_model.save(\"models/alexNetv6_second_Exit.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 94s 48ms/step - loss: 0.1001 - accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10008857399225235, 0.9731730222702026]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, train the student model without the teacher input to get a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before training: 2688.9488805532455\n",
      "Epoch 1/3\n",
      "1406/1406 [==============================] - 91s 57ms/step - loss: 1.7910 - accuracy: 0.3989 - val_loss: 1.3382 - val_accuracy: 0.5278\n",
      "Epoch 2/3\n",
      "1406/1406 [==============================] - 90s 56ms/step - loss: 1.3048 - accuracy: 0.5328 - val_loss: 1.1569 - val_accuracy: 0.5819\n",
      "Epoch 3/3\n",
      "1406/1406 [==============================] - 85s 55ms/step - loss: 1.1058 - accuracy: 0.6070 - val_loss: 0.9795 - val_accuracy: 0.6556\n",
      "summary of trainable variables after training: 12822187.2433519028127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12822187.243351903"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "## keep setting the seed so that it doesn't matter what order you complete cells in. \n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_logits_student.hdf5\")\n",
    "summarize_keras_trainable_variables(student_model,\"before training\")\n",
    "student_model.fit(train_ds, validation_data = validation_ds, epochs=3)\n",
    "summarize_keras_trainable_variables(student_model,\"after training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 4s 12ms/step - loss: 0.7575 - accuracy: 0.7361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7575096487998962, 0.7360777258872986]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before training: 192.5101304054260\n",
      "Epoch 1/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4567 - accuracy: 0.4875\n",
      "[1.456679344177246, 0.48747995495796204]\n",
      "1406/1406 [==============================] - 102s 37ms/step - loss: 1.5733 - accuracy: 0.4449 - val_loss: 1.4031 - val_accuracy: 0.5140\n",
      "Epoch 2/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.7722 - accuracy: 0.4437\n",
      "[1.7721526622772217, 0.44370993971824646]\n",
      "1406/1406 [==============================] - 53s 31ms/step - loss: 1.1791 - accuracy: 0.5786 - val_loss: 1.6911 - val_accuracy: 0.4706\n",
      "Epoch 3/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4881 - accuracy: 0.5155\n",
      "[1.4880932569503784, 0.5155248641967773]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.9951 - accuracy: 0.6476 - val_loss: 1.4096 - val_accuracy: 0.5409\n",
      "Epoch 4/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.2667 - accuracy: 0.5895\n",
      "[1.266702651977539, 0.5895432829856873]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.8457 - accuracy: 0.7063 - val_loss: 1.2147 - val_accuracy: 0.5998\n",
      "Epoch 5/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.3019 - accuracy: 0.6028\n",
      "[1.3018970489501953, 0.6027644276618958]\n",
      "1406/1406 [==============================] - 54s 33ms/step - loss: 0.7173 - accuracy: 0.7516 - val_loss: 1.2589 - val_accuracy: 0.6004\n",
      "Epoch 6/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.5511 - accuracy: 0.5689\n",
      "[1.5510960817337036, 0.5689102411270142]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.6052 - accuracy: 0.7902 - val_loss: 1.5079 - val_accuracy: 0.5741\n",
      "Epoch 7/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.6947 - accuracy: 0.5645\n",
      "[1.694735050201416, 0.5645031929016113]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.5026 - accuracy: 0.8271 - val_loss: 1.6355 - val_accuracy: 0.5695\n",
      "Epoch 8/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.8730 - accuracy: 0.5558\n",
      "[1.8729580640792847, 0.5557892918586731]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.4299 - accuracy: 0.8527 - val_loss: 1.8211 - val_accuracy: 0.5673\n",
      "Epoch 9/9\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 2.0702 - accuracy: 0.5477\n",
      "[2.0702269077301025, 0.5476762652397156]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.3775 - accuracy: 0.8686 - val_loss: 1.9828 - val_accuracy: 0.5605\n",
      "summary of trainable variables after training: 533177.2514293249696\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 2.0702 - accuracy: 0.5477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0702269077301025, 0.5476762652397156]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestSetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        results = self.model.evaluate(test_ds)\n",
    "        print(results)\n",
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "## keep setting the seed so that it doesn't matter what order you complete cells in. \n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_first_Exit.hdf5\")\n",
    "summarize_keras_trainable_variables(student_model,\"before training\")\n",
    "student_model.fit(train_ds, validation_data = validation_ds, epochs=9,callbacks=[TestSetCallback()])\n",
    "summarize_keras_trainable_variables(student_model,\"after training\")\n",
    "student_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before training: 192.5101304054260\n",
      "Epoch 1/3\n",
      "   4/1406 [..............................] - ETA: 25s - loss: 2.4208 - accuracy: 0.1406    WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0084s vs `on_train_batch_end` time: 0.0093s). Check your callbacks.\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4567 - accuracy: 0.4875\n",
      "[1.456679344177246, 0.48747995495796204]\n",
      "1406/1406 [==============================] - 53s 29ms/step - loss: 1.5733 - accuracy: 0.4449 - val_loss: 1.4031 - val_accuracy: 0.5140\n",
      "Epoch 2/3\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.7722 - accuracy: 0.4437\n",
      "[1.7721526622772217, 0.44370993971824646]\n",
      "1406/1406 [==============================] - 54s 32ms/step - loss: 1.1791 - accuracy: 0.5786 - val_loss: 1.6911 - val_accuracy: 0.4706\n",
      "Epoch 3/3\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4881 - accuracy: 0.5155\n",
      "[1.4880932569503784, 0.5155248641967773]\n",
      "1406/1406 [==============================] - 50s 30ms/step - loss: 0.9951 - accuracy: 0.6476 - val_loss: 1.4096 - val_accuracy: 0.5409\n",
      "summary of trainable variables after training: 479021.9750222191215\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4881 - accuracy: 0.5155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4880932569503784, 0.5155248641967773]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestSetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        results = self.model.evaluate(test_ds)\n",
    "        print(results)\n",
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "## keep setting the seed so that it doesn't matter what order you complete cells in. \n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_first_Exit.hdf5\")\n",
    "summarize_keras_trainable_variables(student_model,\"before training\")\n",
    "student_model.fit(train_ds, validation_data = validation_ds, epochs=3,callbacks=[TestSetCallback()])\n",
    "summarize_keras_trainable_variables(student_model,\"after training\")\n",
    "student_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before training: 192.5101304054260\n",
      "Epoch 1/9\n",
      "1406/1406 [==============================] - 59s 35ms/step - loss: 1.5748 - accuracy: 0.4460 - val_loss: 1.4369 - val_accuracy: 0.4902\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4766 - accuracy: 0.4726\n",
      "[1.4765691757202148, 0.47255608439445496]\n",
      "Epoch 2/9\n",
      "1406/1406 [==============================] - 59s 35ms/step - loss: 1.1951 - accuracy: 0.5756 - val_loss: 1.3683 - val_accuracy: 0.5296\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.4189 - accuracy: 0.5117\n",
      "[1.4188727140426636, 0.51171875]\n",
      "Epoch 3/9\n",
      "1406/1406 [==============================] - 61s 38ms/step - loss: 1.0183 - accuracy: 0.6402 - val_loss: 1.2357 - val_accuracy: 0.5801\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 1.2945 - accuracy: 0.5600\n",
      "[1.2944990396499634, 0.5599960088729858]\n",
      "Epoch 4/9\n",
      "1406/1406 [==============================] - 62s 35ms/step - loss: 0.8648 - accuracy: 0.6962 - val_loss: 1.2624 - val_accuracy: 0.5887\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 1.2946 - accuracy: 0.5782\n",
      "[1.2946268320083618, 0.5782251358032227]\n",
      "Epoch 5/9\n",
      "1406/1406 [==============================] - 57s 35ms/step - loss: 0.7316 - accuracy: 0.7464 - val_loss: 1.2933 - val_accuracy: 0.5889\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 1.3364 - accuracy: 0.5783\n",
      "[1.3364394903182983, 0.5783253312110901]\n",
      "Epoch 6/9\n",
      "1406/1406 [==============================] - 87s 55ms/step - loss: 0.6131 - accuracy: 0.7891 - val_loss: 1.3905 - val_accuracy: 0.5927\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 1.4543 - accuracy: 0.5781\n",
      "[1.4542863368988037, 0.578125]\n",
      "Epoch 7/9\n",
      "1406/1406 [==============================] - 89s 57ms/step - loss: 0.5136 - accuracy: 0.8223 - val_loss: 1.4796 - val_accuracy: 0.5931\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 1.5658 - accuracy: 0.5733\n",
      "[1.5658166408538818, 0.573317289352417]\n",
      "Epoch 8/9\n",
      "1406/1406 [==============================] - 57s 35ms/step - loss: 0.4452 - accuracy: 0.8474 - val_loss: 1.6806 - val_accuracy: 0.5785\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 1.7476 - accuracy: 0.5617\n",
      "[1.7475775480270386, 0.5616987347602844]\n",
      "Epoch 9/9\n",
      "1406/1406 [==============================] - 89s 57ms/step - loss: 0.3851 - accuracy: 0.8658 - val_loss: 1.8146 - val_accuracy: 0.5877\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.8956 - accuracy: 0.5756\n",
      "[1.8955588340759277, 0.5756210088729858]\n",
      "summary of trainable variables after training: 544908.3939273101278\n",
      "312/312 [==============================] - 2s 6ms/step - loss: 1.8956 - accuracy: 0.5756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8955588340759277, 0.5756210088729858]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "## keep setting the seed so that it doesn't matter what order you complete cells in. \n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_first_Exit.hdf5\")\n",
    "summarize_keras_trainable_variables(student_model,\"before training\")\n",
    "student_model.fit(train_ds, validation_data = validation_ds, epochs=9,callbacks=[TestSetCallback()])\n",
    "summarize_keras_trainable_variables(student_model,\"after training\")\n",
    "student_model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before training: 722.7782071828842\n",
      "Epoch 1/9\n",
      "1406/1406 [==============================] - 91s 56ms/step - loss: 1.5343 - accuracy: 0.4550 - val_loss: 1.3269 - val_accuracy: 0.5256\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.3598 - accuracy: 0.5102\n",
      "[1.3598397970199585, 0.5102163553237915]\n",
      "Epoch 2/9\n",
      "1406/1406 [==============================] - 69s 44ms/step - loss: 1.1562 - accuracy: 0.5895 - val_loss: 1.1270 - val_accuracy: 0.6058\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.1552 - accuracy: 0.5950\n",
      "[1.155240774154663, 0.5949519276618958]\n",
      "Epoch 3/9\n",
      "1406/1406 [==============================] - 69s 44ms/step - loss: 0.9650 - accuracy: 0.6595 - val_loss: 1.0647 - val_accuracy: 0.6394\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.1066 - accuracy: 0.6211\n",
      "[1.1066480875015259, 0.62109375]\n",
      "Epoch 4/9\n",
      "1406/1406 [==============================] - 82s 52ms/step - loss: 0.8223 - accuracy: 0.7119 - val_loss: 1.0385 - val_accuracy: 0.6538\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.0901 - accuracy: 0.6359\n",
      "[1.0901410579681396, 0.6359174847602844]\n",
      "Epoch 5/9\n",
      "1406/1406 [==============================] - 68s 43ms/step - loss: 0.6906 - accuracy: 0.7596 - val_loss: 1.2275 - val_accuracy: 0.6234\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.3063 - accuracy: 0.6082\n",
      "[1.3062540292739868, 0.6081730723381042]\n",
      "Epoch 6/9\n",
      "1406/1406 [==============================] - 67s 43ms/step - loss: 0.5680 - accuracy: 0.8027 - val_loss: 1.2556 - val_accuracy: 0.6334\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.3262 - accuracy: 0.6245\n",
      "[1.3261829614639282, 0.6244992017745972]\n",
      "Epoch 7/9\n",
      "1406/1406 [==============================] - 68s 43ms/step - loss: 0.4572 - accuracy: 0.8431 - val_loss: 1.5294 - val_accuracy: 0.6086\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.6141 - accuracy: 0.5975\n",
      "[1.6140880584716797, 0.5974559187889099]\n",
      "Epoch 8/9\n",
      "1406/1406 [==============================] - 71s 46ms/step - loss: 0.3662 - accuracy: 0.8738 - val_loss: 1.7528 - val_accuracy: 0.5917\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.8388 - accuracy: 0.5842\n",
      "[1.8387786149978638, 0.5842347741127014]\n",
      "Epoch 9/9\n",
      "1406/1406 [==============================] - 66s 42ms/step - loss: 0.3020 - accuracy: 0.8939 - val_loss: 1.3563 - val_accuracy: 0.6777\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.4703 - accuracy: 0.6544\n",
      "[1.4702694416046143, 0.6544471383094788]\n",
      "summary of trainable variables after training: 2151495.0204285085201\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 1.4703 - accuracy: 0.6544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4702694416046143, 0.6544471383094788]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "## keep setting the seed so that it doesn't matter what order you complete cells in. \n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "summarize_keras_trainable_variables(student_model,\"before training\")\n",
    "student_model.fit(train_ds, validation_data = validation_ds, epochs=9,callbacks=[TestSetCallback()])\n",
    "summarize_keras_trainable_variables(student_model,\"after training\")\n",
    "student_model.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, train the student with the teacher model input as well to see the difference the teacher made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "def createDistiller(alpha,student,teacher):\n",
    "    loaded_student = student\n",
    "    model_teacher = teacher\n",
    "    summarize_keras_trainable_variables(loaded_student,\"before compiling in distiller\")\n",
    "    distiller = Distiller(student=loaded_student, teacher=model_teacher)\n",
    "    distiller.compile(\n",
    "        optimizer=tf.optimizers.SGD(lr=0.001,momentum=0.9),\n",
    "        metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "        student_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "\n",
    "        distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "        alpha=alpha,\n",
    "        temperature=1,\n",
    "    )\n",
    "    return distiller\n",
    "\n",
    "class TestSetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        results = self.model.evaluate(test_ds)\n",
    "        print(results)\n",
    "        \n",
    "class alphaCooldownCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Reduce impact of the teacher input to a minimum of zero. \n",
    "    \n",
    "\n",
    "  Arguments:\n",
    "      schedule: a function that takes an epoch index\n",
    "          (integer, indexed from 0) and current learning rate\n",
    "          as inputs and returns a new learning rate as output (float).\n",
    "  \"\"\"\n",
    "    def __init__(self, cooldownRate, cooldownPoint=1,method=\"sub\"):\n",
    "        super(alphaCooldownCallback, self).__init__()\n",
    "        self.cooldownRate = cooldownRate\n",
    "        self.cooldownPoint = cooldownPoint\n",
    "        self.cooldownMethod = \"sub\"\n",
    "\n",
    "    def on_epoch_begin(self, epoch,logs=None):\n",
    "        print(\"cdP\",self.cooldownPoint, \" cdR\",self.cooldownRate, \" alpha\", self.model.alpha, \"epoch\", epoch)\n",
    "        if epoch+1 >= self.cooldownPoint: #-1 because epoch internally start at 0, but are displayed as starting from 1. \n",
    "#             if self.cooldownMethod == \"sub\":\n",
    "            self.model.alpha = min(self.model.alpha + self.cooldownRate, 1)\n",
    "#             else: \n",
    "#                 self.model.alpha = max(self.model.alpha + (self.model.alpha * self.cooldownRate), 1)\n",
    "#                 self.model.alpha = 1\n",
    "        \n",
    "        tf.print(\"alpha set to: \",self.model.alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before compiling in distiller: 722.7782071828842\n",
      "1\n",
      "summary of trainable variables before training: 703.6863317489624\n",
      "Epoch 1/5\n",
      "312/312 [==============================] - 4s 12ms/step - categorical_accuracy: 0.4926 - student_loss: 1.4745\n",
      "[0.4925881326198578, 1.582078218460083]\n",
      "1406/1406 [==============================] - 102s 67ms/step - categorical_accuracy: 0.4648 - loss: 1.5056 - student_loss: 1.5056 - distillation_loss: 0.0000e+00 - val_categorical_accuracy: 0.5078 - val_student_loss: 1.6571\n",
      "Epoch 2/5\n",
      "312/312 [==============================] - 4s 12ms/step - categorical_accuracy: 0.6289 - student_loss: 1.0840\n",
      "[0.62890625, 1.2472343444824219]\n",
      "1406/1406 [==============================] - 115s 75ms/step - categorical_accuracy: 0.6076 - loss: 1.1081 - student_loss: 1.1081 - distillation_loss: 0.0000e+00 - val_categorical_accuracy: 0.6276 - val_student_loss: 1.7521\n",
      "Epoch 3/5\n",
      "312/312 [==============================] - 4s 11ms/step - categorical_accuracy: 0.6438 - student_loss: 1.0417\n",
      "[0.6438301205635071, 1.4574906826019287]\n",
      "1406/1406 [==============================] - 115s 75ms/step - categorical_accuracy: 0.6752 - loss: 0.9199 - student_loss: 0.9199 - distillation_loss: 0.0000e+00 - val_categorical_accuracy: 0.6430 - val_student_loss: 1.6653\n",
      "Epoch 4/5\n",
      "312/312 [==============================] - 4s 11ms/step - categorical_accuracy: 0.6609 - student_loss: 1.0167\n",
      "[0.6608573794364929, 1.2307944297790527]\n",
      "1406/1406 [==============================] - 111s 73ms/step - categorical_accuracy: 0.7261 - loss: 0.7809 - student_loss: 0.7809 - distillation_loss: 0.0000e+00 - val_categorical_accuracy: 0.6711 - val_student_loss: 1.6744\n",
      "Epoch 5/5\n",
      "312/312 [==============================] - 3s 11ms/step - categorical_accuracy: 0.6412 - student_loss: 1.1429\n",
      "[0.6412259340286255, 1.0740798711776733]\n",
      "1406/1406 [==============================] - 99s 63ms/step - categorical_accuracy: 0.7721 - loss: 0.6568 - student_loss: 0.6568 - distillation_loss: 0.0000e+00 - val_categorical_accuracy: 0.6548 - val_student_loss: 1.8838\n",
      "312/312 [==============================] - 4s 11ms/step - categorical_accuracy: 0.6412 - student_loss: 1.1429\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "# student_model = tf.keras.models.load_model(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "distiller = createDistiller(1,student_model,model_teacher)\n",
    "print(distiller.alpha)\n",
    "summarize_keras_trainable_variables(distiller.student,\"before training\")\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=5,verbose=1,\n",
    "              callbacks=[TestSetCallback()])#alphaCooldownCallback(cooldownRate=.2,cooldownPoint=1)])\n",
    "# Evaluate student on test dataset\n",
    "res = distiller.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before compiling in distiller: 722.7782071828842\n",
      "summary of trainable variables before training: 723.0987946689129\n",
      "Epoch 1/9\n",
      "Tensor(\"alexnet/branch_output_7/Softmax:0\", shape=(32, 10), dtype=float32)\n",
      "Tensor(\"alexnet/branch_output_7/Softmax:0\", shape=(32, 10), dtype=float32)\n",
      "   5/1406 [..............................] - ETA: 53s - categorical_accuracy: 0.1500 - loss: 2.5841 - student_loss: 2.7700 - distillation_loss: 2.5841  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0146s vs `on_train_batch_end` time: 0.0203s). Check your callbacks.\n",
      "1406/1406 [==============================] - 78s 50ms/step - categorical_accuracy: 0.4820 - loss: 1.2590 - student_loss: 1.4568 - distillation_loss: 1.2590 - val_categorical_accuracy: 0.5667 - val_student_loss: 1.7939\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5542 - student_loss: 1.2573\n",
      "[0.5541867017745972, 1.3407378196716309]\n",
      "Epoch 2/9\n",
      "1406/1406 [==============================] - 77s 50ms/step - categorical_accuracy: 0.6196 - loss: 0.8763 - student_loss: 1.0776 - distillation_loss: 0.8763 - val_categorical_accuracy: 0.5769 - val_student_loss: 1.9485\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5690 - student_loss: 1.2725\n",
      "[0.5690104365348816, 1.4730888605117798]\n",
      "Epoch 3/9\n",
      "1406/1406 [==============================] - 218s 150ms/step - categorical_accuracy: 0.6852 - loss: 0.7032 - student_loss: 0.9005 - distillation_loss: 0.7032 - val_categorical_accuracy: 0.6298 - val_student_loss: 1.8417\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6149 - student_loss: 1.1515\n",
      "[0.6148838400840759, 1.2863210439682007]\n",
      "Epoch 4/9\n",
      "1406/1406 [==============================] - 89s 51ms/step - categorical_accuracy: 0.7356 - loss: 0.5733 - student_loss: 0.7649 - distillation_loss: 0.5733 - val_categorical_accuracy: 0.5853 - val_student_loss: 1.9339\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5687 - student_loss: 1.3960\n",
      "[0.5687099099159241, 1.3612890243530273]\n",
      "Epoch 5/9\n",
      "1406/1406 [==============================] - 328s 199ms/step - categorical_accuracy: 0.7790 - loss: 0.4666 - student_loss: 0.6499 - distillation_loss: 0.4666 - val_categorical_accuracy: 0.6110 - val_student_loss: 1.8419\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5967 - student_loss: 1.3197\n",
      "[0.5966546535491943, 1.627554178237915]\n",
      "Epoch 6/9\n",
      "1406/1406 [==============================] - 120s 54ms/step - categorical_accuracy: 0.8173 - loss: 0.3745 - student_loss: 0.5461 - distillation_loss: 0.3745 - val_categorical_accuracy: 0.5988 - val_student_loss: 1.8807\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5796 - student_loss: 1.5104\n",
      "[0.5796273946762085, 1.4880387783050537]\n",
      "Epoch 7/9\n",
      "1406/1406 [==============================] - 145s 51ms/step - categorical_accuracy: 0.8522 - loss: 0.2943 - student_loss: 0.4522 - distillation_loss: 0.2943 - val_categorical_accuracy: 0.6404 - val_student_loss: 2.0933\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6229 - student_loss: 1.3550\n",
      "[0.6228966116905212, 1.051383376121521]\n",
      "Epoch 8/9\n",
      "1406/1406 [==============================] - 96s 54ms/step - categorical_accuracy: 0.8802 - loss: 0.2342 - student_loss: 0.3778 - distillation_loss: 0.2342 - val_categorical_accuracy: 0.6558 - val_student_loss: 2.0315\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6391 - student_loss: 1.3051\n",
      "[0.6391226053237915, 0.9578129649162292]\n",
      "Epoch 9/9\n",
      "1406/1406 [==============================] - 284s 181ms/step - categorical_accuracy: 0.9013 - loss: 0.1912 - student_loss: 0.3233 - distillation_loss: 0.1912 - val_categorical_accuracy: 0.6939 - val_student_loss: 1.6978\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6807 - student_loss: 1.1520\n",
      "[0.6806890964508057, 1.1696693897247314]\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6807 - student_loss: 1.1520\n"
     ]
    }
   ],
   "source": [
    "class TestSetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        results = self.model.evaluate(test_ds)\n",
    "        print(results)\n",
    "            \n",
    "\n",
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "distiller = createDistiller(1,student_model,model_teacher)\n",
    "summarize_keras_trainable_variables(distiller.student,\"before training\")\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=9,verbose=1,callbacks=[TestSetCallback()])\n",
    "# Evaluate student on test dataset\n",
    "res = distiller.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before compiling in distiller: 722.7782071828842\n",
      "summary of trainable variables before training: 723.0987946689129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sanity\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   5/1406 [..............................] - ETA: 51s - categorical_accuracy: 0.1125 - loss: 2.8548 - student_loss: 2.3112 - distillation_loss: 0.5436  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.0202s). Check your callbacks.\n",
      "1406/1406 [==============================] - 79s 47ms/step - categorical_accuracy: 0.4712 - loss: 1.4406 - student_loss: 1.1831 - distillation_loss: 0.2575 - val_categorical_accuracy: 0.5064 - val_student_loss: 1.7999\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5038 - student_loss: 1.3954\n",
      "[0.5038061141967773, 1.4889311790466309]\n",
      "Epoch 2/3\n",
      "1406/1406 [==============================] - 76s 47ms/step - categorical_accuracy: 0.6172 - loss: 1.0498 - student_loss: 0.8696 - distillation_loss: 0.1802 - val_categorical_accuracy: 0.5310 - val_student_loss: 1.9042\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5271 - student_loss: 1.3760\n",
      "[0.5271434187889099, 1.2526040077209473]\n",
      "Epoch 3/3\n",
      "1406/1406 [==============================] - 74s 47ms/step - categorical_accuracy: 0.6889 - loss: 0.8537 - student_loss: 0.7109 - distillation_loss: 0.1428 - val_categorical_accuracy: 0.6050 - val_student_loss: 1.8366\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6023 - student_loss: 1.1928\n",
      "[0.6022636294364929, 1.262915015220642]\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6023 - student_loss: 1.1928\n"
     ]
    }
   ],
   "source": [
    "class TestSetCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        results = self.model.evaluate(test_ds)\n",
    "        print(results)\n",
    "            \n",
    "\n",
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "distiller = createDistiller(.8,student_model,model_teacher)\n",
    "summarize_keras_trainable_variables(distiller.student,\"before training\")\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=3,verbose=1,callbacks=[TestSetCallback()])\n",
    "# Evaluate student on test dataset\n",
    "res = distiller.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary of trainable variables before compiling in distiller: 722.7782071828842\n",
      "summary of trainable variables before training: 723.0987946689129\n",
      "Epoch 1/3\n",
      "1406/1406 [==============================] - 98s 58ms/step - categorical_accuracy: 0.4870 - loss: 1.2506 - student_loss: 0.0000e+00 - distillation_loss: 1.2506 - val_categorical_accuracy: 0.5503 - val_student_loss: 1.8095\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.5506 - student_loss: 1.2733\n",
      "[0.5505809187889099, 1.0943448543548584]\n",
      "Epoch 2/3\n",
      "1406/1406 [==============================] - 77s 48ms/step - categorical_accuracy: 0.6219 - loss: 0.8701 - student_loss: 0.0000e+00 - distillation_loss: 0.8701 - val_categorical_accuracy: 0.6090 - val_student_loss: 1.5796\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6092 - student_loss: 1.1060\n",
      "[0.6091746687889099, 1.1122685670852661]\n",
      "Epoch 3/3\n",
      "1406/1406 [==============================] - 81s 49ms/step - categorical_accuracy: 0.6892 - loss: 0.6912 - student_loss: 0.0000e+00 - distillation_loss: 0.6912 - val_categorical_accuracy: 0.6532 - val_student_loss: 1.6452\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6431 - student_loss: 1.0245\n",
      "[0.6431289911270142, 1.0406861305236816]\n",
      "312/312 [==============================] - 3s 9ms/step - categorical_accuracy: 0.6431 - student_loss: 1.0245\n"
     ]
    }
   ],
   "source": [
    "seed = 66\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "student_model = tf.keras.models.load_model(\"models/alexNetv6_second_Exit.hdf5\")\n",
    "distiller = createDistiller(0,student_model,model_teacher)\n",
    "summarize_keras_trainable_variables(distiller.student,\"before training\")\n",
    "# Distill teacher to student\n",
    "distiller.fit(train_ds, validation_data = validation_ds,epochs=3,verbose=1,callbacks=[TestSetCallback()])\n",
    "# Evaluate student on test dataset\n",
    "res = distiller.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
