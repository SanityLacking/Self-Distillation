{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import branchingdnn as branching\n",
    "from branchingdnn.utils import *\n",
    "from branchingdnn.dataset import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSize 45000\n",
      "testSize 10000\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare.dataset(tf.keras.datasets.cifar10.load_data(),32,5000,22500,(227,227), channel_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens = tf.constant((1,2,3))\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSize 45000\n",
      "testSize 10000\n",
      "Tensor(\"args_0:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "Tensor(\"transpose:0\", shape=(3, 32, 32), dtype=uint8)\n",
      "Tensor(\"args_0:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "Tensor(\"transpose:0\", shape=(3, 32, 32), dtype=uint8)\n",
      "Tensor(\"args_0:0\", shape=(32, 32, 3), dtype=uint8)\n",
      "Tensor(\"transpose:0\", shape=(3, 32, 32), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "validation_size = 5000\n",
    "shuffle_size = 22500\n",
    "input_size=(227,227)\n",
    "channel_first = False\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "#hack to get around the limitation of providing additional parameters to the map function for the datasets below \n",
    "def augment_images(image, label,input_size=input_size):\n",
    "    if channel_first:\n",
    "        #swap the channels around.\n",
    "        image = tf.transpose(image, [2, 0, 1])\n",
    "        \n",
    "    return prepare.augment_images(image, label, input_size)\n",
    "\n",
    "validation_images, validation_labels = train_images[:validation_size], train_labels[:validation_size] #get the first 5k training samples as validation set\n",
    "train_images, train_labels = train_images[validation_size:], train_labels[validation_size:] # now remove the validation set from the training set.\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "\n",
    "\n",
    "\n",
    "train_ds_size = len(list(train_ds))\n",
    "test_ds_size = len(list(test_ds))\n",
    "validation_ds_size = len(list(validation_ds))\n",
    "\n",
    "print(\"trainSize {}\".format(train_ds_size))\n",
    "print(\"testSize {}\".format(test_ds_size))\n",
    "train_ds = (train_ds\n",
    "                .map(augment_images)\n",
    "                .shuffle(buffer_size=tf.cast(shuffle_size,'int64'))\n",
    "                .batch(batch_size=batch_size, drop_remainder=True))\n",
    "\n",
    "test_ds = (test_ds\n",
    "                .map(augment_images)\n",
    "                #   .shuffle(buffer_size=train_ds_size)\n",
    "                .batch(batch_size=batch_size, drop_remainder=True))\n",
    "\n",
    "validation_ds = (validation_ds\n",
    "                .map(augment_images)\n",
    "                #   .shuffle(buffer_size=validation_ds_size)\n",
    "                .batch(batch_size=batch_size, drop_remainder=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def SqueezeNet(nb_classes, inputs=(3, 224, 224)):\n",
    "    \"\"\" Keras Implementation of SqueezeNet(arXiv 1602.07360)\n",
    "    @param nb_classes: total number of final categories\n",
    "    Arguments:\n",
    "    inputs -- shape of the input images (channel, cols, rows)\n",
    "    \"\"\"\n",
    "\n",
    "    input_img = Input(shape=inputs)\n",
    "    conv1 = Convolution2D(\n",
    "        96, (7, 7), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        strides=(2, 2), padding='same', name='conv1',\n",
    "        data_format=\"channels_first\")(input_img)\n",
    "    maxpool1 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool1',\n",
    "        data_format=\"channels_first\")(conv1)\n",
    "    fire2_squeeze = Convolution2D(\n",
    "        16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool1)\n",
    "    fire2_expand1 = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand1',\n",
    "        data_format=\"channels_first\")(fire2_squeeze)\n",
    "    fire2_expand2 = Convolution2D(\n",
    "        64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire2_expand2',\n",
    "        data_format=\"channels_first\")(fire2_squeeze)\n",
    "    merge2 = Concatenate(axis=1)([fire2_expand1, fire2_expand2])\n",
    "\n",
    "    fire3_squeeze = Convolution2D(\n",
    "        16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_squeeze',\n",
    "        data_format=\"channels_first\")(merge2)\n",
    "    fire3_expand1 = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_expand1',\n",
    "        data_format=\"channels_first\")(fire3_squeeze)\n",
    "    fire3_expand2 = Convolution2D(\n",
    "        64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire3_expand2',\n",
    "        data_format=\"channels_first\")(fire3_squeeze)\n",
    "    merge3 = Concatenate(axis=1)([fire3_expand1, fire3_expand2])\n",
    "\n",
    "    fire4_squeeze = Convolution2D(\n",
    "        32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_squeeze',\n",
    "        data_format=\"channels_first\")(merge3)\n",
    "    fire4_expand1 = Convolution2D(\n",
    "        128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_expand1',\n",
    "        data_format=\"channels_first\")(fire4_squeeze)\n",
    "    fire4_expand2 = Convolution2D(\n",
    "        128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire4_expand2',\n",
    "        data_format=\"channels_first\")(fire4_squeeze)\n",
    "    merge4 = Concatenate(axis=1)([fire4_expand1, fire4_expand2])\n",
    "    maxpool4 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool4',\n",
    "        data_format=\"channels_first\")(merge4)\n",
    "\n",
    "    fire5_squeeze = Convolution2D(\n",
    "        32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool4)\n",
    "    fire5_expand1 = Convolution2D(\n",
    "        128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_expand1',\n",
    "        data_format=\"channels_first\")(fire5_squeeze)\n",
    "    fire5_expand2 = Convolution2D(\n",
    "        128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire5_expand2',\n",
    "        data_format=\"channels_first\")(fire5_squeeze)\n",
    "    merge5 = Concatenate(axis=1)([fire5_expand1, fire5_expand2])\n",
    "\n",
    "    fire6_squeeze = Convolution2D(\n",
    "        48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_squeeze',\n",
    "        data_format=\"channels_first\")(merge5)\n",
    "    fire6_expand1 = Convolution2D(\n",
    "        192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_expand1',\n",
    "        data_format=\"channels_first\")(fire6_squeeze)\n",
    "    fire6_expand2 = Convolution2D(\n",
    "        192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire6_expand2',\n",
    "        data_format=\"channels_first\")(fire6_squeeze)\n",
    "    merge6 = Concatenate(axis=1)([fire6_expand1, fire6_expand2])\n",
    "\n",
    "    fire7_squeeze = Convolution2D(\n",
    "        48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_squeeze',\n",
    "        data_format=\"channels_first\")(merge6)\n",
    "    fire7_expand1 = Convolution2D(\n",
    "        192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_expand1',\n",
    "        data_format=\"channels_first\")(fire7_squeeze)\n",
    "    fire7_expand2 = Convolution2D(\n",
    "        192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire7_expand2',\n",
    "        data_format=\"channels_first\")(fire7_squeeze)\n",
    "    merge7 = Concatenate(axis=1)([fire7_expand1, fire7_expand2])\n",
    "\n",
    "    fire8_squeeze = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_squeeze',\n",
    "        data_format=\"channels_first\")(merge7)\n",
    "    fire8_expand1 = Convolution2D(\n",
    "        256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_expand1',\n",
    "        data_format=\"channels_first\")(fire8_squeeze)\n",
    "    fire8_expand2 = Convolution2D(\n",
    "        256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire8_expand2',\n",
    "        data_format=\"channels_first\")(fire8_squeeze)\n",
    "    merge8 = Concatenate(axis=1)([fire8_expand1, fire8_expand2])\n",
    "\n",
    "    maxpool8 = MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), name='maxpool8',\n",
    "        data_format=\"channels_first\")(merge8)\n",
    "    fire9_squeeze = Convolution2D(\n",
    "        64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_squeeze',\n",
    "        data_format=\"channels_first\")(maxpool8)\n",
    "    fire9_expand1 = Convolution2D(\n",
    "        256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_expand1',\n",
    "        data_format=\"channels_first\")(fire9_squeeze)\n",
    "    fire9_expand2 = Convolution2D(\n",
    "        256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='same', name='fire9_expand2',\n",
    "        data_format=\"channels_first\")(fire9_squeeze)\n",
    "    merge9 = Concatenate(axis=1)([fire9_expand1, fire9_expand2])\n",
    "\n",
    "    fire9_dropout = Dropout(0.5, name='fire9_dropout')(merge9)\n",
    "    conv10 = Convolution2D(\n",
    "        nb_classes, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "        padding='valid', name='conv10',\n",
    "        data_format=\"channels_first\")(fire9_dropout)\n",
    "\n",
    "    global_avgpool10 = GlobalAveragePooling2D(data_format='channels_first')(conv10)\n",
    "    softmax = Activation(\"softmax\", name='softmax')(global_avgpool10)\n",
    "\n",
    "    return Model(inputs=input_img, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Activation, Concatenate\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "def SqueezeNet(nb_classes, inputs=(227, 227,3)):\n",
    "  \"\"\" Keras Implementation of SqueezeNet(arXiv 1602.07360)\n",
    "  @param nb_classes: total number of final categories\n",
    "  Arguments:\n",
    "  inputs -- shape of the input images (channel, cols, rows)\n",
    "  \"\"\"\n",
    "\n",
    "  input_img = Input(shape=inputs)\n",
    "  conv1 = Convolution2D(\n",
    "      96, (7, 7), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      strides=(2, 2), padding='same', name='conv1',\n",
    "      data_format=\"channels_last\")(input_img)\n",
    "  maxpool1 = MaxPooling2D(\n",
    "      pool_size=(3, 3), strides=(2, 2), name='maxpool1',\n",
    "      data_format=\"channels_last\")(conv1)\n",
    "  fire2_squeeze = Convolution2D(\n",
    "      16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire2_squeeze',\n",
    "      data_format=\"channels_last\")(maxpool1)\n",
    "  fire2_expand1 = Convolution2D(\n",
    "      64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire2_expand1',\n",
    "      data_format=\"channels_last\")(fire2_squeeze)\n",
    "  fire2_expand2 = Convolution2D(\n",
    "      64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire2_expand2',\n",
    "      data_format=\"channels_last\")(fire2_squeeze)\n",
    "  merge2 = Concatenate(axis=1)([fire2_expand1, fire2_expand2])\n",
    "\n",
    "  fire3_squeeze = Convolution2D(\n",
    "      16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire3_squeeze',\n",
    "      data_format=\"channels_last\")(merge2)\n",
    "  fire3_expand1 = Convolution2D(\n",
    "      64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire3_expand1',\n",
    "      data_format=\"channels_last\")(fire3_squeeze)\n",
    "  fire3_expand2 = Convolution2D(\n",
    "      64, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire3_expand2',\n",
    "      data_format=\"channels_last\")(fire3_squeeze)\n",
    "  merge3 = Concatenate(axis=1)([fire3_expand1, fire3_expand2])\n",
    "\n",
    "  fire4_squeeze = Convolution2D(\n",
    "      32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire4_squeeze',\n",
    "      data_format=\"channels_last\")(merge3)\n",
    "  fire4_expand1 = Convolution2D(\n",
    "      128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire4_expand1',\n",
    "      data_format=\"channels_last\")(fire4_squeeze)\n",
    "  fire4_expand2 = Convolution2D(\n",
    "      128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire4_expand2',\n",
    "      data_format=\"channels_last\")(fire4_squeeze)\n",
    "  merge4 = Concatenate(axis=1)([fire4_expand1, fire4_expand2])\n",
    "  maxpool4 = MaxPooling2D(\n",
    "      pool_size=(3, 3), strides=(2, 2), name='maxpool4',\n",
    "      data_format=\"channels_last\")(merge4)\n",
    "\n",
    "  fire5_squeeze = Convolution2D(\n",
    "      32, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire5_squeeze',\n",
    "      data_format=\"channels_last\")(maxpool4)\n",
    "  fire5_expand1 = Convolution2D(\n",
    "      128, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire5_expand1',\n",
    "      data_format=\"channels_last\")(fire5_squeeze)\n",
    "  fire5_expand2 = Convolution2D(\n",
    "      128, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire5_expand2',\n",
    "      data_format=\"channels_last\")(fire5_squeeze)\n",
    "  merge5 = Concatenate(axis=1)([fire5_expand1, fire5_expand2])\n",
    "\n",
    "  fire6_squeeze = Convolution2D(\n",
    "      48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire6_squeeze',\n",
    "      data_format=\"channels_last\")(merge5)\n",
    "  fire6_expand1 = Convolution2D(\n",
    "      192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire6_expand1',\n",
    "      data_format=\"channels_last\")(fire6_squeeze)\n",
    "  fire6_expand2 = Convolution2D(\n",
    "      192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire6_expand2',\n",
    "      data_format=\"channels_last\")(fire6_squeeze)\n",
    "  merge6 = Concatenate(axis=1)([fire6_expand1, fire6_expand2])\n",
    "\n",
    "  fire7_squeeze = Convolution2D(\n",
    "      48, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire7_squeeze',\n",
    "      data_format=\"channels_last\")(merge6)\n",
    "  fire7_expand1 = Convolution2D(\n",
    "      192, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire7_expand1',\n",
    "      data_format=\"channels_last\")(fire7_squeeze)\n",
    "  fire7_expand2 = Convolution2D(\n",
    "      192, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire7_expand2',\n",
    "      data_format=\"channels_last\")(fire7_squeeze)\n",
    "  merge7 = Concatenate(axis=1)([fire7_expand1, fire7_expand2])\n",
    "\n",
    "  fire8_squeeze = Convolution2D(\n",
    "      64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire8_squeeze',\n",
    "      data_format=\"channels_last\")(merge7)\n",
    "  fire8_expand1 = Convolution2D(\n",
    "      256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire8_expand1',\n",
    "      data_format=\"channels_last\")(fire8_squeeze)\n",
    "  fire8_expand2 = Convolution2D(\n",
    "      256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire8_expand2',\n",
    "      data_format=\"channels_last\")(fire8_squeeze)\n",
    "  merge8 = Concatenate(axis=1)([fire8_expand1, fire8_expand2])\n",
    "\n",
    "  maxpool8 = MaxPooling2D(\n",
    "      pool_size=(3, 3), strides=(2, 2), name='maxpool8',\n",
    "      data_format=\"channels_last\")(merge8)\n",
    "  fire9_squeeze = Convolution2D(\n",
    "      64, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire9_squeeze',\n",
    "      data_format=\"channels_last\")(maxpool8)\n",
    "  fire9_expand1 = Convolution2D(\n",
    "      256, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire9_expand1',\n",
    "      data_format=\"channels_last\")(fire9_squeeze)\n",
    "  fire9_expand2 = Convolution2D(\n",
    "      256, (3, 3), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='same', name='fire9_expand2',\n",
    "      data_format=\"channels_last\")(fire9_squeeze)\n",
    "  merge9 = Concatenate(axis=1)([fire9_expand1, fire9_expand2])\n",
    "\n",
    "  fire9_dropout = Dropout(0.5, name='fire9_dropout')(merge9)\n",
    "  conv10 = Convolution2D(\n",
    "      nb_classes, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "      padding='valid', name='conv10'\n",
    "      )(fire9_dropout)\n",
    "\n",
    "  global_avgpool10 = GlobalAveragePooling2D()(conv10)\n",
    "  softmax = Activation(\"softmax\", name='softmax')(global_avgpool10)\n",
    "\n",
    "  return Model(inputs=input_img, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 227, 227, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 114, 114, 96) 14208       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 96)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2_squeeze (Conv2D)          (None, 56, 56, 16)   1552        maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2_expand1 (Conv2D)          (None, 56, 56, 64)   1088        fire2_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2_expand2 (Conv2D)          (None, 56, 56, 64)   9280        fire2_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112, 56, 64)  0           fire2_expand1[0][0]              \n",
      "                                                                 fire2_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_squeeze (Conv2D)          (None, 112, 56, 16)  1040        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fire3_expand1 (Conv2D)          (None, 112, 56, 64)  1088        fire3_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire3_expand2 (Conv2D)          (None, 112, 56, 64)  9280        fire3_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 224, 56, 64)  0           fire3_expand1[0][0]              \n",
      "                                                                 fire3_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4_squeeze (Conv2D)          (None, 224, 56, 32)  2080        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4_expand1 (Conv2D)          (None, 224, 56, 128) 4224        fire4_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire4_expand2 (Conv2D)          (None, 224, 56, 128) 36992       fire4_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 448, 56, 128) 0           fire4_expand1[0][0]              \n",
      "                                                                 fire4_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool4 (MaxPooling2D)         (None, 223, 27, 128) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire5_squeeze (Conv2D)          (None, 223, 27, 32)  4128        maxpool4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire5_expand1 (Conv2D)          (None, 223, 27, 128) 4224        fire5_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire5_expand2 (Conv2D)          (None, 223, 27, 128) 36992       fire5_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 446, 27, 128) 0           fire5_expand1[0][0]              \n",
      "                                                                 fire5_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6_squeeze (Conv2D)          (None, 446, 27, 48)  6192        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6_expand1 (Conv2D)          (None, 446, 27, 192) 9408        fire6_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire6_expand2 (Conv2D)          (None, 446, 27, 192) 83136       fire6_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 892, 27, 192) 0           fire6_expand1[0][0]              \n",
      "                                                                 fire6_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7_squeeze (Conv2D)          (None, 892, 27, 48)  9264        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7_expand1 (Conv2D)          (None, 892, 27, 192) 9408        fire7_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire7_expand2 (Conv2D)          (None, 892, 27, 192) 83136       fire7_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1784, 27, 192 0           fire7_expand1[0][0]              \n",
      "                                                                 fire7_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8_squeeze (Conv2D)          (None, 1784, 27, 64) 12352       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8_expand1 (Conv2D)          (None, 1784, 27, 256 16640       fire8_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire8_expand2 (Conv2D)          (None, 1784, 27, 256 147712      fire8_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3568, 27, 256 0           fire8_expand1[0][0]              \n",
      "                                                                 fire8_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "maxpool8 (MaxPooling2D)         (None, 1783, 13, 256 0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire9_squeeze (Conv2D)          (None, 1783, 13, 64) 16448       maxpool8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire9_expand1 (Conv2D)          (None, 1783, 13, 256 16640       fire9_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire9_expand2 (Conv2D)          (None, 1783, 13, 256 147712      fire9_squeeze[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 3566, 13, 256 0           fire9_expand1[0][0]              \n",
      "                                                                 fire9_expand2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire9_dropout (Dropout)         (None, 3566, 13, 256 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 3566, 13, 10) 2570        fire9_dropout[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 10)           0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 10)           0           global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 686,794\n",
      "Trainable params: 686,794\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SqueezeNet(10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds, test_ds = dataset\n",
    "model.compile(optimizer=tf.optimizers.SGD(lr=0.001), loss='SparseCategoricalCrossentropy', metrics=['accuracy',confidenceDifference],run_eagerly=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,227,227,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node resize/ResizeBilinear}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2112\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2113\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2114\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2577\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2578\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2579\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6861\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6862\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6863\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,227,227,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node resize/ResizeBilinear}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:IteratorGetNext]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-474382ef112a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepocs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    803\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m       outputs = reduce_per_replica(\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[1;34m(mode)\u001b[0m\n\u001b[0;32m   2114\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m       \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2116\u001b[1;33m       \u001b[0mexecutor_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sanity\\appdata\\local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\eager\\executor.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,227,227,32] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node resize/ResizeBilinear}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "epocs = 1\n",
    "model.fit(train_ds, epochs=epocs,validation_data=validation_ds,validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 114, 114, 96)      14208     \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "fire2_squeeze (Conv2D)       (None, 56, 56, 16)        1552      \n",
      "=================================================================\n",
      "Total params: 15,760\n",
      "Trainable params: 15,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs=(227, 227,3)\n",
    "input_img = Input(shape=inputs)\n",
    "conv1 = Convolution2D(\n",
    "    96, (7, 7), activation='relu', kernel_initializer='glorot_uniform',\n",
    "    strides=(2, 2), padding='same', name='conv1')(input_img)\n",
    "maxpool1 = MaxPooling2D(\n",
    "    pool_size=(3, 3), strides=(2, 2), name='maxpool1')(conv1)\n",
    "fire2_squeeze = Convolution2D(\n",
    "    16, (1, 1), activation='relu', kernel_initializer='glorot_uniform',\n",
    "    padding='same', name='fire2_squeeze')(maxpool1)\n",
    "model = Model(inputs=input_img, outputs=fire2_squeeze)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
